2024-08-13 01:41:36.782580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 01:41:36.876284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 01:41:36.876315: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 01:41:36.895613: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 01:41:37.298206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:41:37.298289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:41:37.298299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23100 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_01-41-39-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723506099.1358397 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 114085.07it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.57it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.52it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.76it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_01-41-39-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.36it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.16it/s] 20%|██        | 2/10 [00:00<00:01,  4.16it/s] 30%|███       | 3/10 [00:00<00:01,  4.53it/s] 40%|████      | 4/10 [00:00<00:01,  4.71it/s] 50%|█████     | 5/10 [00:01<00:01,  4.69it/s] 60%|██████    | 6/10 [00:01<00:00,  4.74it/s] 70%|███████   | 7/10 [00:01<00:00,  4.96it/s] 80%|████████  | 8/10 [00:01<00:00,  5.06it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.07it/s]100%|██████████| 10/10 [00:02<00:00,  4.91it/s]100%|██████████| 10/10 [00:02<00:00,  4.75it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7134.99it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:18,  3.07s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:25,  3.51s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:28,  2.12s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:11,  1.46s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:23,  1.10s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:18,  1.14it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.62# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:36,  1.35it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:09,  1.54it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:51,  1.69it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:39,  1.82it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:39,  1.82it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:30,  1.92it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:24,  1.99it/s]Progress: 7.00%
---- avg training fps: 4.03# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:20,  2.04it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:17,  2.08it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:14,  2.11it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:13,  2.12it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:12,  2.14it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:10,  2.15it/s]Progress: 9.00%
---- avg training fps: 4.91# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:10,  2.16it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:07,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:07,  2.17it/s]Progress: 11.00%
---- avg training fps: 5.51# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:03,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:03,  2.19it/s]Progress: 13.00%
---- avg training fps: 5.95# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:03,  2.19it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:02,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:02,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:16,  1.95it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:11,  2.02it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:08,  2.07it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:05,  2.10it/s]Progress: 15.00%
---- avg training fps: 6.24# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:03,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:00,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:00,  2.17it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:00,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:58,  2.18it/s]Progress: 17.00%
---- avg training fps: 6.50# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:58,  2.18it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.71# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:55,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<05:59,  1.45s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:44,  1.15s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:51,  1.06it/s]Progress: 21.00%
---- avg training fps: 6.23# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:15,  1.25it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:50,  1.43it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:32,  1.60it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:19,  1.73it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:11,  1.84it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:05,  1.92it/s]Progress: 23.00%
---- avg training fps: 6.41# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:05,  1.92it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<02:00,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:56,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:54,  2.08it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<02:06,  1.86it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<02:00,  1.95it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:56,  2.01it/s]Progress: 25.00%
---- avg training fps: 6.54# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:53,  2.06it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:51,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:46,  2.14it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.67# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:45,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:44,  2.17it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:43,  2.17it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:43,  2.16it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:43,  2.16it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:45<01:42,  2.16it/s]Progress: 29.00%
---- avg training fps: 6.79# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:42,  2.16it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:40,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:40,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:39,  2.16it/s]Progress: 31.00%
---- avg training fps: 6.90# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:39,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:38,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:38,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:38,  2.16it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:37,  2.17it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 6.99# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:51<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:51<01:36,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:35,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.08# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:59<04:20,  1.32s/it]Progress: 37.00%
---- avg training fps: 6.82# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<03:29,  1.06s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:00<02:52,  1.13it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<02:27,  1.32it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:01<02:08,  1.51it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:01<01:56,  1.66it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:02<01:47,  1.78it/s]Progress: 39.00%
---- avg training fps: 6.90# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:02<01:41,  1.89it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:03<01:47,  1.77it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:03<01:47,  1.77it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:03<01:40,  1.88it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:04<01:35,  1.96it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:04<01:32,  2.02it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:05<01:29,  2.07it/s]Progress: 41.00%
---- avg training fps: 6.96# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:05<01:27,  2.10it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:26,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:06<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:24,  2.16it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:07<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:22,  2.18it/s]Progress: 43.00%
---- avg training fps: 7.03# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:08<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:08<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:09<01:20,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:09<01:20,  2.18it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:10<01:20,  2.19it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:10<01:19,  2.19it/s]Progress: 45.00%
---- avg training fps: 7.10# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:11<01:19,  2.19it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:11<01:18,  2.19it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:11<01:18,  2.19it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:12<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:13<01:16,  2.19it/s]Progress: 47.00%
---- avg training fps: 7.16# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:16,  2.19it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:14<01:15,  2.19it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:15,  2.19it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:15<01:14,  2.19it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:14,  2.19it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:16<01:13,  2.19it/s]Progress: 49.00%
---- avg training fps: 7.22# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:16<01:13,  2.19it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:16<01:12,  2.19it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:17<01:12,  2.19it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:17<01:12,  2.20it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:17<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:18<01:11,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:18<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.27# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:19<01:10,  2.19it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:19<01:10,  2.19it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:20<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:09,  2.19it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:21<01:09,  2.19it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:08,  2.19it/s]Progress: 53.00%
---- avg training fps: 7.32# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:08,  2.19it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:08,  2.19it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:26<03:54,  1.59s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<03:03,  1.25s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:27<02:27,  1.01s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<02:02,  1.18it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:28<01:45,  1.37it/s]Progress: 55.00%
---- avg training fps: 7.05# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:28<01:33,  1.54it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:28<01:24,  1.68it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:29<01:18,  1.80it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:29<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:30<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:30<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:30<01:08,  2.02it/s]Progress: 57.00%
---- avg training fps: 7.10# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:31<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:31<01:05,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:32<01:04,  2.11it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:32<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:33<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:33<01:01,  2.13it/s]Progress: 59.00%
---- avg training fps: 7.14# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:34<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:34<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:35<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:35<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:36<00:58,  2.16it/s]Progress: 61.00%
---- avg training fps: 7.19# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:36<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:37<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:37<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:38<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:38<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:39<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.23# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:39<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:39<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:41<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:41<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:41<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 7.26# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:42<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:42<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:43<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:44<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:44<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.30# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:45<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:45<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:46<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:46<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:47<00:47,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:47<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.33# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:47<00:46,  2.15it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:48<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:48<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:48<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:31,  1.54s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:53<01:58,  1.22s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:35,  1.01it/s]Progress: 71.00%
---- avg training fps: 7.13# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:54<01:19,  1.20it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:07,  1.38it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:55<01:00,  1.55it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:55<00:54,  1.69it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:56<00:50,  1.80it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:47,  1.90it/s]Progress: 73.00%
---- avg training fps: 7.17# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:57<00:47,  1.90it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:57<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:58<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:41,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:59<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:59<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:00<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:37,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:02<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.23# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:03<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:05<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.26# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:05<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:06<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:06<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:06<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:07<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:30,  2.16it/s]Progress: 81.00%
---- avg training fps: 7.29# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:08<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:09<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:10<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:27,  2.16it/s]Progress: 83.00%
---- avg training fps: 7.32# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:11<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:11<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:12<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:12<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:12<00:25,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:13<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:24,  2.15it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:14<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:22,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:19<01:16,  1.60s/it]Progress: 87.00%
---- avg training fps: 7.18# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:20<00:59,  1.26s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:20<00:46,  1.02s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:21<00:38,  1.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:21<00:32,  1.36it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:22<00:28,  1.53it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:22<00:24,  1.68it/s]Progress: 89.00%
---- avg training fps: 7.21# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:23<00:22,  1.80it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:23<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:24<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:24<00:19,  1.98it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:24<00:18,  2.02it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:25<00:17,  2.06it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:25<00:17,  2.09it/s]Progress: 91.00%
---- avg training fps: 7.23# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:26<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:26<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:26<00:15,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:27<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:27<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:28<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.26# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:28<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:28<00:13,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:29<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:29<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:30<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:30<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:31<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.28# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:31<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:32<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:32<00:09,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:32<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:33<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:33<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:33<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.31# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:34<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:34<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:35<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:35<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:36<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:36<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.33# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:37<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:37<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:38<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:38<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:38<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:38<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:39<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.35# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:39<00:02,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:40<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:40<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:41<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:41<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:42<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.38Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.45it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.43it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.42it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.40it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.39it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.38it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.38it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.37it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.37it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.36it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.36it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.35it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.93it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.17it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.20it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.21it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:02<00:00,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 01:46:10.828993: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 01:46:10.928181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 01:46:10.928209: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 01:46:10.946991: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 01:46:11.347657: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:46:11.347748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:46:11.347757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23112 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_01-46-13-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723506373.187718 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 5978.80it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.14it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.33it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.71it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_01-46-13-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.35it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.46it/s] 20%|██        | 2/10 [00:00<00:01,  4.43it/s] 30%|███       | 3/10 [00:00<00:01,  4.75it/s] 40%|████      | 4/10 [00:00<00:01,  4.88it/s] 50%|█████     | 5/10 [00:01<00:01,  4.85it/s] 60%|██████    | 6/10 [00:01<00:00,  4.89it/s] 70%|███████   | 7/10 [00:01<00:00,  5.11it/s] 80%|████████  | 8/10 [00:01<00:00,  5.18it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.15it/s]100%|██████████| 10/10 [00:02<00:00,  5.00it/s]100%|██████████| 10/10 [00:02<00:00,  4.89it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 6975.68it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:38,  2.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:39,  3.35s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:02,  2.03s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:55,  1.40s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:12,  1.06s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:10,  1.17it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.72# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:31,  1.39it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:05,  1.57it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:48,  1.73it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:28,  1.95it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:23,  2.01it/s]Progress: 7.00%
---- avg training fps: 4.15# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:16,  2.09it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:14,  2.12it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:12,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:11,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:10,  2.16it/s]Progress: 9.00%
---- avg training fps: 5.03# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:09,  2.17it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:09,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:09,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:06,  2.18it/s]Progress: 11.00%
---- avg training fps: 5.63# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]Progress: 13.00%
---- avg training fps: 6.06# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:17,  1.94it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:12,  2.00it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:09,  2.05it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:06,  2.09it/s]Progress: 15.00%
---- avg training fps: 6.32# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:04,  2.11it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:03,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:01,  2.15it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:01,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:59,  2.16it/s]Progress: 17.00%
---- avg training fps: 6.58# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.78# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:54,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:55,  1.43s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:42,  1.14s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:50,  1.07it/s]Progress: 21.00%
---- avg training fps: 6.30# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:14,  1.26it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:48,  1.44it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:31,  1.60it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:19,  1.74it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:10,  1.85it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.94it/s]Progress: 23.00%
---- avg training fps: 6.48# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:03,  1.94it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<01:59,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<02:10,  1.83it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<02:03,  1.92it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:58,  1.99it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<01:55,  2.04it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:54,  2.05it/s]Progress: 25.00%
---- avg training fps: 6.59# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:52,  2.06it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:50,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.72# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:45,  2.15it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:44,  2.15it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:44,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:45<01:43,  2.15it/s]Progress: 29.00%
---- avg training fps: 6.84# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:42,  2.16it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:40,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:40,  2.16it/s]Progress: 31.00%
---- avg training fps: 6.94# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:39,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:39,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 7.03# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:51<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:51<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:34,  2.16it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 7.11# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:33,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:59<04:38,  1.41s/it]Progress: 37.00%
---- avg training fps: 6.81# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<03:41,  1.13s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:00<03:01,  1.08it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<02:34,  1.26it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:01<02:14,  1.44it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:01<02:00,  1.60it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:02<01:50,  1.73it/s]Progress: 39.00%
---- avg training fps: 6.89# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:02<01:43,  1.84it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:03<01:38,  1.92it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:03<01:38,  1.92it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:03<01:35,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:04<01:32,  2.02it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:04<01:30,  2.06it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:05<01:29,  2.08it/s]Progress: 41.00%
---- avg training fps: 6.96# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:05<01:27,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:06<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:07<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 7.03# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:08<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:08<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:22,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:09<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:09<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:10<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:10<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.09# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:11<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:11<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:12<01:19,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:12<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:13<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.14# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:14<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:15<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:16<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.19# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:16<01:15,  2.13it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:17<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:17<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:17<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:18<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:18<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:19<01:13,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.24# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:19<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:20<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:20<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:21<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.28# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:22<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:22<01:11,  2.07it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:26<04:02,  1.64s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:27<03:08,  1.29s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:27<02:31,  1.04s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:28<02:06,  1.15it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:28<01:47,  1.33it/s]Progress: 55.00%
---- avg training fps: 7.00# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:29<01:35,  1.50it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:29<01:26,  1.65it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:30<01:19,  1.77it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:30<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:30<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:30<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:31<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 7.05# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:31<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:32<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:32<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:33<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:33<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:34<01:02,  2.11it/s]Progress: 59.00%
---- avg training fps: 7.09# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:34<01:01,  2.11it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:35<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:35<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:35<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:36<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:36<00:59,  2.12it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:37<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 7.13# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:37<00:59,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:38<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:38<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:38<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:39<00:56,  2.13it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:39<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 7.17# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:40<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:40<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:40<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:41<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:41<00:54,  2.13it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:42<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:42<00:53,  2.12it/s]Progress: 65.00%
---- avg training fps: 7.21# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:43<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:43<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:44<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:44<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:45<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:45<00:51,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:45<00:51,  2.11it/s]Progress: 67.00%
---- avg training fps: 7.24# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:46<00:50,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:46<00:50,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:46<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:47<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:47<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:48<00:48,  2.12it/s]Progress: 69.00%
---- avg training fps: 7.28# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:48<00:47,  2.12it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:49<00:46,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:53<02:34,  1.58s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:54<02:00,  1.25s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:54<01:37,  1.01s/it]Progress: 71.00%
---- avg training fps: 7.07# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:55<01:20,  1.18it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:55<01:09,  1.36it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:56<01:00,  1.53it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:56<00:55,  1.67it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:57<00:51,  1.78it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:57<00:48,  1.87it/s]Progress: 73.00%
---- avg training fps: 7.11# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:58<00:48,  1.87it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:58<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:58<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:59<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:59<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:00<00:40,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:00<00:40,  2.09it/s]Progress: 75.00%
---- avg training fps: 7.14# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:01<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:01<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:01<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:02<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:02<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:02<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:03<00:36,  2.12it/s]Progress: 77.00%
---- avg training fps: 7.17# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:03<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:04<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:04<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:05<00:34,  2.12it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:05<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:06<00:33,  2.13it/s]Progress: 79.00%
---- avg training fps: 7.20# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:06<00:33,  2.12it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:07<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:07<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:07<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:08<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:08<00:31,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:09<00:31,  2.11it/s]Progress: 81.00%
---- avg training fps: 7.23# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:09<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:09<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:10<00:29,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:10<00:29,  2.12it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:11<00:28,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:11<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.25# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:12<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:12<00:27,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:12<00:27,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:13<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:13<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:14<00:25,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:14<00:25,  2.12it/s]Progress: 85.00%
---- avg training fps: 7.28# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:15<00:25,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:15<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:16<00:24,  2.10it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:16<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:17<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:17<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:21<01:12,  1.52s/it]Progress: 87.00%
---- avg training fps: 7.11# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:21<01:00,  1.29s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:22<00:47,  1.04s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:22<00:38,  1.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:23<00:32,  1.34it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:23<00:28,  1.52it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:24<00:25,  1.66it/s]Progress: 89.00%
---- avg training fps: 7.14# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:24<00:22,  1.79it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:25<00:21,  1.87it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:25<00:21,  1.87it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:25<00:20,  1.95it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:25<00:19,  2.00it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:26<00:18,  2.04it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:26<00:17,  2.07it/s]Progress: 91.00%
---- avg training fps: 7.17# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:27<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:27<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:28<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:28<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:29<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:29<00:13,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.19# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:30<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:30<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:30<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:31<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:31<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:32<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:32<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.22# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:32<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:33<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:33<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:34<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:34<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:34<00:08,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:35<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.24# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:35<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:36<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:36<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:37<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:37<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:38<00:05,  2.14it/s]Progress: 99.00%
---- avg training fps: 7.27# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:38<00:05,  2.14it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:39<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:39<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:39<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:39<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:40<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:40<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.29# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:41<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:41<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:42<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:42<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:43<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:43<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.31Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.43it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.19it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.16it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.20it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.78it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.52it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.22it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:03<00:00,  1.23it/s]
------------------------------------------
Training done :)
2024-08-13 01:50:46.895412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 01:50:46.989922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 01:50:46.989950: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 01:50:47.008611: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 01:50:47.414189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:50:47.414273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:50:47.414283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23116 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_01-50-49-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723506649.2649713 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 51408.20it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.19it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  6.90it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.56it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.77it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_01-50-49-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 66788.28it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.63it/s] 20%|██        | 2/10 [00:00<00:02,  3.46it/s] 30%|███       | 3/10 [00:00<00:01,  4.13it/s] 40%|████      | 4/10 [00:01<00:01,  4.36it/s] 50%|█████     | 5/10 [00:01<00:01,  4.55it/s] 60%|██████    | 6/10 [00:01<00:00,  4.72it/s] 70%|███████   | 7/10 [00:01<00:00,  4.70it/s] 80%|████████  | 8/10 [00:01<00:00,  4.83it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.81it/s]100%|██████████| 10/10 [00:02<00:00,  4.97it/s]100%|██████████| 10/10 [00:02<00:00,  4.53it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, bold compositions

- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red cloak standing in front of a building.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a camel in front of a mountain.
- In the style of TOK: A man standing on top of a sandy beach next to the ocean.
- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red dress walking through an archway.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a dog on a leash.
- In the style of TOK: A person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, bold compositions
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 11104.86it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>: a sunset over a ...
1     in the style of <s0><s1><s2>: a woman in a red...
2     in the style of <s0><s1><s2>: a person standin...
3     in the style of <s0><s1><s2>: a person walking...
4     in the style of <s0><s1><s2>: a man standing o...
5     in the style of <s0><s1><s2>: a sunset over a ...
6     in the style of <s0><s1><s2>: a woman in a red...
7     in the style of <s0><s1><s2>: a person standin...
8     in the style of <s0><s1><s2>: a person walking...
9     in the style of <s0><s1><s2>: a person walking...
10    in the style of <s0><s1><s2>: a sunset over a ...
11    in the style of <s0><s1><s2>: a woman in a red...
12    in the style of <s0><s1><s2>: a person standin...
13    in the style of <s0><s1><s2>: a person walking...
14    in the style of <s0><s1><s2>: a man standing o...
15    in the style of <s0><s1><s2>: a sunset over a ...
16    in the style of <s0><s1><s2>: a woman in a red...
17    in the style of <s0><s1><s2>: a person standin...
18    in the style of <s0><s1><s2>: a person walking...
19    in the style of <s0><s1><s2>: a person walking...
20    in the style of <s0><s1><s2>: a sunset over a ...
21    in the style of <s0><s1><s2>: a woman in a red...
22    in the style of <s0><s1><s2>: a person standin...
23    in the style of <s0><s1><s2>: a person walking...
24    in the style of <s0><s1><s2>: a man standing o...
25    in the style of <s0><s1><s2>: a sunset over a ...
26    in the style of <s0><s1><s2>: a woman in a red...
27    in the style of <s0><s1><s2>: a person standin...
28    in the style of <s0><s1><s2>: a person walking...
29    in the style of <s0><s1><s2>: a person walking...
30    in the style of <s0><s1><s2>: a sunset over a ...
31    in the style of <s0><s1><s2>: a woman in a red...
32    in the style of <s0><s1><s2>: a person standin...
33    in the style of <s0><s1><s2>: a person walking...
34    in the style of <s0><s1><s2>: a man standing o...
35    in the style of <s0><s1><s2>: a sunset over a ...
36    in the style of <s0><s1><s2>: a woman in a red...
37    in the style of <s0><s1><s2>: a person standin...
38    in the style of <s0><s1><s2>: a person walking...
39    in the style of <s0><s1><s2>: a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:14,  3.06s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<20:07,  4.05s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:57,  2.41s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:05,  1.64s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:57,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:40,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.38# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:52,  1.26it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:20,  1.46it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:34,  1.87it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:28,  1.94it/s]Progress: 7.00%
---- avg training fps: 3.67# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:41,  1.78it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:25,  1.97it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.55# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:12,  2.12it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:08,  2.15it/s]Progress: 11.00%
---- avg training fps: 5.16# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:20<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.15it/s]Progress: 13.00%
---- avg training fps: 5.61# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:03,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:03,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:06,  2.09it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:05,  2.10it/s]Progress: 15.00%
---- avg training fps: 5.94# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:04,  2.11it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:03,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:26<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:26<02:01,  2.14it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<02:00,  2.13it/s]Progress: 17.00%
---- avg training fps: 6.21# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:27<02:00,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:59,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:59,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:57,  2.14it/s]Progress: 19.00%
---- avg training fps: 6.43# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:57,  2.14it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:35<06:39,  1.61s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:12,  1.27s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:12,  1.03s/it]Progress: 21.00%
---- avg training fps: 5.93# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:30,  1.16it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<03:01,  1.35it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:40,  1.51it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:25,  1.67it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.78it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.11# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:03,  1.94it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:59,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:40<01:56,  2.03it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:54,  2.06it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:41<01:52,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:51,  2.10it/s]Progress: 25.00%
---- avg training fps: 6.27# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:42<01:50,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:43<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:47,  2.12it/s]Progress: 27.00%
---- avg training fps: 6.41# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.54# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:48<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:49<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:50<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.65# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:38,  2.13it/s]Progress: 33.00%
---- avg training fps: 6.75# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:55<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.84# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:56<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:57<01:33,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:58<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:58<01:32,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:02<05:38,  1.71s/it]Progress: 37.00%
---- avg training fps: 6.47# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:03<04:23,  1.34s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:03<03:30,  1.08s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:04<02:54,  1.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:04<02:28,  1.30it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:04<02:10,  1.48it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:05<01:58,  1.62it/s]Progress: 39.00%
---- avg training fps: 6.56# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:05<01:48,  1.75it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:06<01:42,  1.85it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:06<01:42,  1.85it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:06<01:37,  1.93it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:07<01:34,  1.99it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:07<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:08<01:30,  2.06it/s]Progress: 41.00%
---- avg training fps: 6.64# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:08<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:09<01:27,  2.10it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:09<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:10<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:10<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:11<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 6.71# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:11<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:11<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:11<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:12<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:12<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:13<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:13<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 6.78# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:14<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:14<01:20,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:15<01:20,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:15<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:16<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:16<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:16<01:18,  2.14it/s]Progress: 47.00%
---- avg training fps: 6.85# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:17<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:17<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:18<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:18<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:18<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:19<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 6.91# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:19<01:15,  2.14it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:20<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:21<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:21<01:13,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:22<01:13,  2.13it/s]Progress: 51.00%
---- avg training fps: 6.96# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:22<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:23<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:23<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:24<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:24<01:10,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:25<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.01# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:25<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:25<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:30<04:14,  1.72s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:30<03:17,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:31<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:31<02:10,  1.11it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:32<01:50,  1.30it/s]Progress: 55.00%
---- avg training fps: 6.74# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:32<01:36,  1.48it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:33<01:27,  1.63it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:33<01:20,  1.76it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:33<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:34<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:34<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:34<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.80# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:35<01:07,  2.02it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:35<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:36<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:36<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:37<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:37<01:02,  2.12it/s]Progress: 59.00%
---- avg training fps: 6.85# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:38<01:01,  2.12it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:38<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:39<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:39<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:39<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:40<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:40<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 6.89# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:40<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:41<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:41<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:42<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:42<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 6.94# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:43<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:44<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:44<00:54,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:45<00:54,  2.13it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:45<00:53,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:46<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 6.98# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:46<00:53,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:47<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:47<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:48<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:48<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:48<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:48<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.02# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:49<00:50,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:49<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:50<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:50<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:51<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:51<00:47,  2.13it/s]Progress: 69.00%
---- avg training fps: 7.06# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:52<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:52<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:53<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:53<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:57<02:53,  1.77s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:58<02:14,  1.38s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:58<01:46,  1.11s/it]Progress: 71.00%
---- avg training fps: 6.83# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:59<01:27,  1.09it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:59<01:13,  1.28it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [02:00<01:03,  1.45it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [02:00<00:56,  1.61it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:01<00:52,  1.74it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:01<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 6.87# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:02<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:02<00:46,  1.92it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:02<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:03<00:43,  2.02it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:03<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:04<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:04<00:39,  2.10it/s]Progress: 75.00%
---- avg training fps: 6.91# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:05<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:05<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:05<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:07<00:36,  2.13it/s]Progress: 77.00%
---- avg training fps: 6.95# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:07<00:36,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:08<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:08<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:10<00:33,  2.13it/s]Progress: 79.00%
---- avg training fps: 6.98# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:10<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:11<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:11<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:11<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:12<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:12<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:12<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.01# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:13<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:13<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:14<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:14<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:15<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:15<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.05# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:16<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:16<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:16<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:17<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:17<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:18<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:18<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.08# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:19<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:19<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:20<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:20<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:20<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:20<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:25<01:18,  1.63s/it]Progress: 87.00%
---- avg training fps: 6.90# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:26<01:04,  1.37s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:26<00:50,  1.10s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:26<00:40,  1.10it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:27<00:34,  1.29it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:27<00:29,  1.47it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:28<00:25,  1.62it/s]Progress: 89.00%
---- avg training fps: 6.93# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:28<00:23,  1.76it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:29<00:20,  1.93it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:30<00:19,  2.00it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:30<00:18,  2.05it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:31<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 6.96# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:31<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:32<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:32<00:15,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:33<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:33<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:33<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 6.99# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:34<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:34<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:34<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:35<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:35<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:36<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:36<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.02# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:37<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:37<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:38<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:38<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:39<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:39<00:08,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:39<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.05# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:39<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:40<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:40<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:41<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:41<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:42<00:05,  2.14it/s]Progress: 99.00%
---- avg training fps: 7.08# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:42<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:44<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:44<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:45<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.10# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:45<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:46<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:46<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:46<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:47<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:47<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.13Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:08<00:00,  1.21it/s]
------------------------------------------
Training done :)
2024-08-13 01:55:23.328041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 01:55:23.419523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 01:55:23.419549: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 01:55:23.438423: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 01:55:23.841399: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:55:23.841483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:55:23.841493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23109 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_01-55-25-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723506925.6767387 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 138452.75it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.56it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.83it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.32it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.15it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_01-55-25-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 182361.04it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.62it/s] 20%|██        | 2/10 [00:00<00:02,  3.48it/s] 30%|███       | 3/10 [00:00<00:01,  4.18it/s] 40%|████      | 4/10 [00:00<00:01,  4.42it/s] 50%|█████     | 5/10 [00:01<00:01,  4.62it/s] 60%|██████    | 6/10 [00:01<00:00,  4.81it/s] 70%|███████   | 7/10 [00:01<00:00,  4.78it/s] 80%|████████  | 8/10 [00:01<00:00,  4.92it/s] 90%|█████████ | 9/10 [00:01<00:00,  4.91it/s]100%|██████████| 10/10 [00:02<00:00,  5.06it/s]100%|██████████| 10/10 [00:02<00:00,  4.60it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, bold contrasts

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
GPT-4 returned the wrong number of prompts 8 instead of 10, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Dreamy, surreal landscape with vivid colors.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Dreamy, surreal landscape with vivid colors.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10288.35it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:40,  2.95s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:29,  3.92s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:33,  2.34s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:50,  1.59s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:47,  1.18s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:33,  1.08it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.45# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:46,  1.29it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:15,  1.49it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:55,  1.66it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:41,  1.79it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:41,  1.79it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:31,  1.90it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:25,  1.98it/s]Progress: 7.00%
---- avg training fps: 3.78# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:37,  1.82it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:28,  1.92it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:23,  1.99it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:18,  2.05it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:14,  2.10it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:12,  2.13it/s]Progress: 9.00%
---- avg training fps: 4.66# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:10,  2.15it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:07,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:06,  2.18it/s]Progress: 11.00%
---- avg training fps: 5.28# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:04,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:04,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:03,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:03,  2.18it/s]Progress: 13.00%
---- avg training fps: 5.73# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:02,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:00,  2.19it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:00,  2.19it/s]Progress: 15.00%
---- avg training fps: 6.08# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:00,  2.19it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<01:58,  2.20it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<01:58,  2.20it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<01:58,  2.20it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<01:58,  2.20it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:57,  2.20it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:57,  2.19it/s]Progress: 17.00%
---- avg training fps: 6.37# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:56,  2.20it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<01:56,  2.20it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:56,  2.20it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:55,  2.19it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:55,  2.20it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:54,  2.19it/s]Progress: 19.00%
---- avg training fps: 6.59# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:54,  2.19it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:54,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:54,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:53,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:29,  1.57s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<05:04,  1.23s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:06,  1.00s/it]Progress: 21.00%
---- avg training fps: 6.07# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:25,  1.19it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:56,  1.38it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:36,  1.55it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:22,  1.70it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:12,  1.82it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:04,  1.92it/s]Progress: 23.00%
---- avg training fps: 6.26# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:04,  1.92it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:00,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<01:56,  2.05it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:53,  2.09it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:51,  2.12it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:50,  2.14it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:48,  2.15it/s]Progress: 25.00%
---- avg training fps: 6.43# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:47,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:47,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:46,  2.17it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:44,  2.18it/s]Progress: 27.00%
---- avg training fps: 6.57# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:44,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:42,  2.17it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:42,  2.18it/s]Progress: 29.00%
---- avg training fps: 6.70# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:41,  2.18it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:38,  2.18it/s]Progress: 31.00%
---- avg training fps: 6.81# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:38,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:36,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.91# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:35,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:35,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.00# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:30,  2.19it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.09# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:57<01:30,  2.18it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:30,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:58<01:29,  2.18it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:58<01:28,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:59<01:28,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:59<01:28,  2.17it/s]Progress: 39.00%
---- avg training fps: 7.16# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:28,  2.17it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:00<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:01<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:26,  2.16it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:02<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 7.23# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:25,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:03<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:04<01:23,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:04<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:05<01:23,  2.16it/s]Progress: 43.00%
---- avg training fps: 7.29# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:05<01:23,  2.16it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:05<01:22,  2.16it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:06<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:06<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:07<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:07<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:19,  2.18it/s]Progress: 45.00%
---- avg training fps: 7.34# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:08<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:09<01:19,  2.16it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:10<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:10<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:10<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.39# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:11<01:17,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:11<01:18,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:12<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:12<01:18,  2.09it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:13<01:18,  2.08it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:13<01:17,  2.08it/s]Progress: 49.00%
---- avg training fps: 7.43# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:14<01:16,  2.09it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:14<01:16,  2.10it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:15<01:16,  2.10it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:15<01:15,  2.10it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:15<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:16<01:13,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:16<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 7.47# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:17<01:11,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:11,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:18<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:18<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:19<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.51# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:19<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:19<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:24<04:11,  1.70s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:24<03:15,  1.33s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:25<02:36,  1.07s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:25<02:08,  1.13it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:49,  1.32it/s]Progress: 55.00%
---- avg training fps: 7.19# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:26<01:35,  1.50it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:25,  1.65it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:27<01:19,  1.78it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:14,  1.88it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:28<01:14,  1.88it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:28<01:11,  1.96it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.24# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:29<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:30<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:30<01:03,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:31<01:02,  2.14it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:31<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.28# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:00,  2.16it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:32<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:33<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:34<00:58,  2.16it/s]Progress: 61.00%
---- avg training fps: 7.32# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:35<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:36<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:36<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:37<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.36# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:37<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:37<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:38<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:39<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:53,  2.15it/s]Progress: 65.00%
---- avg training fps: 7.39# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:40<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:41<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:42<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:42<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:42<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:42<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.42# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:43<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:43<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:44<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:44<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:45<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:45<00:48,  2.12it/s]Progress: 69.00%
---- avg training fps: 7.45# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:46<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:51<02:51,  1.75s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:52<02:12,  1.36s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:52<01:44,  1.09s/it]Progress: 71.00%
---- avg training fps: 7.20# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:25,  1.11it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:53<01:12,  1.30it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<01:02,  1.48it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:54<00:56,  1.64it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:51,  1.77it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:55<00:48,  1.87it/s]Progress: 73.00%
---- avg training fps: 7.24# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:48,  1.87it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:56<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:57<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:57<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:39,  2.12it/s]Progress: 75.00%
---- avg training fps: 7.27# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:58<00:39,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:59<00:37,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:00<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:01<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.30# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:01<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:02<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:02<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:03<00:33,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:03<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.33# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:33,  2.15it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:04<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:05<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:06<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:06<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.36# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:07<00:30,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:07<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:08<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:08<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:09<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:09<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.38# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:10<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:10<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:10<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:10<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:11<00:25,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:12<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.41# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:12<00:24,  2.15it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:13<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:13<00:23,  2.17it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:14<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:14<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:14<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:15<00:22,  2.17it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.43# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:15<00:21,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:16<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:16<00:20,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:16<00:20,  2.17it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:17<00:19,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:17<00:19,  2.16it/s]Progress: 89.00%
---- avg training fps: 7.46# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:18<00:19,  2.15it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:18<00:18,  2.17it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:19<00:18,  2.17it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:19<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:19<00:20,  1.90it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:20<00:18,  1.97it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:20<00:17,  2.03it/s]Progress: 91.00%
---- avg training fps: 7.47# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:21<00:16,  2.06it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:21<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:22<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:22<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:23<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:23<00:13,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.49# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:24<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:24<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:24<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:25<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:25<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:25<00:11,  2.17it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:26<00:11,  2.17it/s]Progress: 95.00%
---- avg training fps: 7.52# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:26<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:27<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:27<00:09,  2.17it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:28<00:08,  2.17it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:29<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.54# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:29<00:07,  2.17it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:30<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:30<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:31<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:31<00:05,  2.17it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:31<00:05,  2.17it/s]Progress: 99.00%
---- avg training fps: 7.56# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:32<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:32<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:33<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:33<00:04,  2.18it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:33<00:03,  2.17it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:34<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:34<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.58# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:35<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:35<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:36<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:36<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:37<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:37<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.59Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.01it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.48it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.31it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.79it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.23it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.23it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.24it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:58<00:00,  1.26it/s]
------------------------------------------
Training done :)
2024-08-13 01:59:50.783651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 01:59:50.874995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 01:59:50.875023: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 01:59:50.894102: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 01:59:51.295489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:59:51.295570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 01:59:51.295580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23116 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_01-59-53-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723507193.1146789 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 43744.27it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 18.10it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.78it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.72it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.03it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_01-59-53-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_01-59-53-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 428962.91it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 534180.23it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a Tarsem Singh-like flair.
- In the style of TOK, a brigade of beavers resembles M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above water.

--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15327.36it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two individuals ...
12    in the style of <s0><s1><s2>, petroglyphs are ...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, trypophobia is v...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is show...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain is ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are pooping...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two individuals ...
39    in the style of <s0><s1><s2>, petroglyphs are ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:49,  2.98s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:49,  4.40s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:50,  2.59s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:37,  1.75s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:17,  1.28s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:53,  1.00it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.26# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:00,  1.22it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:25,  1.42it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:01,  1.60it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:45,  1.75it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:35,  1.86it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:27,  1.96it/s]Progress: 7.00%
---- avg training fps: 3.60# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:21,  2.03it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:17,  2.08it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:17,  2.08it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:25,  1.96it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:16,  2.08it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:13,  2.12it/s]Progress: 9.00%
---- avg training fps: 4.45# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:11,  2.14it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:09,  2.16it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:08,  2.17it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:07,  2.18it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:06,  2.19it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:05,  2.19it/s]Progress: 11.00%
---- avg training fps: 5.08# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:05,  2.19it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:04,  2.20it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:03,  2.20it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:03,  2.20it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:03,  2.20it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:58,  2.29it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<01:59,  2.26it/s]Progress: 13.00%
---- avg training fps: 5.56# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<02:00,  2.23it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:00,  2.22it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<02:00,  2.21it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<02:00,  2.20it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:00,  2.19it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<02:00,  2.19it/s]Progress: 15.00%
---- avg training fps: 5.92# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:00,  2.19it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:59,  2.18it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<01:59,  2.18it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<01:59,  2.18it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<01:59,  2.17it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:58,  2.18it/s]Progress: 17.00%
---- avg training fps: 6.21# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:58,  2.18it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:53,  2.26it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:54,  2.23it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:55,  2.21it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:55,  2.19it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:55,  2.20it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:54,  2.19it/s]Progress: 19.00%
---- avg training fps: 6.44# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:55,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:54,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:54,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:39,  1.37s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:30,  1.09s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:42,  1.11it/s]Progress: 21.00%
---- avg training fps: 6.07# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:08,  1.30it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:45,  1.48it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:45,  1.48it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:24,  1.68it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:14,  1.80it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:07,  1.89it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:02,  1.96it/s]Progress: 23.00%
---- avg training fps: 6.27# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:58,  2.02it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:55,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:53,  2.08it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<02:11,  1.79it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<02:04,  1.89it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:58,  1.97it/s]Progress: 25.00%
---- avg training fps: 6.38# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:41<01:54,  2.03it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:52,  2.06it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:42<01:50,  2.09it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:49,  2.11it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:43<01:49,  2.11it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:43<01:44,  2.20it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:44,  2.19it/s]Progress: 27.00%
---- avg training fps: 6.53# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:44<01:44,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:45<01:43,  2.17it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:46<01:42,  2.17it/s]Progress: 29.00%
---- avg training fps: 6.66# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:41,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:47<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:40,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:40,  2.17it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:40,  2.17it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:49<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 6.78# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:39,  2.17it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:35,  2.26it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:50<01:35,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:37,  2.19it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:36,  2.19it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.88# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:52<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:53<01:34,  2.18it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:54<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:33,  2.17it/s]Progress: 35.00%
---- avg training fps: 6.97# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:55<01:33,  2.18it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:32,  2.17it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:32,  2.17it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:28,  2.26it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:29,  2.23it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:29,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:55,  1.19s/it]Progress: 37.00%
---- avg training fps: 6.77# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [01:00<03:11,  1.03it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:40,  1.22it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:01<02:18,  1.41it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<02:03,  1.57it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:02<01:52,  1.71it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:45,  1.82it/s]Progress: 39.00%
---- avg training fps: 6.86# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:03<01:39,  1.92it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:03<01:35,  1.99it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:32,  2.03it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:04<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:25,  2.18it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:05<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 6.94# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:25,  2.17it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:06<01:25,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:07<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:23,  2.17it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:08<01:23,  2.16it/s]Progress: 43.00%
---- avg training fps: 7.01# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:23,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:22,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:09<01:31,  1.94it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:10<01:27,  2.00it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:10<01:25,  2.04it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:11<01:24,  2.07it/s]Progress: 45.00%
---- avg training fps: 7.06# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:11<01:24,  2.07it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:11<01:19,  2.18it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:18,  2.18it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:13<01:17,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.18it/s]Progress: 47.00%
---- avg training fps: 7.12# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:14<01:16,  2.18it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:16,  2.17it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:15<01:16,  2.17it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:15<01:15,  2.18it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:16<01:15,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:16<01:14,  2.16it/s]Progress: 49.00%
---- avg training fps: 7.17# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:14,  2.16it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:17<01:13,  2.16it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:13,  2.16it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:10,  2.25it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:18<01:11,  2.22it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:19<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.23# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:10,  2.19it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:20<01:10,  2.18it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:10,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:21<01:10,  2.16it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:09,  2.16it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.28# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:09,  2.16it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:27<04:30,  1.82s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:27<03:28,  1.42s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:28<02:45,  1.13s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:28<02:45,  1.13s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:28<02:12,  1.10it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:29<01:52,  1.28it/s]Progress: 55.00%
---- avg training fps: 6.96# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:29<01:37,  1.46it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:30<01:27,  1.62it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:30<01:20,  1.75it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:31<01:15,  1.86it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:31<01:11,  1.94it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:32<01:08,  2.00it/s]Progress: 57.00%
---- avg training fps: 7.01# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:32<01:06,  2.05it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:32<01:05,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:33<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:33<01:03,  2.13it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:34<01:02,  2.14it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:34<01:01,  2.15it/s]Progress: 59.00%
---- avg training fps: 7.06# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:35<01:01,  2.15it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:35<00:58,  2.24it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:35<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:36<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:36<00:58,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:37<00:58,  2.16it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:37<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.10# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:37<00:58,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:38<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:38<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:39<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:39<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:40<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.14# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:40<00:55,  2.14it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:41<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:41<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:41<00:52,  2.23it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:42<00:52,  2.20it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:42<00:52,  2.19it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:43<00:52,  2.18it/s]Progress: 65.00%
---- avg training fps: 7.19# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:43<00:52,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:43<00:52,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:44<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:44<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:45<00:50,  2.15it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:45<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.22# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:46<00:49,  2.14it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:46<00:49,  2.14it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:47<00:49,  2.13it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:47<00:48,  2.15it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:48<00:48,  2.15it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:48<00:46,  2.23it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:48<00:46,  2.20it/s]Progress: 69.00%
---- avg training fps: 7.26# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:49<00:46,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:49<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:49<00:45,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:52<01:58,  1.21s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:53<01:35,  1.01it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:53<01:19,  1.21it/s]Progress: 71.00%
---- avg training fps: 7.12# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:54<01:16,  1.24it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:55<01:05,  1.43it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:55<00:58,  1.59it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:56<00:53,  1.73it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:56<00:49,  1.84it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:56<00:46,  1.93it/s]Progress: 73.00%
---- avg training fps: 7.16# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:57<00:46,  1.93it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:57<00:43,  2.07it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:57<00:41,  2.10it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:58<00:41,  2.12it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:58<00:40,  2.13it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:59<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:59<00:39,  2.15it/s]Progress: 75.00%
---- avg training fps: 7.19# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [02:00<00:38,  2.16it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [02:00<00:38,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:01<00:37,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:01<00:36,  2.16it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:01<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:02<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.23# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:02<00:35,  2.16it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:03<00:35,  2.16it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:03<00:35,  2.16it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:03<00:33,  2.25it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:04<00:33,  2.22it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:04<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:05<00:32,  2.18it/s]Progress: 79.00%
---- avg training fps: 7.26# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:05<00:32,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:06<00:32,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:06<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:06<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:07<00:31,  2.15it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:07<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.29# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:08<00:30,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:08<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:09<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:09<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:10<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:10<00:27,  2.24it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:10<00:27,  2.21it/s]Progress: 83.00%
---- avg training fps: 7.32# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:11<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:11<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:12<00:26,  2.16it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:12<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:12<00:25,  2.15it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:13<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.35# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:13<00:24,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:14<00:24,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:14<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:15<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:15<00:22,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:19<01:09,  1.45s/it]Progress: 87.00%
---- avg training fps: 7.20# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:19<01:09,  1.45s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:19<00:53,  1.14s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:20<00:43,  1.06it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:20<00:35,  1.25it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:21<00:30,  1.43it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:21<00:26,  1.59it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:22<00:24,  1.73it/s]Progress: 89.00%
---- avg training fps: 7.23# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:22<00:22,  1.84it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:23<00:20,  1.92it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:23<00:19,  1.99it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:24<00:18,  2.03it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:24<00:17,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:25<00:17,  2.09it/s]Progress: 91.00%
---- avg training fps: 7.26# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:25<00:16,  2.11it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:25<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:26<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:26<00:14,  2.21it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:26<00:14,  2.17it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:27<00:14,  2.17it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:27<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.28# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:28<00:13,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:28<00:13,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:29<00:12,  2.14it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:29<00:12,  2.14it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:30<00:11,  2.14it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:30<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.31# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:31<00:10,  2.13it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:31<00:10,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:32<00:09,  2.13it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:32<00:09,  2.13it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:32<00:09,  2.13it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:32<00:08,  2.22it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:33<00:08,  2.20it/s]Progress: 97.00%
---- avg training fps: 7.33# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:33<00:07,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:34<00:07,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:34<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:35<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:35<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:36<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.35# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:36<00:05,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:37<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:37<00:04,  2.14it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:38<00:03,  2.14it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:38<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:38<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.38# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:39<00:02,  2.14it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:39<00:02,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:39<00:01,  2.20it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:40<00:01,  2.17it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:40<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:41<00:00,  2.15it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:41<00:00,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.40# Trainer step: 294, epoch: 21: : 301it [02:42,  2.15it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.12it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.51it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.48it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.47it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.45it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.44it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.43it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.41it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.40it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.39it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.37it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:05,  1.23it/s]
------------------------------------------
Training done :)
2024-08-13 02:04:51.883372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:04:51.976011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:04:51.976038: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:04:51.995071: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:04:52.393460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:04:52.393543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:04:52.393553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23112 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_02-04-54-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723507494.217606 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 127554.86it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 14.02it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  6.71it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.66it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.86it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_02-04-54-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.37it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.30it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.59it/s] 20%|██        | 2/10 [00:00<00:01,  4.51it/s] 30%|███       | 3/10 [00:00<00:01,  4.80it/s] 40%|████      | 4/10 [00:00<00:01,  4.72it/s] 50%|█████     | 5/10 [00:01<00:01,  4.76it/s] 60%|██████    | 6/10 [00:01<00:00,  4.82it/s] 70%|███████   | 7/10 [00:01<00:00,  5.06it/s] 80%|████████  | 8/10 [00:01<00:00,  5.16it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.15it/s]100%|██████████| 10/10 [00:02<00:00,  4.99it/s]100%|██████████| 10/10 [00:02<00:00,  4.87it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal blending of nature and technology

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal blending of nature and technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7468.49it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:49,  2.98s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:25,  3.31s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:55,  2.00s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:52,  1.39s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:11,  1.05s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:10,  1.17it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.73# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:32,  1.38it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:06,  1.56it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:49,  1.72it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:38,  1.83it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:38,  1.83it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:29,  1.93it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:23,  2.00it/s]Progress: 7.00%
---- avg training fps: 4.16# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:17,  2.07it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:15,  2.10it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:14,  2.12it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:13,  2.13it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:12,  2.13it/s]Progress: 9.00%
---- avg training fps: 5.03# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:10,  2.15it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:07,  2.16it/s]Progress: 11.00%
---- avg training fps: 5.61# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:05,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:05,  2.16it/s]Progress: 13.00%
---- avg training fps: 6.03# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:05,  2.16it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:03,  2.16it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:02,  2.16it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 6.30# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:16,  1.92it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:10,  2.00it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:07,  2.04it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:05,  2.07it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:05,  2.07it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:03,  2.10it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:01,  2.13it/s]Progress: 17.00%
---- avg training fps: 6.55# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<01:59,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:57,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:57,  2.15it/s]Progress: 19.00%
---- avg training fps: 6.76# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:44,  1.39s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:34,  1.11s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:45,  1.09it/s]Progress: 21.00%
---- avg training fps: 6.30# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:11,  1.28it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:47,  1.45it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:30,  1.61it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:18,  1.74it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:10,  1.85it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:04,  1.93it/s]Progress: 23.00%
---- avg training fps: 6.47# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:04,  1.93it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<01:59,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:56,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:54,  2.08it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:52,  2.10it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:51,  2.11it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:50,  2.12it/s]Progress: 25.00%
---- avg training fps: 6.62# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:49,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:48,  2.15it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:47,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:46,  2.14it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:59,  1.90it/s]Progress: 27.00%
---- avg training fps: 6.72# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:55,  1.97it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:51,  2.02it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:49,  2.06it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:47,  2.08it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:45,  2.11it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:45<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.84# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:40,  2.17it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 6.94# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:39,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:38,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:38,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:37,  2.16it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:37,  2.16it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 7.04# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:51<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:51<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:34,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:34,  2.17it/s]Progress: 35.00%
---- avg training fps: 7.12# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:33,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:56<01:31,  2.15it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.19# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:56<01:31,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:57<01:30,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:57<01:30,  2.15it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:58<01:30,  2.15it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:58<01:29,  2.15it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:59<01:29,  2.15it/s]Progress: 39.00%
---- avg training fps: 7.26# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [00:59<01:29,  2.15it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [00:59<01:28,  2.15it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:00<01:28,  2.15it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:00<01:27,  2.15it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:00<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:01<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:01<01:26,  2.15it/s]Progress: 41.00%
---- avg training fps: 7.32# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:02<01:26,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:02<01:25,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:03<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:03<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:04<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:04<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 7.37# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:05<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:05<01:23,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:05<01:22,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:06<01:22,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:06<01:21,  2.15it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:06<01:21,  2.15it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:07<01:21,  2.15it/s]Progress: 45.00%
---- avg training fps: 7.42# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:07<01:20,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:08<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:08<01:19,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:09<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:09<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:09<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:10<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.47# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:10<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:11<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:11<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:12<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:12<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:13<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.51# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:13<01:15,  2.15it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:13<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:14<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:14<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:14<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:15<01:13,  2.15it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:15<01:12,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.55# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:16<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:16<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:17<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:17<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:18<01:10,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:18<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.59# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:19<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:19<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:23<03:48,  1.54s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:23<02:59,  1.22s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:24<02:24,  1.01it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:24<02:00,  1.20it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:24<01:43,  1.39it/s]Progress: 55.00%
---- avg training fps: 7.30# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:25<01:32,  1.55it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:25<01:23,  1.70it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:26<01:17,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:26<01:13,  1.91it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:27<01:13,  1.91it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:27<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:27<01:08,  2.03it/s]Progress: 57.00%
---- avg training fps: 7.34# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:28<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:28<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:29<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:29<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:30<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:30<01:01,  2.13it/s]Progress: 59.00%
---- avg training fps: 7.38# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:31<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:31<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:31<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:31<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:32<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:32<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:33<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.42# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:33<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:34<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:34<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:35<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:35<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:36<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.45# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:36<00:56,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:36<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:37<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:37<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:38<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:38<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:38<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.48# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:39<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:39<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:40<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:40<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:41<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:41<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:41<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.51# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:42<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:42<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:43<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:43<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:44<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:44<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.54# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:45<00:46,  2.15it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:45<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:45<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:45<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:49<02:27,  1.51s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:50<01:55,  1.19s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:50<01:33,  1.03it/s]Progress: 71.00%
---- avg training fps: 7.33# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:51<01:17,  1.22it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:51<01:06,  1.40it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:52<00:59,  1.58it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:52<00:53,  1.71it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:53<00:49,  1.83it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:53<00:46,  1.92it/s]Progress: 73.00%
---- avg training fps: 7.37# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:54<00:46,  1.92it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:54<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:54<00:43,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:54<00:42,  2.06it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:55<00:41,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:55<00:40,  2.11it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:56<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.40# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:56<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:57<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:57<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:58<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [01:58<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [01:58<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [01:59<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.42# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [01:59<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:00<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:00<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:01<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:01<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:01<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.45# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:02<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:02<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:03<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:03<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:03<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:04<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:04<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.47# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:05<00:30,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:05<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:06<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:06<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:07<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:07<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.50# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:08<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:08<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:08<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:08<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:09<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:09<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:10<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.52# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:10<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:11<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:11<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:12<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:12<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:12<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:13<00:22,  2.13it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.54# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:13<00:22,  2.13it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:14<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:14<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:15<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:15<00:20,  2.13it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:15<00:19,  2.14it/s]Progress: 89.00%
---- avg training fps: 7.56# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:16<00:19,  2.13it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:16<00:18,  2.13it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:17<00:18,  2.13it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:17<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:17<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:18<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:18<00:16,  2.13it/s]Progress: 91.00%
---- avg training fps: 7.58# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:19<00:16,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:19<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:20<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:20<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:21<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:21<00:14,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.60# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:22<00:14,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:22<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:22<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:23<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:23<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:23<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:24<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.62# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:24<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:25<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:25<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:26<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:26<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:26<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:27<00:08,  2.14it/s]Progress: 97.00%
---- avg training fps: 7.64# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:27<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:28<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:28<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:29<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:29<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:30<00:05,  2.13it/s]Progress: 99.00%
---- avg training fps: 7.65# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:30<00:05,  2.14it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:30<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:31<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:31<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:31<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:32<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:32<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.67# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:33<00:02,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:33<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:34<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:34<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:35<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:35<00:00,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.69Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.78it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.23it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.23it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.79it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.52it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:56<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 02:09:20.532324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:09:20.626535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:09:20.626572: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:09:20.645332: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:09:21.052725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:09:21.052807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:09:21.052817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23108 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_02-09-22-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723507762.8702936 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 17001.23it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00,  9.95it/s]Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  5.44it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.90it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.85it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_02-09-22-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 114598.47it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.61it/s] 20%|██        | 2/10 [00:00<00:02,  3.44it/s] 30%|███       | 3/10 [00:00<00:01,  4.11it/s] 40%|████      | 4/10 [00:01<00:01,  4.33it/s] 50%|█████     | 5/10 [00:01<00:01,  4.52it/s] 60%|██████    | 6/10 [00:01<00:00,  4.71it/s] 70%|███████   | 7/10 [00:01<00:00,  4.69it/s] 80%|████████  | 8/10 [00:01<00:00,  4.83it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.82it/s]100%|██████████| 10/10 [00:02<00:00,  4.96it/s]100%|██████████| 10/10 [00:02<00:00,  4.52it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, bold compositions.

- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red cloak standing in front of a building.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a camel in front of a mountain.
- In the style of TOK: A man standing on top of a sandy beach next to the ocean.
- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red dress walking through an archway.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a dog on a leash.
- In the style of TOK: A person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, bold compositions.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 9978.12it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>: a sunset over a ...
1     in the style of <s0><s1><s2>: a woman in a red...
2     in the style of <s0><s1><s2>: a person standin...
3     in the style of <s0><s1><s2>: a person walking...
4     in the style of <s0><s1><s2>: a man standing o...
5     in the style of <s0><s1><s2>: a sunset over a ...
6     in the style of <s0><s1><s2>: a woman in a red...
7     in the style of <s0><s1><s2>: a person standin...
8     in the style of <s0><s1><s2>: a person walking...
9     in the style of <s0><s1><s2>: a person walking...
10    in the style of <s0><s1><s2>: a sunset over a ...
11    in the style of <s0><s1><s2>: a woman in a red...
12    in the style of <s0><s1><s2>: a person standin...
13    in the style of <s0><s1><s2>: a person walking...
14    in the style of <s0><s1><s2>: a man standing o...
15    in the style of <s0><s1><s2>: a sunset over a ...
16    in the style of <s0><s1><s2>: a woman in a red...
17    in the style of <s0><s1><s2>: a person standin...
18    in the style of <s0><s1><s2>: a person walking...
19    in the style of <s0><s1><s2>: a person walking...
20    in the style of <s0><s1><s2>: a sunset over a ...
21    in the style of <s0><s1><s2>: a woman in a red...
22    in the style of <s0><s1><s2>: a person standin...
23    in the style of <s0><s1><s2>: a person walking...
24    in the style of <s0><s1><s2>: a man standing o...
25    in the style of <s0><s1><s2>: a sunset over a ...
26    in the style of <s0><s1><s2>: a woman in a red...
27    in the style of <s0><s1><s2>: a person standin...
28    in the style of <s0><s1><s2>: a person walking...
29    in the style of <s0><s1><s2>: a person walking...
30    in the style of <s0><s1><s2>: a sunset over a ...
31    in the style of <s0><s1><s2>: a woman in a red...
32    in the style of <s0><s1><s2>: a person standin...
33    in the style of <s0><s1><s2>: a person walking...
34    in the style of <s0><s1><s2>: a man standing o...
35    in the style of <s0><s1><s2>: a sunset over a ...
36    in the style of <s0><s1><s2>: a woman in a red...
37    in the style of <s0><s1><s2>: a person standin...
38    in the style of <s0><s1><s2>: a person walking...
39    in the style of <s0><s1><s2>: a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:08,  3.04s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:57,  4.02s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:51,  2.40s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:02,  1.63s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:55,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:39,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.39# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:51,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:19,  1.46it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.76it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:44,  1.76it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:34,  1.87it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:28,  1.94it/s]Progress: 7.00%
---- avg training fps: 3.69# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:40,  1.79it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:25,  1.96it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.56# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:07,  2.16it/s]Progress: 11.00%
---- avg training fps: 5.18# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.16it/s]Progress: 13.00%
---- avg training fps: 5.63# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.16it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:04,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:01,  2.16it/s]Progress: 15.00%
---- avg training fps: 5.98# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:58,  2.18it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.26# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.48# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:55,  2.17it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:33,  1.59s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:08,  1.25s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:09,  1.01s/it]Progress: 21.00%
---- avg training fps: 5.98# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:27,  1.18it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:58,  1.36it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:38,  1.53it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:24,  1.67it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:14,  1.79it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]Progress: 23.00%
---- avg training fps: 6.16# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:02,  1.95it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.01it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:55,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:53,  2.08it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:51,  2.11it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:50,  2.12it/s]Progress: 25.00%
---- avg training fps: 6.33# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:47,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.47# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:44,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.15it/s]Progress: 29.00%
---- avg training fps: 6.59# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:40,  2.15it/s]Progress: 31.00%
---- avg training fps: 6.71# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:39,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:39,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:38,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:37,  2.16it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 6.81# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.90# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:34,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:33,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:33,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:31,  2.16it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 6.98# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<01:31,  2.15it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:00<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:29,  2.14it/s]Progress: 39.00%
---- avg training fps: 7.05# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:01<01:29,  2.14it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:29,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:02<01:29,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:02<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:28,  2.13it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:03<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:26,  2.14it/s]Progress: 41.00%
---- avg training fps: 7.12# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:26,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:05<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:06<01:24,  2.14it/s]Progress: 43.00%
---- avg training fps: 7.18# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:24,  2.14it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:07<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:08<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:09<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.23# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:19,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:11<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:11<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:17,  2.15it/s]Progress: 47.00%
---- avg training fps: 7.28# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:13<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:14<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:16,  2.13it/s]Progress: 49.00%
---- avg training fps: 7.33# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:15,  2.14it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:16<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:13,  2.13it/s]Progress: 51.00%
---- avg training fps: 7.37# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:18<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:19<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:10,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:20<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.42# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:09,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<04:14,  1.72s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<03:17,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:26<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<02:09,  1.12it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:27<01:50,  1.31it/s]Progress: 55.00%
---- avg training fps: 7.10# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:36,  1.48it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:28<01:26,  1.64it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:19,  1.77it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:29<01:15,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:15,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:11,  1.94it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:30<01:09,  2.00it/s]Progress: 57.00%
---- avg training fps: 7.15# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:31<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:32<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:02,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:02,  2.13it/s]Progress: 59.00%
---- avg training fps: 7.19# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:33<01:01,  2.13it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:35<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.23# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:36<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:37<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:38<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.27# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:39<00:56,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:39<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:39<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:40<00:54,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:40<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:53,  2.13it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:41<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.30# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:53,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:42<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.34# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:50,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:45<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:46<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:46<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:47<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.37# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:47<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:48<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:53<02:54,  1.78s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:53<02:14,  1.39s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:54<01:46,  1.11s/it]Progress: 71.00%
---- avg training fps: 7.12# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:54<01:27,  1.09it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:55<01:13,  1.28it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:55<01:03,  1.46it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:56<00:57,  1.61it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:56<00:52,  1.75it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 7.15# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:57<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:57<00:46,  1.93it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:58<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:59<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:59<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.18# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:00<00:39,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:00<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:01<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:01<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:02<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:02<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:02<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.22# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:03<00:36,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:03<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:04<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:05<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.25# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:05<00:33,  2.15it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:07<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:07<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:08<00:30,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.27# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:08<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:09<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:09<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:10<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:10<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:11<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.30# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:11<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:11<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:12<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:12<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:13<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:13<00:25,  2.12it/s]Progress: 85.00%
---- avg training fps: 7.33# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:14<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:14<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:15<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:15<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:16<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:16<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:16<00:22,  2.13it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.35# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:17<00:21,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:17<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:18<00:21,  2.13it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:18<00:20,  2.13it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:19<00:20,  2.13it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:19<00:19,  2.13it/s]Progress: 89.00%
---- avg training fps: 7.37# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:19<00:19,  2.13it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:20<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:20<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:20<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:21<00:17,  2.13it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:21<00:17,  2.13it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:22<00:16,  2.14it/s]Progress: 91.00%
---- avg training fps: 7.40# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:22<00:16,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:23<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:23<00:15,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:24<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:24<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:25<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.42# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:25<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:25<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:26<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:26<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:26<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:27<00:11,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:27<00:11,  2.12it/s]Progress: 95.00%
---- avg training fps: 7.44# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:28<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:28<00:10,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:29<00:09,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:29<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:30<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:30<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:30<00:09,  1.86it/s]Progress: 97.00%
---- avg training fps: 7.45# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:31<00:08,  1.94it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:31<00:08,  1.99it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:32<00:07,  2.03it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:32<00:06,  2.06it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:33<00:06,  2.09it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:33<00:05,  2.10it/s]Progress: 99.00%
---- avg training fps: 7.47# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:34<00:05,  2.11it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:34<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:35<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:35<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:35<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:36<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:36<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.49# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:37<00:02,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:37<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:38<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:38<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:38<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:39<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.51Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.79it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.25it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.52it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.30it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.23it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:00<00:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 02:13:48.510854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:13:48.602404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:13:48.602431: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:13:48.621198: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:13:49.024119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:13:49.024207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:13:49.024216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23103 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_02-13-50-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723508030.8450646 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 6136.77it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.26it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.56it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.81it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.09it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_02-13-50-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_02-13-50-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 469901.28it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 791931.52it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam as envisioned by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted in M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
--------------------------
GPT-4 returned the wrong number of prompts 26 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals consider quitting their boring corporation job together.
- In the style of TOK, petroglyphs are illustrated.
- In the style of TOK, a room and space exchange is depicted based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from waste materials swims underwater.
- In the style of TOK, small Lilliputians gather inside a giant sea-sponge.
- In the style of TOK, a view of Fort Kochi in Kerala, India.
- In the style of TOK, an ambiguous scenario reflecting the dual nature of times.
- In the style of TOK, a chain formation made of bees.
- In the style of TOK, a gorgon made of self-consuming sharks in the ocean.
- In the style of TOK, Venus and Earth orbit the sun above a sunset hillside.
- In the style of TOK, an ancient temple located deep within the Amazon jungle.
- In the style of TOK, cats are seen defecating in zero-gravity conditions.
- In the style of TOK, an odd-looking goblin goat.
- In the style of TOK, a contradictory phrase depicting wisdom and foolishness.
- In the style of TOK, an invitation to resign from a corporate job together.
- In the style of TOK, ancient rock carvings (petroglyphs).
- In the style of TOK, room and space exchanged through personal connections.
- In the style of TOK, a pattern inducing trypophobia.
- In the style of TOK, six terrifying images.
- In the style of TOK, a group of beavers performing musically.
- In the style of TOK, a beaver gnaws a rifle in half.
- In the style of TOK, beavers rapidly constructing a dam in a Hawaiian shirt pattern.
- In the style of TOK, beavers rapidly constructing a dam in a Tarsem Singh film style.
- In the style of TOK, beavers in an M.C. Escher-like composition.
- In the style of TOK, a moving castle traverses grassy hills.
- In the style of TOK, a line of beavers performing a dance routine.
- In the style of TOK, a 1950s kitchen, frozen and discovered during the space age.
- In the style of TOK, a fashion show with elephant seal models and egret spectators.
- In the style of TOK, highly detailed lemon-lime-colored architecture.
- In the style of TOK, a mermaid made from sea trash swims up to the water’s surface.
- In the style of TOK, a mermaid crafted from waste materials swims underwater.
- In the style of TOK, small Lilliputians gather inside a giant sea-sponge.
- In the style of TOK, a view of Fort Kochi in Kerala, India.
- In the style of TOK, an ambiguous scenario reflecting the dual nature of times.
- In the style of TOK, a chain formation made of bees.
- In the style of TOK, a gorgon made of self-consuming sharks in the ocean.
- In the style of TOK, Venus and Earth orbit the sun above a sunset hillside.
- In the style of TOK, an ancient temple located deep within the Amazon jungle.
- In the style of TOK, cats are seen defecating in zero-gravity conditions.
- In the style of TOK, an odd-looking goblin goat.
- In the style of TOK, a contradictory phrase depicting wisdom and foolishness.
- In the style of TOK, an invitation to resign from a corporate job together.
- In the style of TOK, ancient rock carvings (petroglyphs).
- In the style of TOK, room and space exchanged through personal connections.
- In the style of TOK, a pattern inducing trypophobia.
- In the style of TOK, six terrifying images.
- In the style of TOK, a group of beavers performing musically.
- In the style of TOK, a beaver gnaws a rifle in half.
- In the style of TOK, beavers rapidly constructing a dam in a Hawaiian shirt pattern.
- In the style of TOK, beavers rapidly constructing a dam in a Tarsem Singh film style.
- In the style of TOK, beavers in an M.C. Escher-like composition.
- In the style of TOK, a moving castle traverses grassy hills.
- In the style of TOK, a line of beavers performing a dance routine.
- In the style of TOK, a 1950s kitchen, frozen and discovered during the space age.
- In the style of TOK, a fashion show with elephant seal models and egret spectators.
- In the style of TOK, highly detailed lemon-lime-colored architecture.
- In the style of TOK, a mermaid made from sea trash swims up to the water’s surface.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surreal and intricate marine or forest scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 14114.32it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid crafte...
1     in the style of <s0><s1><s2>, small lilliputia...
2     in the style of <s0><s1><s2>, a view of fort k...
3     in the style of <s0><s1><s2>, an ambiguous sce...
4     in the style of <s0><s1><s2>, a chain formatio...
5     in the style of <s0><s1><s2>, a gorgon made of...
6     in the style of <s0><s1><s2>, venus and earth ...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are seen de...
9     in the style of <s0><s1><s2>, an odd-looking g...
10    in the style of <s0><s1><s2>, a contradictory ...
11    in the style of <s0><s1><s2>, an invitation to...
12    in the style of <s0><s1><s2>, ancient rock car...
13    in the style of <s0><s1><s2>, room and space e...
14    in the style of <s0><s1><s2>, a pattern induci...
15    in the style of <s0><s1><s2>, six terrifying i...
16    in the style of <s0><s1><s2>, a group of beave...
17    in the style of <s0><s1><s2>, a beaver gnaws a...
18    in the style of <s0><s1><s2>, beavers rapidly ...
19    in the style of <s0><s1><s2>, beavers rapidly ...
20    in the style of <s0><s1><s2>, beavers in an m....
21    in the style of <s0><s1><s2>, a moving castle ...
22    in the style of <s0><s1><s2>, a line of beaver...
23    in the style of <s0><s1><s2>, a 1950s kitchen,...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, highly detailed ...
26    in the style of <s0><s1><s2>, a mermaid made f...
27    in the style of <s0><s1><s2>, a mermaid crafte...
28    in the style of <s0><s1><s2>, small lilliputia...
29    in the style of <s0><s1><s2>, a view of fort k...
30    in the style of <s0><s1><s2>, an ambiguous sce...
31    in the style of <s0><s1><s2>, a chain formatio...
32    in the style of <s0><s1><s2>, a gorgon made of...
33    in the style of <s0><s1><s2>, venus and earth ...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are seen de...
36    in the style of <s0><s1><s2>, an odd-looking g...
37    in the style of <s0><s1><s2>, a contradictory ...
38    in the style of <s0><s1><s2>, an invitation to...
39    in the style of <s0><s1><s2>, ancient rock car...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:37,  2.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:15,  3.47s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:21,  2.09s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:06,  1.44s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:19,  1.08s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:14,  1.15it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.66# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:33,  1.37it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:06,  1.57it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:48,  1.73it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:10<02:27,  1.96it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:11<02:21,  2.03it/s]Progress: 7.00%
---- avg training fps: 4.10# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:11<02:17,  2.09it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:12<02:14,  2.13it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:12<02:14,  2.13it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:12<02:21,  2.02it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:13<02:16,  2.07it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:13<02:13,  2.12it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:14<02:11,  2.15it/s]Progress: 9.00%
---- avg training fps: 4.96# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:14<02:09,  2.17it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:14<02:08,  2.19it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:15<02:06,  2.20it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:15<02:06,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:16<02:05,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:16<02:04,  2.22it/s]Progress: 11.00%
---- avg training fps: 5.58# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:17<02:03,  2.22it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:17<02:03,  2.22it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:18<02:02,  2.22it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:18<02:18,  1.97it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:19<02:18,  1.97it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:19<02:08,  2.10it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:19<02:06,  2.14it/s]Progress: 13.00%
---- avg training fps: 5.99# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:20<02:04,  2.16it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:20<02:03,  2.17it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:20<02:01,  2.19it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:21<02:00,  2.20it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:21<01:59,  2.21it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:22<01:59,  2.21it/s]Progress: 15.00%
---- avg training fps: 6.33# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:22<01:58,  2.21it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:23<01:58,  2.21it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:23<01:57,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:24<01:57,  2.21it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:24<01:57,  2.20it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:25<01:57,  2.20it/s]Progress: 17.00%
---- avg training fps: 6.61# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:25<01:57,  2.20it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:25<01:52,  2.28it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:25<01:53,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:26<01:53,  2.24it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:26<01:54,  2.22it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:27<01:54,  2.21it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:27<01:54,  2.19it/s]Progress: 19.00%
---- avg training fps: 6.82# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:28<01:54,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:28<01:53,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:29<01:53,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:32<05:24,  1.31s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:32<04:20,  1.05s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:33<03:34,  1.15it/s]Progress: 21.00%
---- avg training fps: 6.40# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:33<03:02,  1.34it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:34<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:34<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:34<02:21,  1.72it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:35<02:11,  1.84it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:35<02:05,  1.93it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:35<01:59,  2.00it/s]Progress: 23.00%
---- avg training fps: 6.59# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:36<01:56,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:36<01:53,  2.09it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:37<01:52,  2.11it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:37<01:50,  2.14it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:38<01:49,  2.15it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:38<01:48,  2.16it/s]Progress: 25.00%
---- avg training fps: 6.74# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:39<01:47,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:39<01:46,  2.18it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:40<01:45,  2.18it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:40<01:45,  2.18it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:41<01:45,  2.18it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:41<01:54,  2.00it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:41<01:51,  2.05it/s]Progress: 27.00%
---- avg training fps: 6.85# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:42<01:48,  2.09it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:42<01:46,  2.11it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:42<01:45,  2.13it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:43<01:44,  2.15it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:43<01:43,  2.16it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:44<01:42,  2.17it/s]Progress: 29.00%
---- avg training fps: 6.97# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:44<01:41,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:45<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:45<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:46<01:39,  2.19it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:46<01:39,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:47<01:38,  2.18it/s]Progress: 31.00%
---- avg training fps: 7.08# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:47<01:38,  2.18it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:47<01:34,  2.27it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:47<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:48<01:35,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:48<01:35,  2.23it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:49<01:35,  2.21it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:49<01:35,  2.21it/s]Progress: 33.00%
---- avg training fps: 7.17# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:50<01:34,  2.20it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:50<01:34,  2.21it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:51<01:33,  2.21it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:51<01:33,  2.20it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:52<01:33,  2.20it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:52<01:32,  2.20it/s]Progress: 35.00%
---- avg training fps: 7.25# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:52<01:32,  2.20it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:53<01:28,  2.28it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:54<01:28,  2.25it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:54<01:29,  2.23it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:57<03:52,  1.17s/it]Progress: 37.00%
---- avg training fps: 7.03# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:58<03:08,  1.04it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [00:58<02:38,  1.24it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [00:58<02:17,  1.42it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [00:59<02:02,  1.59it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [00:59<01:51,  1.73it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:00<01:44,  1.84it/s]Progress: 39.00%
---- avg training fps: 7.11# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:00<01:38,  1.93it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:01<01:35,  2.00it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:01<01:32,  2.05it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:02<01:29,  2.09it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:02<01:29,  2.09it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:02<01:25,  2.19it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:03<01:25,  2.19it/s]Progress: 41.00%
---- avg training fps: 7.18# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:03<01:24,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:03<01:24,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:04<01:23,  2.19it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:04<01:23,  2.18it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:05<01:22,  2.18it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:05<01:22,  2.18it/s]Progress: 43.00%
---- avg training fps: 7.25# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:06<01:22,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:06<01:21,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:07<01:21,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:07<01:20,  2.18it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:08<01:20,  2.18it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:08<01:19,  2.18it/s]Progress: 45.00%
---- avg training fps: 7.31# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:08<01:19,  2.18it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:08<01:16,  2.27it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:09<01:26,  1.99it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:10<01:23,  2.05it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:10<01:21,  2.08it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:10<01:19,  2.12it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:11<01:19,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.35# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:11<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:12<01:17,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:12<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:13<01:15,  2.17it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:13<01:15,  2.17it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:14<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.40# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:14<01:14,  2.17it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:15<01:13,  2.17it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:15<01:13,  2.17it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:15<01:10,  2.26it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:15<01:10,  2.24it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:16<01:10,  2.22it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:16<01:10,  2.20it/s]Progress: 51.00%
---- avg training fps: 7.45# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:17<01:10,  2.19it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:17<01:10,  2.19it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:18<01:10,  2.18it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:18<01:09,  2.18it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:19<01:09,  2.18it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:19<01:09,  2.17it/s]Progress: 53.00%
---- avg training fps: 7.49# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:20<01:08,  2.17it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:23<03:35,  1.46s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:24<02:58,  1.22s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:24<02:24,  1.01it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:25<02:24,  1.01it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:25<01:57,  1.23it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:25<01:41,  1.42it/s]Progress: 55.00%
---- avg training fps: 7.23# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:26<01:30,  1.59it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:26<01:22,  1.73it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:27<01:16,  1.84it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:27<01:12,  1.93it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:28<01:09,  2.00it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:28<01:07,  2.06it/s]Progress: 57.00%
---- avg training fps: 7.28# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:29<01:05,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:29<01:04,  2.12it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:29<01:03,  2.14it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:30<01:01,  2.16it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:30<01:01,  2.17it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:31<01:00,  2.18it/s]Progress: 59.00%
---- avg training fps: 7.33# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:31<01:00,  2.18it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:31<00:57,  2.27it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:32<00:57,  2.24it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:32<00:57,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:33<00:57,  2.23it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:33<00:57,  2.21it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:34<00:57,  2.20it/s]Progress: 61.00%
---- avg training fps: 7.37# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:34<00:56,  2.19it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:34<00:56,  2.20it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:35<00:56,  2.19it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:35<00:55,  2.19it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:36<00:55,  2.18it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:36<00:54,  2.19it/s]Progress: 63.00%
---- avg training fps: 7.41# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:37<00:54,  2.18it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:37<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:38<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:38<00:51,  2.27it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:38<00:51,  2.24it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:38<00:51,  2.22it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:39<00:51,  2.20it/s]Progress: 65.00%
---- avg training fps: 7.45# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:39<00:51,  2.20it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:40<00:51,  2.19it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:40<00:50,  2.18it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:41<00:50,  2.18it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:41<00:50,  2.18it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:42<00:49,  2.17it/s]Progress: 67.00%
---- avg training fps: 7.48# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:42<00:49,  2.17it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:43<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:43<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:44<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:44<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:44<00:45,  2.25it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:44<00:45,  2.23it/s]Progress: 69.00%
---- avg training fps: 7.52# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:45<00:45,  2.21it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:45<00:45,  2.20it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:46<00:45,  2.19it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:49<02:01,  1.24s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:49<01:42,  1.06s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:50<01:24,  1.14it/s]Progress: 71.00%
---- avg training fps: 7.36# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:50<01:11,  1.34it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:51<01:02,  1.51it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:51<00:55,  1.67it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:52<00:51,  1.79it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:52<00:47,  1.90it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:53<00:45,  1.97it/s]Progress: 73.00%
---- avg training fps: 7.40# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:53<00:45,  1.97it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:53<00:42,  2.11it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:54<00:41,  2.12it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:54<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:54<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:55<00:39,  2.16it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:55<00:38,  2.17it/s]Progress: 75.00%
---- avg training fps: 7.43# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:56<00:38,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:56<00:37,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:57<00:37,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:57<00:36,  2.17it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:58<00:36,  2.17it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:58<00:35,  2.17it/s]Progress: 77.00%
---- avg training fps: 7.46# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [01:59<00:35,  2.18it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [01:59<00:35,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [01:59<00:35,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [01:59<00:33,  2.26it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:00<00:33,  2.22it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:00<00:33,  2.21it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:01<00:32,  2.21it/s]Progress: 79.00%
---- avg training fps: 7.49# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:01<00:32,  2.20it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:02<00:32,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:02<00:31,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:03<00:30,  2.20it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:03<00:30,  2.18it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:04<00:30,  2.18it/s]Progress: 81.00%
---- avg training fps: 7.51# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:04<00:29,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:05<00:29,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:05<00:28,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:05<00:28,  2.18it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:06<00:28,  2.18it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:06<00:26,  2.30it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:06<00:26,  2.26it/s]Progress: 83.00%
---- avg training fps: 7.55# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:07<00:26,  2.23it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:07<00:26,  2.23it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:08<00:25,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:08<00:25,  2.20it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:09<00:25,  2.19it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:09<00:24,  2.20it/s]Progress: 85.00%
---- avg training fps: 7.57# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:09<00:24,  2.19it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:10<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:10<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:11<00:22,  2.19it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:11<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:15<01:06,  1.38s/it]Progress: 87.00%
---- avg training fps: 7.43# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:15<01:06,  1.38s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:15<00:50,  1.09s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:16<00:41,  1.12it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:16<00:34,  1.31it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:17<00:29,  1.49it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:17<00:26,  1.64it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:18<00:23,  1.78it/s]Progress: 89.00%
---- avg training fps: 7.45# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:18<00:21,  1.88it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:18<00:20,  1.97it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:19<00:19,  2.03it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:19<00:18,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:20<00:17,  2.10it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:20<00:16,  2.13it/s]Progress: 91.00%
---- avg training fps: 7.48# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:21<00:16,  2.14it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:21<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:22<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:22<00:14,  2.25it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:22<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:23<00:14,  2.21it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:23<00:13,  2.20it/s]Progress: 93.00%
---- avg training fps: 7.50# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:23<00:13,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:24<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:24<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:25<00:11,  2.19it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:25<00:11,  2.18it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:26<00:11,  2.17it/s]Progress: 95.00%
---- avg training fps: 7.53# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:26<00:10,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:27<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:27<00:09,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:28<00:08,  2.26it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:28<00:08,  2.23it/s]Progress: 97.00%
---- avg training fps: 7.55# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:29<00:07,  2.23it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:29<00:07,  2.21it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:30<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:30<00:06,  2.18it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:31<00:05,  2.19it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:31<00:05,  2.18it/s]Progress: 99.00%
---- avg training fps: 7.57# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:32<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:32<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:33<00:04,  2.18it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:33<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:34<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:34<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.59# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:34<00:02,  2.16it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:34<00:02,  2.25it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:35<00:01,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:35<00:01,  2.22it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:36<00:00,  2.20it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:36<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:37<00:00,  2.19it/s]Progress: 100.00%
---- avg training fps: 7.61# Trainer step: 294, epoch: 21: : 301it [02:37,  2.18it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.10it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [03:57,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 02:18:44.679792: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:18:44.772375: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:18:44.772406: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:18:44.791362: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:18:45.193486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:18:45.193543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:18:45.193552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23115 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_02-18-46-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723508327.029796 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 50213.50it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.55it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.56it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.79it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.06it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_02-18-46-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.38it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.40it/s] 20%|██        | 2/10 [00:00<00:01,  4.37it/s] 30%|███       | 3/10 [00:00<00:01,  4.69it/s] 40%|████      | 4/10 [00:00<00:01,  4.80it/s] 50%|█████     | 5/10 [00:01<00:01,  4.77it/s] 60%|██████    | 6/10 [00:01<00:00,  4.81it/s] 70%|███████   | 7/10 [00:01<00:00,  5.03it/s] 80%|████████  | 8/10 [00:01<00:00,  5.10it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.11it/s]100%|██████████| 10/10 [00:02<00:00,  4.94it/s]100%|██████████| 10/10 [00:02<00:00,  4.83it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7189.72it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:34,  2.93s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:33,  3.34s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:58,  2.02s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:53,  1.40s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:10,  1.05s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:09,  1.18it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.74# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:29,  1.40it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:04,  1.58it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:47,  1.73it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:27,  1.95it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:22,  2.02it/s]Progress: 7.00%
---- avg training fps: 4.17# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:18,  2.07it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:11<02:15,  2.10it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:13,  2.13it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:12,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:11,  2.16it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:09,  2.17it/s]Progress: 9.00%
---- avg training fps: 5.06# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:08,  2.19it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:07,  2.19it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:07,  2.19it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:07,  2.19it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:06,  2.19it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:06,  2.19it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:05,  2.19it/s]Progress: 11.00%
---- avg training fps: 5.66# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:16<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:04,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:03,  2.20it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:03,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:03,  2.19it/s]Progress: 13.00%
---- avg training fps: 6.09# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:03,  2.19it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:02,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:02,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:16,  1.96it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:11,  2.02it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:07,  2.07it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:05,  2.10it/s]Progress: 15.00%
---- avg training fps: 6.37# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:03,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:23<01:59,  2.18it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<01:59,  2.18it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<01:58,  2.18it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:24<01:58,  2.18it/s]Progress: 17.00%
---- avg training fps: 6.63# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:57,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:57,  2.18it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:56,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:55,  2.19it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:55,  2.18it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:55,  2.19it/s]Progress: 19.00%
---- avg training fps: 6.83# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:54,  2.19it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:54,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:54,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:53,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:50,  1.41s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:38,  1.13s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:47,  1.08it/s]Progress: 21.00%
---- avg training fps: 6.35# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:12,  1.27it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:47,  1.46it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:34<02:30,  1.62it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:18,  1.75it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:35<02:09,  1.86it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]Progress: 23.00%
---- avg training fps: 6.53# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:58,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:55,  2.07it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:52,  2.11it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<02:04,  1.90it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:58,  1.98it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:54,  2.05it/s]Progress: 25.00%
---- avg training fps: 6.65# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:51,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:48,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:46,  2.16it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:46,  2.16it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:45,  2.16it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:41<01:44,  2.17it/s]Progress: 27.00%
---- avg training fps: 6.79# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:44,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:42<01:43,  2.19it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:42,  2.19it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:43<01:42,  2.19it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:41,  2.19it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:41,  2.19it/s]Progress: 29.00%
---- avg training fps: 6.91# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:40,  2.20it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:40,  2.20it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:40,  2.20it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:39,  2.19it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.18it/s]Progress: 31.00%
---- avg training fps: 7.01# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:47<01:38,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:37,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:48<01:37,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:36,  2.19it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:49<01:36,  2.19it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:35,  2.19it/s]Progress: 33.00%
---- avg training fps: 7.11# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:34,  2.20it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:34,  2.20it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:33,  2.20it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:33,  2.19it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:52<01:33,  2.19it/s]Progress: 35.00%
---- avg training fps: 7.19# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:32,  2.20it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:31,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:54<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:30,  2.20it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:55<01:30,  2.20it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.27# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:56<01:30,  2.19it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:56<01:29,  2.18it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:57<01:28,  2.19it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:57<01:28,  2.19it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:57<01:28,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:58<01:28,  2.17it/s]Progress: 39.00%
---- avg training fps: 7.34# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [00:58<01:27,  2.18it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [00:59<01:27,  2.18it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [00:59<01:27,  2.18it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [00:59<01:26,  2.18it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:00<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:00<01:25,  2.18it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:01<01:25,  2.18it/s]Progress: 41.00%
---- avg training fps: 7.40# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:01<01:24,  2.18it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:02<01:24,  2.18it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:02<01:24,  2.18it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:03<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:03<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:03<01:22,  2.18it/s]Progress: 43.00%
---- avg training fps: 7.46# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:04<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:04<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:04<01:21,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:05<01:20,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:05<01:20,  2.18it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:06<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:06<01:19,  2.19it/s]Progress: 45.00%
---- avg training fps: 7.51# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:07<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:07<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:08<01:18,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:08<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:08<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:08<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:09<01:17,  2.18it/s]Progress: 47.00%
---- avg training fps: 7.56# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:09<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:10<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:10<01:15,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:11<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:11<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:12<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.60# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:12<01:14,  2.17it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:13<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:13<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:13<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:14<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:14<01:11,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:14<01:11,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.64# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:15<01:11,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:15<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:16<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:16<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:17<01:09,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:17<01:09,  2.17it/s]Progress: 53.00%
---- avg training fps: 7.68# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:18<01:09,  2.17it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:18<01:08,  2.17it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:22<03:46,  1.53s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:22<02:57,  1.21s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:23<02:23,  1.02it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:23<01:59,  1.21it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:24<01:43,  1.40it/s]Progress: 55.00%
---- avg training fps: 7.39# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:24<01:30,  1.57it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:24<01:22,  1.72it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:25<01:16,  1.83it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:25<01:12,  1.92it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:26<01:12,  1.92it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:26<01:09,  1.99it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:26<01:07,  2.05it/s]Progress: 57.00%
---- avg training fps: 7.43# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:27<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:27<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:28<01:03,  2.13it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:28<01:02,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:29<01:01,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:29<01:01,  2.15it/s]Progress: 59.00%
---- avg training fps: 7.47# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:30<01:00,  2.16it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:30<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:30<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:30<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:31<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:31<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:32<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.50# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:32<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:33<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:33<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:34<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:34<00:55,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:35<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.54# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:35<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:35<00:54,  2.18it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:35<00:54,  2.18it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:36<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:36<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:37<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:37<00:52,  2.17it/s]Progress: 65.00%
---- avg training fps: 7.57# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:38<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:38<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:39<00:51,  2.17it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:39<00:50,  2.17it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:40<00:50,  2.17it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:40<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:40<00:50,  2.16it/s]Progress: 67.00%
---- avg training fps: 7.60# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:41<00:49,  2.17it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:41<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:42<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:42<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:42<00:47,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:43<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.62# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:43<00:46,  2.15it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:44<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:44<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:44<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:48<02:30,  1.54s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:49<01:57,  1.21s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:49<01:34,  1.01it/s]Progress: 71.00%
---- avg training fps: 7.40# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:50<01:18,  1.21it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:50<01:07,  1.40it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:51<00:59,  1.56it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:51<00:54,  1.69it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:52<00:50,  1.82it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:52<00:47,  1.91it/s]Progress: 73.00%
---- avg training fps: 7.43# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:52<00:47,  1.91it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:52<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:53<00:43,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:53<00:42,  2.07it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:54<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:54<00:40,  2.12it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:55<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.46# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:55<00:38,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:56<00:38,  2.15it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:56<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:57<00:37,  2.16it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [01:57<00:37,  2.16it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [01:57<00:36,  2.16it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [01:58<00:35,  2.17it/s]Progress: 77.00%
---- avg training fps: 7.49# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [01:58<00:35,  2.17it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [01:58<00:35,  2.17it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [01:59<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [01:59<00:34,  2.17it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:00<00:33,  2.17it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:00<00:33,  2.17it/s]Progress: 79.00%
---- avg training fps: 7.52# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:01<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:01<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:02<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:02<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:02<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:03<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:03<00:30,  2.17it/s]Progress: 81.00%
---- avg training fps: 7.54# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:04<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:04<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:05<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:05<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:05<00:28,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:06<00:27,  2.14it/s]Progress: 83.00%
---- avg training fps: 7.57# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:06<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:06<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:07<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:07<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:08<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:08<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:09<00:24,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.59# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:09<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:10<00:24,  2.15it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:10<00:23,  2.17it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:11<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:11<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:11<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:11<00:22,  2.15it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.61# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:12<00:21,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:12<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:13<00:20,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:13<00:20,  2.15it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:14<00:19,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:14<00:19,  2.15it/s]Progress: 89.00%
---- avg training fps: 7.63# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:15<00:19,  2.15it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:15<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:16<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:16<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:16<00:17,  2.16it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:17<00:17,  2.16it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:17<00:16,  2.17it/s]Progress: 91.00%
---- avg training fps: 7.65# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:17<00:16,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:18<00:15,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:18<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:19<00:14,  2.17it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:20<00:16,  1.92it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:20<00:15,  1.98it/s]Progress: 93.00%
---- avg training fps: 7.66# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:20<00:15,  1.98it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:20<00:14,  2.03it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:21<00:13,  2.08it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:21<00:12,  2.11it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:22<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:22<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:23<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.68# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:23<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:24<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:24<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:25<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:25<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:25<00:08,  2.17it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:26<00:08,  2.17it/s]Progress: 97.00%
---- avg training fps: 7.70# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:26<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:26<00:07,  2.17it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:27<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:27<00:06,  2.17it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:28<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:28<00:05,  2.18it/s]Progress: 99.00%
---- avg training fps: 7.72# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:29<00:05,  2.17it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:29<00:04,  2.17it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:30<00:04,  2.17it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:30<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:30<00:03,  2.18it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:31<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:31<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.74# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:32<00:02,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:32<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:32<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:33<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:33<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:34<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.75Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:54<00:00,  1.28it/s]
------------------------------------------
Training done :)
2024-08-13 02:23:11.920940: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:23:12.013029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:23:12.013057: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:23:12.032109: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:23:12.433598: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:23:12.433686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:23:12.433696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23132 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_02-23-14-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723508594.2655654 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 4913.39it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 15.98it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.52it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.81it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.09it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_02-23-14-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_02-23-14-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 376233.25it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 808901.49it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is made up of bees.
- In the style of TOK, a gorgon made out of sharks eats each other while swimming underwater.
- In the style of TOK, a hillside at sunset features Venus and Earth circling the sun.
- In the style of TOK, an ancient temple stands deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin appears alongside a goat.
- In the style of TOK, the phrase describes the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second degree connections.
- In the style of TOK, trypophobia is represented.
- In the style of TOK, six-pack containers burst with nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers performs.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers is depicted in an intricate pattern.
- In the style of TOK, a brigade of beavers appears in a visually complex design.
- In the style of TOK, a castle moves along the ground amid grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, lemon-lime architecture is depicted in hyper-realistic painting.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is made up of bees.
- In the style of TOK, a gorgon made out of sharks eats each other while swimming underwater.
- In the style of TOK, a hillside at sunset features Venus and Earth circling the sun.
- In the style of TOK, an ancient temple stands deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin appears alongside a goat.
- In the style of TOK, the phrase describes the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second degree connections.
- In the style of TOK, trypophobia is represented.
- In the style of TOK, six-pack containers burst with nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers performs.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers is depicted in an intricate pattern.
- In the style of TOK, a brigade of beavers appears in a visually complex design.
- In the style of TOK, a castle moves along the ground amid grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, lemon-lime architecture is depicted in hyper-realistic painting.
--------------------------
GPT-4 returned the wrong number of prompts 53 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, Venus and Earth are circling the sun over a hillside at sunset.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness" is depicted visually.
- In the style of TOK, two people decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange based on first and second-degree connections is visualized.
- In the style of TOK, trypophobia is depicted.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of beavers is dancing and singing like characters from Jim Henson's Muppets.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a pattern reminiscent of Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam, directed by Tarsem Singh.
- In the style of TOK, a brigade of beavers is illustrated in a style similar to M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, then rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models, with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid swimming underwater, made from sea trash.
- In the style of TOK, Lilliputians cramped inside giant sea-sponge pores.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, a reflection on the best and worst times.
- In the style of TOK, a blockchain formed by bees.
- In the style of TOK, a gorgon of sharks eating each other underwater.
- In the style of TOK, Venus and Earth circling the sun at sunset on a hillside.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats experiencing zero-gravity while pooping.
- In the style of TOK, a goblin goat.
- In the style of TOK, a reflection on the age of wisdom and foolishness.
- In the style of TOK, a proposal to quit a boring corporation job together.
- In the style of TOK, ancient petroglyphs.
- In the style of TOK, a room and space exchange based on personal connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of items seen as nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, beavers quickly building a dam.
- In the style of TOK, beavers quickly building a dam.
- In the style of TOK, a brigade of beavers.
- In the style of TOK, a moving castle on grassy hills.
- In the style of TOK, a line of adorable beavers dancing in unison.
- In the style of TOK, a frozen 1950s restaurant kitchen rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals on the runway and egrets in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made from sea trash, swimming up to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or nature scenes

- In the style of TOK, a mermaid crafted from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, narrating the best and worst of times.
- In the style of TOK, a blockchain composed of bees.
- In the style of TOK, a gorgon formed from sharks cannibalizing each other, swimming underwater.
- In the style of TOK, a sunset over a hillside with Venus and Earth orbiting the sun.
- In the style of TOK, an ancient temple located deep within the Amazon jungle.
- In the style of TOK, cats defecate in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, narrating the age of wisdom and foolishness.
- In the style of TOK, a scene where two people quit their boring corporate jobs together.
- In the style of TOK, ancient petroglyphs.
- In the style of TOK, an exchange room and space based on first and second degree connections.
- In the style of TOK, a depiction of trypophobia.
- In the style of TOK, a pack of six frightening images.
- In the style of TOK, a band of dancing and singing beavers.
- In the style of TOK, a beaver gnawing a rifle in half.
- In the style of TOK, a brigade of beavers quickly constructing a dam as a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers quickly constructing a dam in Tarsem Singh style.
- In the style of TOK, a brigade of beavers depicted in an M.C. Escher style.
- In the style of TOK, a moving castle travels along grassy hills.
- In the style of TOK, a chorus line of cute beavers dances in unison.
- In the style of TOK, a frozen and preserved 1950s restaurant kitchen, rediscovered in the space age.
- In the style of TOK, a fashion show featuring elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made from fishnets, dead fish, packing peanuts, and sea trash swims to the surface for a peek.
- In the style of TOK, a mermaid fashioned from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India.
- In the style of TOK, it was the best of times and the worst of times.
- In the style of TOK, a blockchain made up of bees.
- In the style of TOK, a gorgon comprised of sharks eating each other, swimming underwater.
- In the style of TOK, a sunset over a hillside with Venus and Earth orbiting the sun.
- In the style of TOK, an ancient temple buried deep within the Amazon jungle.
- In the style of TOK, cats defecating in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, it was the age of wisdom and foolishness.
- In the style of TOK, a scene where two people decide to quit their boring corporate jobs together.
- In the style of TOK, representations of petroglyphs.
- In the style of TOK, a room and space exchange based on first and second degree connections.
- In the style of TOK, a pattern invoking trypophobia.
- In the style of TOK, a collection of six terrifying images.
- In the style of TOK, a troupe of dancing, singing beavers as Muppets.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly constructing a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers swiftly building a dam as seen in Tarsem Singh's works.
- In the style of TOK, a brigade of beavers illustrated in an M.C. Escher style.
- In the style of TOK, a mobile castle moving along grassy hills.
- In the style of TOK, a line of adorable beavers dancing in sync.
- In the style of TOK, a frozen 1950s restaurant kitchen discovered in the space age.
- In the style of TOK, a fashion show featuring elephant seals as models and egrets in the audience.
- In the style of TOK, a hyper-realistic painting depicting lemon-lime architecture.
- In the style of TOK, a mermaid constructed from fishnets, dead fish, packing peanuts, and sea trash swims upward to peek above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surreal and intricate marine or nature scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 13968.08it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid crafte...
1     in the style of <s0><s1><s2>, lilliputians are...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, narrating the be...
4     in the style of <s0><s1><s2>, a blockchain com...
5     in the style of <s0><s1><s2>, a gorgon formed ...
6     in the style of <s0><s1><s2>, a sunset over a ...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats defecate in...
9          in the style of <s0><s1><s2>, a goblin goat.
10    in the style of <s0><s1><s2>, narrating the ag...
11    in the style of <s0><s1><s2>, a scene where tw...
12    in the style of <s0><s1><s2>, ancient petrogly...
13    in the style of <s0><s1><s2>, an exchange room...
14    in the style of <s0><s1><s2>, a depiction of t...
15    in the style of <s0><s1><s2>, a pack of six fr...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver gnawing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a moving castle ...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a frozen and pre...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made f...
27    in the style of <s0><s1><s2>, a mermaid fashio...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, it was the best ...
31    in the style of <s0><s1><s2>, a blockchain mad...
32    in the style of <s0><s1><s2>, a gorgon compris...
33    in the style of <s0><s1><s2>, a sunset over a ...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats defecating ...
36         in the style of <s0><s1><s2>, a goblin goat.
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, a scene where tw...
39    in the style of <s0><s1><s2>, representations ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:41,  2.95s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<20:12,  4.07s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:57,  2.41s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:04,  1.64s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:56,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:39,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.39# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:50,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:18,  1.47it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:56,  1.65it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:42,  1.79it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:11<02:32,  1.90it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:25,  1.99it/s]Progress: 7.00%
---- avg training fps: 3.77# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:12<02:20,  2.05it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:13<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:13<02:22,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:17,  2.07it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:14<02:14,  2.11it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:11,  2.14it/s]Progress: 9.00%
---- avg training fps: 4.63# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:15<02:09,  2.16it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:08,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:07,  2.19it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:16<02:06,  2.20it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:05,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:17<02:05,  2.20it/s]Progress: 11.00%
---- avg training fps: 5.26# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:04,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:18<02:03,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:03,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:19<02:03,  2.21it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:03,  2.21it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:57,  2.30it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:58,  2.27it/s]Progress: 13.00%
---- avg training fps: 5.74# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:20<01:59,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:59,  2.24it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:21<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:22<01:59,  2.22it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:58,  2.22it/s]Progress: 15.00%
---- avg training fps: 6.10# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:23<01:58,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:58,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:58,  2.21it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:24<01:57,  2.20it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:57,  2.21it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:25<01:57,  2.20it/s]Progress: 17.00%
---- avg training fps: 6.39# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:26<01:57,  2.20it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:26<01:52,  2.29it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:26<01:52,  2.27it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:53,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:27<01:54,  2.23it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:54,  2.21it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:28<01:54,  2.20it/s]Progress: 19.00%
---- avg training fps: 6.62# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:54,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:54,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:29<01:53,  2.19it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<06:33,  1.59s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<05:07,  1.25s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<04:07,  1.01s/it]Progress: 21.00%
---- avg training fps: 6.08# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:26,  1.19it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:35<02:57,  1.37it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:57,  1.37it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:32,  1.59it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:19,  1.73it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:10,  1.85it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:03,  1.94it/s]Progress: 23.00%
---- avg training fps: 6.28# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:59,  2.01it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:56,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:53,  2.09it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:51,  2.12it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<01:49,  2.14it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:49,  2.15it/s]Progress: 25.00%
---- avg training fps: 6.45# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:40<01:48,  2.16it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:47,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:46,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:46,  2.17it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:46,  2.17it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:41,  2.25it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:42,  2.23it/s]Progress: 27.00%
---- avg training fps: 6.60# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<01:42,  2.21it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:43,  2.19it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:45<01:42,  2.17it/s]Progress: 29.00%
---- avg training fps: 6.72# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:41,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:46<01:41,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:40,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:47<01:40,  2.16it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:40,  2.15it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:48<01:40,  2.16it/s]Progress: 31.00%
---- avg training fps: 6.84# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:40,  2.16it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:49<01:36,  2.22it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:37,  2.20it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:37,  2.18it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:36,  2.18it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.17it/s]Progress: 33.00%
---- avg training fps: 6.93# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:51<01:36,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:36,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:52<01:35,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:35,  2.15it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:53<01:35,  2.15it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:34,  2.15it/s]Progress: 35.00%
---- avg training fps: 7.02# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:54<01:34,  2.15it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:34,  2.15it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:34,  2.15it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:30,  2.20it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:31,  2.18it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:46,  1.14s/it]Progress: 37.00%
---- avg training fps: 6.83# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<03:05,  1.06it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:36,  1.25it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:16,  1.43it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<02:01,  1.59it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:52,  1.72it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:44,  1.84it/s]Progress: 39.00%
---- avg training fps: 6.91# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:39,  1.92it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:03<01:36,  1.98it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:33,  2.02it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:03<01:31,  2.06it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:31,  2.06it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:26,  2.17it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:04<01:26,  2.16it/s]Progress: 41.00%
---- avg training fps: 6.98# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:26,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:05<01:25,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:25,  2.14it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:06<01:24,  2.14it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:24,  2.14it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:07<01:23,  2.14it/s]Progress: 43.00%
---- avg training fps: 7.05# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:09<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:09<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:09<01:21,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.11# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:10<01:21,  2.14it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:10<01:17,  2.23it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:17,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:11<01:18,  2.18it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:12<01:18,  2.16it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:18,  2.15it/s]Progress: 47.00%
---- avg training fps: 7.17# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:13<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:14<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:15<01:16,  2.14it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:15<01:16,  2.14it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:15<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.22# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:15,  2.14it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:14,  2.13it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:11,  2.23it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:18<01:24,  1.87it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:20,  1.94it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:19<01:18,  2.00it/s]Progress: 51.00%
---- avg training fps: 7.25# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:15,  2.04it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:19<01:14,  2.07it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:13,  2.10it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:20<01:12,  2.11it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:10,  2.13it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.29# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:09,  2.14it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:26<03:53,  1.58s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:26<03:03,  1.25s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:27<02:27,  1.01s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:27<02:27,  1.01s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:27<02:00,  1.21it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:28<01:43,  1.39it/s]Progress: 55.00%
---- avg training fps: 7.02# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:28<01:41,  1.41it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:29<01:30,  1.58it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:29<01:22,  1.71it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:30<01:16,  1.83it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:30<01:12,  1.92it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:31<01:09,  1.98it/s]Progress: 57.00%
---- avg training fps: 7.07# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:31<01:07,  2.03it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:32<01:05,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:32<01:04,  2.10it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:33<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:33<01:02,  2.12it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:34<01:01,  2.13it/s]Progress: 59.00%
---- avg training fps: 7.12# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:34<01:01,  2.13it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:34<00:58,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:34<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:35<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:35<00:58,  2.18it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:36<00:58,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:36<00:58,  2.16it/s]Progress: 61.00%
---- avg training fps: 7.16# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:37<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:37<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:38<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:38<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:39<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:39<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.20# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:39<00:55,  2.16it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:40<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:40<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:40<00:52,  2.24it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:41<00:52,  2.21it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:41<00:52,  2.19it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:42<00:52,  2.18it/s]Progress: 65.00%
---- avg training fps: 7.24# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:42<00:52,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:43<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:43<00:51,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:44<00:51,  2.15it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:44<00:50,  2.15it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:45<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.28# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:45<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:45<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:46<00:48,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:46<00:48,  2.14it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:47<00:48,  2.14it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:47<00:46,  2.23it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:47<00:46,  2.20it/s]Progress: 69.00%
---- avg training fps: 7.32# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:48<00:46,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:48<00:46,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:49<00:45,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:52<02:02,  1.25s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:52<01:38,  1.02s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:53<01:21,  1.17it/s]Progress: 71.00%
---- avg training fps: 7.18# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:53<01:09,  1.36it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:54<01:01,  1.53it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:54<01:01,  1.52it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:55<00:54,  1.67it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:55<00:50,  1.80it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:56<00:47,  1.89it/s]Progress: 73.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:56<00:47,  1.89it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:56<00:43,  2.04it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:57<00:42,  2.07it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:57<00:41,  2.09it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:57<00:40,  2.12it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:58<00:40,  2.12it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:58<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.24# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:59<00:38,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:00<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:00<00:37,  2.13it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:01<00:37,  2.13it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:01<00:36,  2.13it/s]Progress: 77.00%
---- avg training fps: 7.27# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:02<00:36,  2.13it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:02<00:35,  2.12it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:03<00:35,  2.12it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:03<00:33,  2.22it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:03<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:04<00:33,  2.17it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:04<00:33,  2.15it/s]Progress: 79.00%
---- avg training fps: 7.30# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:04<00:33,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:05<00:32,  2.14it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:05<00:32,  2.13it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:06<00:31,  2.13it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:06<00:31,  2.12it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:07<00:31,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.32# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:07<00:30,  2.12it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:08<00:30,  2.13it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:08<00:29,  2.13it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:09<00:29,  2.14it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:09<00:29,  2.14it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:09<00:27,  2.24it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:10<00:27,  2.21it/s]Progress: 83.00%
---- avg training fps: 7.35# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:10<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:11<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:11<00:26,  2.16it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:11<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:12<00:25,  2.15it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:12<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.38# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:13<00:24,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:13<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:14<00:23,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:14<00:23,  2.14it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:15<00:22,  2.16it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:19<01:15,  1.57s/it]Progress: 87.00%
---- avg training fps: 7.21# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:19<01:15,  1.57s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:19<00:57,  1.22s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:20<00:45,  1.01it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:20<00:37,  1.20it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:21<00:31,  1.38it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:21<00:27,  1.55it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:22<00:24,  1.69it/s]Progress: 89.00%
---- avg training fps: 7.24# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:22<00:22,  1.80it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:23<00:21,  1.89it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:23<00:19,  1.95it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:23<00:18,  2.01it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:24<00:18,  2.05it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:24<00:17,  2.07it/s]Progress: 91.00%
---- avg training fps: 7.27# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:25<00:16,  2.09it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:25<00:16,  2.10it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:26<00:16,  2.10it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:26<00:14,  2.20it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:26<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:27<00:14,  2.16it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:27<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.29# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:28<00:13,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:28<00:13,  2.14it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:29<00:12,  2.14it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:29<00:12,  2.13it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:29<00:11,  2.13it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:30<00:11,  2.13it/s]Progress: 95.00%
---- avg training fps: 7.32# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:30<00:10,  2.13it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:31<00:10,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:31<00:09,  2.13it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:32<00:09,  2.13it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:32<00:09,  2.13it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:32<00:08,  2.22it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:33<00:08,  2.19it/s]Progress: 97.00%
---- avg training fps: 7.34# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:33<00:07,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:34<00:07,  2.16it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:34<00:06,  2.14it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:35<00:06,  2.14it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:35<00:06,  2.13it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:36<00:05,  2.12it/s]Progress: 99.00%
---- avg training fps: 7.36# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:36<00:05,  2.14it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:36<00:04,  2.12it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:37<00:04,  2.12it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:37<00:03,  2.12it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:38<00:03,  2.12it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:38<00:02,  2.12it/s]Progress: 100.00%
---- avg training fps: 7.38# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:39<00:02,  2.12it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:39<00:02,  2.22it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:39<00:01,  2.19it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:40<00:01,  2.17it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:40<00:00,  2.14it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:41<00:00,  2.14it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:41<00:00,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.40# Trainer step: 294, epoch: 21: : 301it [02:42,  2.12it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.14it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.70it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.61it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.51it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.48it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.46it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.45it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.43it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.43it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.42it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.42it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.41it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:05,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 02:28:21.267241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:28:21.359036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:28:21.359064: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:28:21.378498: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:28:21.780788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:28:21.780871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:28:21.780881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23119 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_02-28-23-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723508903.5469067 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 16745.69it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:02,  2.27it/s]Loading pipeline components...:  43%|████▎     | 3/7 [00:01<00:01,  2.51it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:01<00:00,  4.78it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.80it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_02-28-23-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_02-28-23-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 334059.61it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1094166.26it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene depicts Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is visualized using bees.
- In the style of TOK, a gorgon made out of sharks eats each other while swimming underwater.
- In the style of TOK, a hillside at sunset features Venus and Earth circling the sun.
- In the style of TOK, an ancient temple stands deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and foolishness.
- In the style of TOK, the message suggests quitting a boring corporation job together.
- In the style of TOK, petroglyphs are depicted in the image.
- In the style of TOK, a room and space exchange based on first and second-degree connections is shown.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, a 6-pack is referred to as nightmare fuel.
- In the style of TOK, a band of beavers sings and dances like Jim Henson's Muppets.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam, depicted as a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers quickly builds a dam, resembling Tarsem Singh's work.
- In the style of TOK, a brigade of beavers is illustrated in the manner of M. C. Escher.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, later rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 13279.34it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two individuals ...
12    in the style of <s0><s1><s2>, petroglyphs are ...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, trypophobia is v...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is show...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain is ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are pooping...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two individuals ...
39    in the style of <s0><s1><s2>, petroglyphs are ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:00,  3.01s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<22:12,  4.47s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<13:05,  2.64s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:48,  1.79s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:26,  1.31s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<05:01,  1.02s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.21# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:07,  1.18it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:31,  1.38it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:07,  1.55it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:51,  1.70it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:39,  1.81it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:13<02:32,  1.89it/s]Progress: 7.00%
---- avg training fps: 3.51# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:26,  1.96it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:14<02:22,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:22,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:27,  1.94it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:15<02:23,  1.99it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:19,  2.03it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:16<02:17,  2.06it/s]Progress: 9.00%
---- avg training fps: 4.34# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:14,  2.09it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:17<02:13,  2.10it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:12,  2.11it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:11,  2.11it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:10,  2.12it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:10,  2.11it/s]Progress: 11.00%
---- avg training fps: 4.95# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:09,  2.13it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:08,  2.13it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:20<02:08,  2.13it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:07,  2.13it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:21<02:07,  2.13it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:21<02:01,  2.23it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:03,  2.19it/s]Progress: 13.00%
---- avg training fps: 5.42# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:22<02:04,  2.17it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:04,  2.15it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:23<02:05,  2.13it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:04,  2.13it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:24<02:04,  2.13it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:24<02:03,  2.13it/s]Progress: 15.00%
---- avg training fps: 5.77# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:03,  2.13it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:25<02:02,  2.14it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:02,  2.14it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:26<02:01,  2.14it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<02:01,  2.14it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:27<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.06# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<02:00,  2.14it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:55,  2.23it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:28<01:56,  2.19it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:57,  2.18it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:29<01:57,  2.16it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:29<01:57,  2.15it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:30<01:57,  2.14it/s]Progress: 19.00%
---- avg training fps: 6.29# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:30<01:57,  2.14it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:31<01:57,  2.13it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:31<01:56,  2.14it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:42,  1.38s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:35<04:33,  1.11s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:45,  1.09it/s]Progress: 21.00%
---- avg training fps: 5.93# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:36<03:11,  1.28it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:48,  1.45it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:37<02:48,  1.45it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:37<02:26,  1.66it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:37<02:16,  1.77it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:38<02:09,  1.85it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:38<02:04,  1.93it/s]Progress: 23.00%
---- avg training fps: 6.13# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:39<02:00,  1.98it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:39<01:57,  2.03it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:40<01:55,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:40<01:53,  2.07it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:41<02:11,  1.78it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:41<02:04,  1.88it/s]Progress: 25.00%
---- avg training fps: 6.25# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:42<01:59,  1.95it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:42<01:55,  2.00it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:43<01:53,  2.04it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:43<01:51,  2.07it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:44<01:51,  2.07it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:44<01:44,  2.19it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:44<01:44,  2.17it/s]Progress: 27.00%
---- avg training fps: 6.40# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:45<01:45,  2.16it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:45<01:45,  2.15it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:45<01:44,  2.15it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:47<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.52# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:48<01:42,  2.14it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:48<01:42,  2.14it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:49<01:42,  2.13it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:49<01:41,  2.14it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:50<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.65# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:50<01:41,  2.13it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:50<01:36,  2.24it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:51<01:37,  2.20it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:51<01:37,  2.18it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:51<01:37,  2.16it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:52<01:37,  2.16it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:52<01:37,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.74# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:53<01:37,  2.14it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:53<01:37,  2.14it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:54<01:36,  2.15it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:54<01:36,  2.14it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:55<01:36,  2.13it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:55<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.83# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:56<01:35,  2.13it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:56<01:34,  2.14it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:57<01:34,  2.14it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:57<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:57<01:30,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:57<01:31,  2.18it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [01:00<04:00,  1.22s/it]Progress: 37.00%
---- avg training fps: 6.64# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [01:01<03:15,  1.01it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:01<02:43,  1.20it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:02<02:20,  1.38it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:02<02:05,  1.54it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:03<01:54,  1.68it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:03<01:47,  1.79it/s]Progress: 39.00%
---- avg training fps: 6.72# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:04<01:42,  1.87it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:04<01:37,  1.94it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:05<01:35,  1.99it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:05<01:32,  2.03it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:06<01:32,  2.03it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:06<01:27,  2.14it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:06<01:27,  2.13it/s]Progress: 41.00%
---- avg training fps: 6.80# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:07<01:26,  2.13it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:07<01:26,  2.12it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:07<01:26,  2.12it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:08<01:25,  2.12it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:08<01:25,  2.13it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:09<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 6.87# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:09<01:24,  2.12it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:10<01:23,  2.12it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:10<01:23,  2.12it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:11<01:22,  2.12it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:11<01:32,  1.90it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:12<01:28,  1.97it/s]Progress: 45.00%
---- avg training fps: 6.92# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:12<01:28,  1.97it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:12<01:22,  2.10it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:13<01:21,  2.11it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:13<01:20,  2.12it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:14<01:20,  2.12it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:14<01:19,  2.13it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:15<01:19,  2.12it/s]Progress: 47.00%
---- avg training fps: 6.98# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:15<01:18,  2.13it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:16<01:17,  2.13it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:16<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:17<01:16,  2.14it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:17<01:16,  2.14it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:17<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.04# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:18<01:15,  2.14it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:18<01:15,  2.13it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:19<01:15,  2.13it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:19<01:11,  2.23it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:19<01:12,  2.19it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:20<01:12,  2.17it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:20<01:12,  2.16it/s]Progress: 51.00%
---- avg training fps: 7.10# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:21<01:12,  2.15it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:21<01:11,  2.14it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:22<01:11,  2.15it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:22<01:10,  2.15it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:23<01:10,  2.13it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:23<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.14# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:23<01:09,  2.13it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:29<04:33,  1.84s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:29<03:30,  1.43s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:29<02:47,  1.14s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:30<02:47,  1.14s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:30<02:13,  1.09it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:30<01:52,  1.28it/s]Progress: 55.00%
---- avg training fps: 6.83# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:31<01:38,  1.45it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:31<01:28,  1.60it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:32<01:21,  1.73it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:32<01:16,  1.83it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:33<01:12,  1.91it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:33<01:09,  1.97it/s]Progress: 57.00%
---- avg training fps: 6.88# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:34<01:07,  2.03it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:34<01:06,  2.06it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:35<01:05,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:35<01:04,  2.09it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:36<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:36<01:02,  2.12it/s]Progress: 59.00%
---- avg training fps: 6.94# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:36<01:02,  2.12it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:36<00:58,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:37<00:59,  2.20it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:37<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:38<00:58,  2.18it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:38<00:58,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:39<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 6.98# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:39<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:40<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:40<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:41<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:41<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:41<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.03# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:42<00:55,  2.15it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:42<00:54,  2.15it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:43<00:54,  2.15it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:43<00:51,  2.26it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:43<00:52,  2.22it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:44<00:52,  2.20it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:44<00:52,  2.18it/s]Progress: 65.00%
---- avg training fps: 7.07# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:45<00:51,  2.18it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:45<00:51,  2.17it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:46<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:46<00:50,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:47<00:50,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:47<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.11# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:47<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:48<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:48<00:48,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:49<00:48,  2.15it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:49<00:48,  2.15it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:49<00:45,  2.25it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:50<00:47,  2.16it/s]Progress: 69.00%
---- avg training fps: 7.15# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:50<00:46,  2.15it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:51<00:46,  2.15it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:51<00:45,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:54<01:59,  1.22s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:55<01:35,  1.01it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:55<01:19,  1.20it/s]Progress: 71.00%
---- avg training fps: 7.03# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:56<01:08,  1.39it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:56<01:00,  1.56it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:56<00:54,  1.70it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:57<00:50,  1.82it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:57<00:47,  1.91it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:58<00:45,  1.99it/s]Progress: 73.00%
---- avg training fps: 7.08# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:58<00:45,  1.99it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:58<00:42,  2.12it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:59<00:41,  2.13it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:59<00:40,  2.15it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [02:00<00:39,  2.16it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [02:00<00:46,  1.83it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [02:01<00:43,  1.93it/s]Progress: 75.00%
---- avg training fps: 7.10# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [02:01<00:41,  2.00it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [02:02<00:39,  2.06it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:02<00:38,  2.10it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:03<00:37,  2.12it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:03<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:04<00:36,  2.16it/s]Progress: 77.00%
---- avg training fps: 7.13# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:04<00:35,  2.18it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:04<00:34,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:05<00:34,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:05<00:33,  2.27it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:05<00:33,  2.23it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:06<00:32,  2.22it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:06<00:32,  2.22it/s]Progress: 79.00%
---- avg training fps: 7.17# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:07<00:32,  2.21it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:07<00:31,  2.20it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:08<00:31,  2.19it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:08<00:30,  2.19it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:08<00:30,  2.20it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:09<00:30,  2.20it/s]Progress: 81.00%
---- avg training fps: 7.21# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:09<00:29,  2.19it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:10<00:29,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:10<00:28,  2.19it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:11<00:28,  2.18it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:11<00:28,  2.18it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:11<00:26,  2.31it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:12<00:26,  2.27it/s]Progress: 83.00%
---- avg training fps: 7.24# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:12<00:26,  2.24it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:13<00:26,  2.22it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:13<00:25,  2.22it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:13<00:25,  2.21it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:14<00:24,  2.20it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:14<00:24,  2.19it/s]Progress: 85.00%
---- avg training fps: 7.27# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:15<00:24,  2.18it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:15<00:23,  2.18it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:16<00:23,  2.18it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:16<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:17<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:20<01:08,  1.43s/it]Progress: 87.00%
---- avg training fps: 7.14# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:21<01:08,  1.43s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:21<00:52,  1.12s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:21<00:42,  1.08it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:22<00:35,  1.27it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:22<00:30,  1.46it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:23<00:26,  1.61it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:23<00:23,  1.75it/s]Progress: 89.00%
---- avg training fps: 7.17# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:24<00:22,  1.85it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:24<00:20,  1.94it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:24<00:19,  2.01it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:25<00:18,  2.06it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:25<00:17,  2.09it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:26<00:17,  2.10it/s]Progress: 91.00%
---- avg training fps: 7.19# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:26<00:16,  2.12it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:27<00:15,  2.14it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:27<00:15,  2.14it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:27<00:14,  2.24it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:28<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:28<00:14,  2.21it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:29<00:13,  2.19it/s]Progress: 93.00%
---- avg training fps: 7.23# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:29<00:13,  2.20it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:29<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:30<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:30<00:11,  2.19it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:31<00:11,  2.18it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:31<00:11,  2.18it/s]Progress: 95.00%
---- avg training fps: 7.25# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:32<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:32<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:33<00:09,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:33<00:09,  2.18it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:33<00:09,  2.18it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:33<00:08,  2.26it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:34<00:08,  2.24it/s]Progress: 97.00%
---- avg training fps: 7.28# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:34<00:07,  2.21it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:35<00:07,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:35<00:06,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:36<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:36<00:05,  2.18it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:37<00:05,  2.17it/s]Progress: 99.00%
---- avg training fps: 7.31# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:37<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:38<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:38<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:39<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:39<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:40<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.33# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:40<00:02,  2.16it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:40<00:02,  2.25it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:40<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:41<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:41<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:42<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:42<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.35# Trainer step: 294, epoch: 21: : 301it [02:43,  2.16it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.10it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:03,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 02:33:08.556638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:33:08.649580: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:33:08.649608: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:33:08.668174: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:33:09.069232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:33:09.069312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:33:09.069321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23101 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_02-33-10-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723509190.8997006 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 4540.74it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.26it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.51it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.79it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.07it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_02-33-10-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.37it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.47it/s] 20%|██        | 2/10 [00:00<00:01,  4.44it/s] 30%|███       | 3/10 [00:00<00:01,  4.74it/s] 40%|████      | 4/10 [00:00<00:01,  4.88it/s] 50%|█████     | 5/10 [00:01<00:01,  4.85it/s] 60%|██████    | 6/10 [00:01<00:00,  4.89it/s] 70%|███████   | 7/10 [00:01<00:00,  5.10it/s] 80%|████████  | 8/10 [00:01<00:00,  5.09it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.09it/s]100%|██████████| 10/10 [00:02<00:00,  4.95it/s]100%|██████████| 10/10 [00:02<00:00,  4.86it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7619.43it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:41,  2.95s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:37,  3.35s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:00,  2.02s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:54,  1.40s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:11,  1.06s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:09,  1.18it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.73# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:30,  1.39it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:04,  1.58it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:47,  1.74it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:35,  1.86it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:35,  1.86it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:27,  1.95it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:23,  2.01it/s]Progress: 7.00%
---- avg training fps: 4.16# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:18,  2.06it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:11<02:16,  2.10it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:14,  2.12it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:12,  2.14it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:11,  2.16it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:10,  2.17it/s]Progress: 9.00%
---- avg training fps: 5.04# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:09,  2.17it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:06,  2.19it/s]Progress: 11.00%
---- avg training fps: 5.64# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:05,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]Progress: 13.00%
---- avg training fps: 6.07# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:17,  1.94it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:12,  2.01it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:08,  2.06it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:05,  2.10it/s]Progress: 15.00%
---- avg training fps: 6.34# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:03,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:00,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<01:58,  2.18it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:24<01:58,  2.18it/s]Progress: 17.00%
---- avg training fps: 6.60# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:57,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:57,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:56,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:56,  2.18it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:55,  2.19it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:55,  2.18it/s]Progress: 19.00%
---- avg training fps: 6.81# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:54,  2.18it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:53,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:50,  1.41s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:37,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:47,  1.08it/s]Progress: 21.00%
---- avg training fps: 6.33# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:12,  1.27it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:47,  1.46it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:30,  1.62it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:17,  1.76it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:35<02:09,  1.87it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]Progress: 23.00%
---- avg training fps: 6.51# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:58,  2.01it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:54,  2.07it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:52,  2.10it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<02:04,  1.89it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:59,  1.97it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:55,  2.03it/s]Progress: 25.00%
---- avg training fps: 6.64# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:51,  2.08it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:44,  2.18it/s]Progress: 27.00%
---- avg training fps: 6.77# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:44,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:42<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:42,  2.19it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:43<01:42,  2.18it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:42,  2.18it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:41,  2.18it/s]Progress: 29.00%
---- avg training fps: 6.89# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:41,  2.18it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:40,  2.19it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:40,  2.19it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:40,  2.19it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:39,  2.19it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:38,  2.20it/s]Progress: 31.00%
---- avg training fps: 7.00# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:37,  2.20it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:37,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:48<01:37,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:36,  2.20it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:49<01:36,  2.20it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:35,  2.20it/s]Progress: 33.00%
---- avg training fps: 7.10# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:35,  2.20it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:35,  2.20it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:34,  2.20it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:33,  2.20it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:33,  2.19it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.18# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:32,  2.20it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:54<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:30,  2.19it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:55<01:30,  2.18it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.26# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:56<01:30,  2.19it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:56<01:29,  2.18it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:57<01:29,  2.18it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:57<01:29,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:58<01:28,  2.17it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:58<01:28,  2.17it/s]Progress: 39.00%
---- avg training fps: 7.32# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [00:58<01:28,  2.17it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [00:59<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [00:59<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [00:59<01:27,  2.16it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:00<01:26,  2.16it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:00<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:01<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 7.38# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:01<01:25,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:03<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:03<01:23,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:04<01:23,  2.17it/s]Progress: 43.00%
---- avg training fps: 7.44# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:04<01:23,  2.17it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:04<01:22,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:04<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:05<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:05<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:06<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:06<01:19,  2.18it/s]Progress: 45.00%
---- avg training fps: 7.49# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:07<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:07<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:08<01:19,  2.16it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:08<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:09<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:09<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:09<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.54# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:10<01:17,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:10<01:16,  2.17it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:10<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:11<01:15,  2.16it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:11<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:12<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.58# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:12<01:14,  2.16it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:13<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:13<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:13<01:13,  2.17it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:14<01:12,  2.17it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:14<01:12,  2.17it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:15<01:11,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.62# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:15<01:11,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:16<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:16<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:16<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:17<01:09,  2.17it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:17<01:09,  2.17it/s]Progress: 53.00%
---- avg training fps: 7.66# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:18<01:09,  2.17it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:18<01:08,  2.16it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:22<03:41,  1.50s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:22<02:54,  1.19s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:23<02:21,  1.03it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:23<01:58,  1.23it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:24<01:41,  1.41it/s]Progress: 55.00%
---- avg training fps: 7.38# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:24<01:30,  1.58it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:25<01:22,  1.73it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:25<01:16,  1.84it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:25<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:26<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:26<01:09,  1.99it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:26<01:07,  2.05it/s]Progress: 57.00%
---- avg training fps: 7.42# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:27<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:27<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:28<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:28<01:02,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:29<01:01,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:29<01:01,  2.15it/s]Progress: 59.00%
---- avg training fps: 7.46# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:30<01:00,  2.15it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:30<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:31<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:31<00:59,  2.17it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:31<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:31<00:58,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:32<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.50# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:32<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:33<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:33<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:34<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:34<00:55,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:35<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.53# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:35<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:35<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:36<00:54,  2.18it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:36<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:37<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:37<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:37<00:52,  2.17it/s]Progress: 65.00%
---- avg training fps: 7.56# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:38<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:38<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:39<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:39<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:40<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:40<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:40<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.59# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:41<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:41<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:42<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:42<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:43<00:47,  2.17it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:43<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.62# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:43<00:46,  2.15it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:44<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:44<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:44<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:48<02:29,  1.52s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:49<01:56,  1.20s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:49<01:34,  1.02it/s]Progress: 71.00%
---- avg training fps: 7.40# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:50<01:18,  1.22it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:50<01:07,  1.40it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:51<00:59,  1.57it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:51<00:53,  1.71it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:52<00:49,  1.83it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:52<00:46,  1.92it/s]Progress: 73.00%
---- avg training fps: 7.43# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:53<00:46,  1.92it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:53<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:53<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:53<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:54<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:54<00:40,  2.12it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:55<00:39,  2.14it/s]Progress: 75.00%
---- avg training fps: 7.46# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:55<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:56<00:38,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:56<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:57<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [01:57<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [01:57<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [01:58<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.49# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [01:58<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [01:59<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [01:59<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [01:59<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:00<00:33,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:00<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.51# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:01<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:01<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:02<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:02<00:31,  2.17it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:02<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:03<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:03<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.54# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:04<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:04<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:05<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:05<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:06<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:06<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.56# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:06<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:06<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:07<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:07<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:08<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:08<00:25,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:09<00:24,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.59# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:09<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:10<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:10<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:11<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:11<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:11<00:22,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:12<00:22,  2.17it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.61# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:12<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:12<00:21,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:13<00:20,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:13<00:20,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:14<00:19,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:14<00:19,  2.17it/s]Progress: 89.00%
---- avg training fps: 7.63# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:15<00:18,  2.17it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:15<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:16<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:16<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:16<00:17,  2.17it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:17<00:17,  2.15it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:17<00:16,  2.15it/s]Progress: 91.00%
---- avg training fps: 7.65# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:18<00:16,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:18<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:18<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:19<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:19<00:14,  2.16it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:20<00:13,  2.16it/s]Progress: 93.00%
---- avg training fps: 7.67# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:20<00:13,  2.16it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:20<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:21<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:21<00:12,  2.17it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:22<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:22<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:23<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.69# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:23<00:10,  2.17it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:24<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:24<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:25<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:25<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:25<00:08,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:25<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.71# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:26<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:26<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:27<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:27<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:28<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:28<00:05,  2.14it/s]Progress: 99.00%
---- avg training fps: 7.72# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:29<00:05,  2.13it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:29<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:30<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:30<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:30<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:31<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:31<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.74# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:31<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:32<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:32<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:33<00:01,  1.91it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:34<00:00,  2.00it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:34<00:00,  2.04it/s]Progress: 100.00%
---- avg training fps: 7.74Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.98it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.79it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.52it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.40it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.30it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.26it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.25it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.24it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.78it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.50it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.39it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.33it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.29it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.27it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.26it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.24it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.24it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.23it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.23it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.23it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.22it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.22it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.22it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.22it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.22it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.22it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.22it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.22it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.22it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.22it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.22it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.22it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.22it/s][A100%|██████████| 30/30 [00:09<00:00,  3.26it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.76it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.51it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.39it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.33it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.29it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.27it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.25it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.24it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.23it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.23it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.23it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.22it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.23it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.22it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.22it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.22it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.21it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.21it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.22it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.22it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.22it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.21it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.21it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.22it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.21it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.21it/s][A100%|██████████| 30/30 [00:09<00:00,  3.26it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.40it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.33it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.30it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.27it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.25it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.24it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.23it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.22it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.22it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.22it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.22it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.22it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.21it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.21it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.21it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.21it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.21it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.21it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.21it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.21it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.21it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.21it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.21it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.21it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.21it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.21it/s][A100%|██████████| 30/30 [00:09<00:00,  3.25it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.33it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.29it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.26it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.24it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.24it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.23it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.22it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.22it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.22it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.21it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.21it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.21it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.21it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.21it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.21it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.21it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.21it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.21it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.21it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.21it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.21it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.21it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.21it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.21it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.21it/s][A100%|██████████| 30/30 [00:09<00:00,  3.25it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.78it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.39it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.32it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.28it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.26it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.24it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.23it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.23it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.21it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.21it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.21it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.21it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.21it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.21it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.20it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.21it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.21it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.20it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.20it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.20it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.21it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.20it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.20it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.21it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.21it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.20it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.20it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.20it/s][A100%|██████████| 30/30 [00:09<00:00,  3.25it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:55<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 02:37:35.900290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:37:35.997660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:37:35.997687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:37:36.016597: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:37:36.415243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:37:36.415323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:37:36.415332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23100 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_02-37-38-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723509458.1703897 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 51371.16it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.70it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.54it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.83it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_02-37-38-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_02-37-38-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 770382.37it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1063344.68it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a visual style like Tarsem Singh's.
- In the style of TOK, a brigade of beavers is shown in a style similar to M. C. Escher's work.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, and rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting shows lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and packing peanuts swims up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 14869.51it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two individuals ...
12    in the style of <s0><s1><s2>, petroglyphs are ...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, trypophobia is v...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is show...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain is ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are pooping...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two individuals ...
39    in the style of <s0><s1><s2>, petroglyphs are ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:49,  2.97s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:55,  4.41s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:53,  2.60s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:39,  1.75s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:18,  1.28s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:54,  1.00s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.26# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:00,  1.22it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:25,  1.42it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:01,  1.60it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:46,  1.74it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:35,  1.86it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 3.59# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:21,  2.02it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:18,  2.07it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:18,  2.07it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:23,  1.98it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:18,  2.05it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:15,  2.10it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:12,  2.13it/s]Progress: 9.00%
---- avg training fps: 4.45# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:10,  2.15it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:09,  2.17it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:08,  2.17it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:07,  2.18it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:07,  2.17it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:06,  2.18it/s]Progress: 11.00%
---- avg training fps: 5.07# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:06,  2.18it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:06,  2.17it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:05,  2.18it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:05,  2.17it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:05,  2.17it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:59,  2.27it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:00,  2.24it/s]Progress: 13.00%
---- avg training fps: 5.55# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<02:01,  2.21it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:02,  2.19it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<02:02,  2.18it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:01,  2.19it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:01,  2.18it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<02:01,  2.17it/s]Progress: 15.00%
---- avg training fps: 5.90# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:01,  2.17it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<02:01,  2.16it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:00,  2.16it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<02:00,  2.16it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<01:59,  2.16it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.20# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:58,  2.17it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:53,  2.27it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:54,  2.24it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:54,  2.22it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:55,  2.20it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:54,  2.20it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:55,  2.18it/s]Progress: 19.00%
---- avg training fps: 6.43# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:55,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:55,  2.17it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:54,  2.17it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:42,  1.38s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:33,  1.11s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:44,  1.10it/s]Progress: 21.00%
---- avg training fps: 6.05# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:10,  1.29it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:46,  1.46it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:46,  1.46it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:25,  1.68it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:37<02:14,  1.80it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:07,  1.89it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:01,  1.97it/s]Progress: 23.00%
---- avg training fps: 6.24# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:58,  2.02it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:55,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:53,  2.08it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:40<02:11,  1.79it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<02:04,  1.89it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:41<01:58,  1.97it/s]Progress: 25.00%
---- avg training fps: 6.36# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:41<01:55,  2.02it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:52,  2.06it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:42<01:50,  2.10it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:43<01:42,  2.23it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:42,  2.22it/s]Progress: 27.00%
---- avg training fps: 6.52# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:44<01:43,  2.19it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:45<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:46<01:42,  2.17it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:46<01:42,  2.17it/s]Progress: 29.00%
---- avg training fps: 6.65# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:41,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:47<01:41,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:40,  2.17it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:39,  2.17it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:49<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 6.77# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:39,  2.17it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:35,  2.26it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:50<01:36,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:51<01:36,  2.20it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:36,  2.19it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.17it/s]Progress: 33.00%
---- avg training fps: 6.86# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:52<01:36,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:36,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:53<01:35,  2.16it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:35,  2.15it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:54<01:35,  2.15it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.95# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:55<01:34,  2.16it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:56<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:56<01:29,  2.26it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:30,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:57<01:30,  2.20it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:57,  1.20s/it]Progress: 37.00%
---- avg training fps: 6.75# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [01:00<03:12,  1.02it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:41,  1.21it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:01<02:19,  1.40it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<02:04,  1.56it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:02<01:53,  1.70it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:45,  1.82it/s]Progress: 39.00%
---- avg training fps: 6.84# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:03<01:40,  1.90it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:03<01:36,  1.97it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:04<01:33,  2.02it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:04<01:31,  2.06it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:31,  2.06it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:25,  2.18it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:05<01:25,  2.18it/s]Progress: 41.00%
---- avg training fps: 6.92# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:25,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:06<01:25,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:07<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:33,  1.93it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:08<01:30,  1.99it/s]Progress: 43.00%
---- avg training fps: 6.97# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:27,  2.05it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:09<01:25,  2.08it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:09<01:24,  2.10it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:10<01:23,  2.11it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:10<01:22,  2.12it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:11<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 7.04# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:11<01:21,  2.13it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:11<01:17,  2.24it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:12<01:17,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:12<01:18,  2.19it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:17,  2.19it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:13<01:17,  2.18it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.18it/s]Progress: 47.00%
---- avg training fps: 7.10# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:14<01:17,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:15<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:15<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:16<01:15,  2.15it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:16<01:15,  2.15it/s]Progress: 49.00%
---- avg training fps: 7.15# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:17<01:14,  2.15it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:17<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:18<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:18<01:10,  2.25it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:18<01:11,  2.21it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:11,  2.19it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:19<01:11,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.21# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:11,  2.16it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:20<01:11,  2.15it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:11,  2.14it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:21<01:11,  2.13it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:10,  2.15it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:22<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.25# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:09,  2.14it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:27<04:30,  1.83s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:28<03:28,  1.42s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:28<02:45,  1.13s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:29<02:45,  1.13s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:29<02:12,  1.10it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:29<01:52,  1.29it/s]Progress: 55.00%
---- avg training fps: 6.93# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:29<01:37,  1.47it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:30<01:27,  1.62it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:30<01:20,  1.75it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:31<01:15,  1.86it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:31<01:11,  1.94it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:32<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.99# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:32<01:07,  2.04it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:33<01:05,  2.06it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:33<01:04,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:34<01:03,  2.10it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:34<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:35<01:02,  2.13it/s]Progress: 59.00%
---- avg training fps: 7.04# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:35<01:02,  2.13it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:35<00:58,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:35<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:36<00:59,  2.18it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:36<00:59,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:37<00:58,  2.16it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:37<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.08# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:38<00:58,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:38<00:57,  2.14it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:39<00:57,  2.14it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:39<00:57,  2.14it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:40<00:56,  2.14it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:40<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.12# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:41<00:55,  2.13it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:41<00:55,  2.13it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:41<00:55,  2.13it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:41<00:52,  2.24it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:42<00:52,  2.21it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:42<00:52,  2.18it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:43<00:52,  2.17it/s]Progress: 65.00%
---- avg training fps: 7.16# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:43<00:52,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:44<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:44<00:51,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:45<00:51,  2.15it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:45<00:50,  2.14it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:46<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.20# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:46<00:49,  2.14it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:47<00:49,  2.13it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:47<00:48,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:48<00:48,  2.13it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:48<00:48,  2.13it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:48<00:46,  2.23it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:48<00:46,  2.20it/s]Progress: 69.00%
---- avg training fps: 7.24# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:49<00:46,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:49<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:50<00:45,  2.15it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:53<01:58,  1.21s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:53<01:35,  1.01it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:54<01:19,  1.20it/s]Progress: 71.00%
---- avg training fps: 7.10# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:54<01:16,  1.24it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:55<01:06,  1.42it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:55<00:58,  1.58it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:56<00:53,  1.72it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:56<00:49,  1.83it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:57<00:47,  1.91it/s]Progress: 73.00%
---- avg training fps: 7.14# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:57<00:47,  1.91it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:57<00:43,  2.06it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:58<00:42,  2.09it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:58<00:41,  2.11it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:59<00:40,  2.12it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:59<00:39,  2.13it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [02:00<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.17# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [02:00<00:38,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [02:00<00:38,  2.13it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:01<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:02<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:02<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:03<00:35,  2.14it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:03<00:35,  2.14it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:04<00:35,  2.14it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:04<00:33,  2.24it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:04<00:33,  2.22it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:05<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:05<00:33,  2.18it/s]Progress: 79.00%
---- avg training fps: 7.24# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:06<00:32,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:06<00:32,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:06<00:31,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:07<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:07<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:08<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.27# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:08<00:30,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:09<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:09<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:10<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:10<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:10<00:27,  2.26it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:11<00:26,  2.23it/s]Progress: 83.00%
---- avg training fps: 7.30# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:11<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:11<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:12<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:12<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:13<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:13<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.33# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:14<00:24,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:14<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:15<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:16<00:22,  2.16it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:19<01:07,  1.41s/it]Progress: 87.00%
---- avg training fps: 7.19# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:20<01:07,  1.41s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:20<00:52,  1.11s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:20<00:41,  1.10it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:21<00:35,  1.29it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:21<00:30,  1.46it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:22<00:26,  1.62it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:22<00:24,  1.75it/s]Progress: 89.00%
---- avg training fps: 7.22# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:22<00:22,  1.85it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:23<00:20,  1.94it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:23<00:19,  1.99it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:24<00:18,  2.04it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:24<00:17,  2.06it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:25<00:17,  2.09it/s]Progress: 91.00%
---- avg training fps: 7.24# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:25<00:16,  2.10it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:26<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:26<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:26<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:27<00:14,  2.20it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:27<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:28<00:13,  2.18it/s]Progress: 93.00%
---- avg training fps: 7.27# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:28<00:13,  2.17it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:28<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:29<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:29<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:30<00:11,  2.14it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:30<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.30# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:31<00:10,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:31<00:10,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:32<00:09,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:32<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:33<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:33<00:08,  2.26it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:33<00:08,  2.22it/s]Progress: 97.00%
---- avg training fps: 7.32# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:34<00:07,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:34<00:07,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:34<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:35<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:35<00:06,  2.15it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:36<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.35# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:36<00:05,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:37<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:37<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:38<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:38<00:03,  2.14it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:39<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.37# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:39<00:02,  2.14it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:39<00:02,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:40<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:40<00:01,  2.19it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:40<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:41<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:41<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.39# Trainer step: 294, epoch: 21: : 301it [02:42,  2.16it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.14it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.50it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.47it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.42it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.40it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.39it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.35it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.77it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.77it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:06,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 02:42:30.257978: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:42:30.350279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:42:30.350307: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:42:30.369065: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:42:30.771134: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:42:30.771189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:42:30.771197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23132 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_02-42-32-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723509752.5997176 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 6259.61it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.15it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.44it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.78it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.06it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_02-42-32-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 199728.76it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.57it/s] 20%|██        | 2/10 [00:00<00:02,  3.42it/s] 30%|███       | 3/10 [00:00<00:01,  4.10it/s] 40%|████      | 4/10 [00:01<00:01,  4.26it/s] 50%|█████     | 5/10 [00:01<00:01,  4.49it/s] 60%|██████    | 6/10 [00:01<00:00,  4.71it/s] 70%|███████   | 7/10 [00:01<00:00,  4.70it/s] 80%|████████  | 8/10 [00:01<00:00,  4.74it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.74it/s]100%|██████████| 10/10 [00:02<00:00,  4.91it/s]100%|██████████| 10/10 [00:02<00:00,  4.48it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, bold compositions.

- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red cloak standing in front of a building.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a camel in front of a mountain.
- In the style of TOK: A man standing on top of a sandy beach next to the ocean.
- In the style of TOK: A sunset over a desert landscape with a mountain in the background.
- In the style of TOK: A woman in a red dress walking through an archway.
- In the style of TOK: A person standing on top of a body of water.
- In the style of TOK: A person walking in the desert with a dog on a leash.
- In the style of TOK: A person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, bold compositions.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10288.35it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>: a sunset over a ...
1     in the style of <s0><s1><s2>: a woman in a red...
2     in the style of <s0><s1><s2>: a person standin...
3     in the style of <s0><s1><s2>: a person walking...
4     in the style of <s0><s1><s2>: a man standing o...
5     in the style of <s0><s1><s2>: a sunset over a ...
6     in the style of <s0><s1><s2>: a woman in a red...
7     in the style of <s0><s1><s2>: a person standin...
8     in the style of <s0><s1><s2>: a person walking...
9     in the style of <s0><s1><s2>: a person walking...
10    in the style of <s0><s1><s2>: a sunset over a ...
11    in the style of <s0><s1><s2>: a woman in a red...
12    in the style of <s0><s1><s2>: a person standin...
13    in the style of <s0><s1><s2>: a person walking...
14    in the style of <s0><s1><s2>: a man standing o...
15    in the style of <s0><s1><s2>: a sunset over a ...
16    in the style of <s0><s1><s2>: a woman in a red...
17    in the style of <s0><s1><s2>: a person standin...
18    in the style of <s0><s1><s2>: a person walking...
19    in the style of <s0><s1><s2>: a person walking...
20    in the style of <s0><s1><s2>: a sunset over a ...
21    in the style of <s0><s1><s2>: a woman in a red...
22    in the style of <s0><s1><s2>: a person standin...
23    in the style of <s0><s1><s2>: a person walking...
24    in the style of <s0><s1><s2>: a man standing o...
25    in the style of <s0><s1><s2>: a sunset over a ...
26    in the style of <s0><s1><s2>: a woman in a red...
27    in the style of <s0><s1><s2>: a person standin...
28    in the style of <s0><s1><s2>: a person walking...
29    in the style of <s0><s1><s2>: a person walking...
30    in the style of <s0><s1><s2>: a sunset over a ...
31    in the style of <s0><s1><s2>: a woman in a red...
32    in the style of <s0><s1><s2>: a person standin...
33    in the style of <s0><s1><s2>: a person walking...
34    in the style of <s0><s1><s2>: a man standing o...
35    in the style of <s0><s1><s2>: a sunset over a ...
36    in the style of <s0><s1><s2>: a woman in a red...
37    in the style of <s0><s1><s2>: a person standin...
38    in the style of <s0><s1><s2>: a person walking...
39    in the style of <s0><s1><s2>: a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:00,  3.01s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:53,  4.00s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:49,  2.39s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:00,  1.62s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:55,  1.20s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:39,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.40# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:51,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:19,  1.46it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:34,  1.87it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 3.70# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:40,  1.79it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:24,  1.97it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:19,  2.03it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:17,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.58# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:09,  2.14it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:07,  2.16it/s]Progress: 11.00%
---- avg training fps: 5.19# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.16it/s]Progress: 13.00%
---- avg training fps: 5.64# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.16it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:03,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:02,  2.16it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 5.98# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:02,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:59,  2.16it/s]Progress: 17.00%
---- avg training fps: 6.25# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:57,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:57,  2.15it/s]Progress: 19.00%
---- avg training fps: 6.47# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:56,  2.15it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:31,  1.58s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:07,  1.24s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:08,  1.01s/it]Progress: 21.00%
---- avg training fps: 5.97# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:27,  1.18it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:58,  1.36it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:38,  1.53it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:24,  1.68it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:14,  1.79it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]Progress: 23.00%
---- avg training fps: 6.16# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:02,  1.95it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:56,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:54,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:52,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:51,  2.10it/s]Progress: 25.00%
---- avg training fps: 6.32# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:49,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:47,  2.13it/s]Progress: 27.00%
---- avg training fps: 6.46# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.58# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:41,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.69# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:38,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.79# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:38,  2.14it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.88# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:35,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:02<05:38,  1.71s/it]Progress: 37.00%
---- avg training fps: 6.50# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:02<04:23,  1.34s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:03<03:30,  1.07s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:03<02:53,  1.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:04<02:28,  1.31it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:04<02:10,  1.48it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:05<01:57,  1.63it/s]Progress: 39.00%
---- avg training fps: 6.59# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:05<01:48,  1.76it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:06<01:42,  1.86it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:06<01:42,  1.86it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:06<01:37,  1.93it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:06<01:34,  2.00it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:07<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:07<01:30,  2.06it/s]Progress: 41.00%
---- avg training fps: 6.67# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:08<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:08<01:27,  2.10it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:09<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:09<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:10<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:10<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 6.74# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:11<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:11<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:11<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:12<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:12<01:22,  2.13it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:13<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:13<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 6.81# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:13<01:21,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:14<01:20,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:14<01:20,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:15<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:15<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:15<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:16<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 6.88# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:16<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:17<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:17<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:18<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:18<01:16,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:19<01:16,  2.13it/s]Progress: 49.00%
---- avg training fps: 6.93# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:19<01:15,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:20<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:20<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:21<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:21<01:13,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:21<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 6.99# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:22<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:22<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:23<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:23<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:24<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:24<01:10,  2.12it/s]Progress: 53.00%
---- avg training fps: 7.04# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:25<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:25<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:29<04:15,  1.73s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:30<03:18,  1.35s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:30<02:38,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:31<02:10,  1.11it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:31<01:50,  1.30it/s]Progress: 55.00%
---- avg training fps: 6.76# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:32<01:37,  1.47it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:32<01:27,  1.63it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:33<01:20,  1.75it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:33<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:34<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:34<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:34<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.82# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:35<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:35<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:36<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:36<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:36<01:03,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:37<01:02,  2.11it/s]Progress: 59.00%
---- avg training fps: 6.86# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:37<01:01,  2.12it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:38<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:38<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:38<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:39<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:39<00:59,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:40<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 6.91# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:40<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:41<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:41<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:42<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:42<00:56,  2.13it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 6.95# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:43<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:44<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:44<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:44<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:45<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:45<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.00# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:46<00:53,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:46<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:47<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:47<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:48<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:48<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:48<00:50,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.03# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:49<00:50,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:49<00:50,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:50<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:50<00:49,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:51<00:48,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:51<00:48,  2.11it/s]Progress: 69.00%
---- avg training fps: 7.07# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:52<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:52<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:52<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:52<00:46,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:57<02:53,  1.77s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:58<02:13,  1.38s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:58<01:46,  1.11s/it]Progress: 71.00%
---- avg training fps: 6.85# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:59<01:26,  1.09it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:59<01:13,  1.28it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [02:00<01:03,  1.45it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [02:00<00:57,  1.61it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:01<00:52,  1.74it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:01<00:48,  1.84it/s]Progress: 73.00%
---- avg training fps: 6.89# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:02<00:48,  1.84it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:02<00:46,  1.91it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:02<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:02<00:42,  2.02it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:03<00:41,  2.05it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:03<00:40,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:04<00:40,  2.10it/s]Progress: 75.00%
---- avg training fps: 6.92# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:04<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:05<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:05<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:07<00:36,  2.12it/s]Progress: 77.00%
---- avg training fps: 6.96# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:07<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:08<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:08<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:09<00:33,  2.12it/s]Progress: 79.00%
---- avg training fps: 6.99# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:10<00:33,  2.13it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:10<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:11<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:11<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:11<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:12<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:12<00:30,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.02# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:13<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:13<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:14<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:14<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:15<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:15<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.06# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:16<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:16<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:16<00:27,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:17<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:17<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:17<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:18<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.08# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:18<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:19<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:19<00:23,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:20<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:20<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:20<00:22,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:25<01:23,  1.73s/it]Progress: 87.00%
---- avg training fps: 6.91# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:25<01:03,  1.35s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:26<00:49,  1.08s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:26<00:40,  1.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:27<00:33,  1.30it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:27<00:29,  1.48it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:28<00:25,  1.63it/s]Progress: 89.00%
---- avg training fps: 6.94# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:28<00:23,  1.76it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:29<00:20,  1.94it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:30<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:30<00:18,  2.03it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:31<00:17,  2.06it/s]Progress: 91.00%
---- avg training fps: 6.97# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:31<00:16,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:31<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:32<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:32<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:33<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:33<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.00# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:34<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:34<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:34<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:35<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:35<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:36<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:36<00:11,  2.13it/s]Progress: 95.00%
---- avg training fps: 7.03# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:37<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:37<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:38<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:38<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:38<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:38<00:08,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:39<00:08,  2.13it/s]Progress: 97.00%
---- avg training fps: 7.05# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:39<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:40<00:07,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:40<00:07,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:41<00:06,  2.12it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:41<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:42<00:05,  2.12it/s]Progress: 99.00%
---- avg training fps: 7.08# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:42<00:05,  2.12it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:43<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:43<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:43<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:44<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:44<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:45<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.10# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:45<00:02,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:46<00:01,  2.08it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:46<00:01,  2.10it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:47<00:00,  2.10it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:47<00:00,  2.11it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:47<00:00,  2.12it/s]Progress: 100.00%
---- avg training fps: 7.13Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:08<00:00,  1.21it/s]
------------------------------------------
Training done :)
2024-08-13 02:47:06.925410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:47:07.016927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:47:07.016953: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:47:07.035677: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:47:07.434247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:47:07.434328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:47:07.434337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23134 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_02-47-09-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723510029.247109 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 15347.22it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.32it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.55it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.14it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.94it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_02-47-09-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.39it/s] 80%|████████  | 4/5 [00:02<00:00,  1.59it/s]100%|██████████| 5/5 [00:03<00:00,  1.08it/s]100%|██████████| 5/5 [00:03<00:00,  1.32it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.56it/s] 20%|██        | 2/10 [00:00<00:01,  4.49it/s] 30%|███       | 3/10 [00:00<00:01,  4.80it/s] 40%|████      | 4/10 [00:00<00:01,  4.92it/s] 50%|█████     | 5/10 [00:01<00:01,  4.88it/s] 60%|██████    | 6/10 [00:01<00:00,  4.91it/s] 70%|███████   | 7/10 [00:01<00:00,  5.11it/s] 80%|████████  | 8/10 [00:01<00:00,  5.19it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.19it/s]100%|██████████| 10/10 [00:02<00:00,  5.03it/s]100%|██████████| 10/10 [00:02<00:00,  4.93it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7293.81it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:39,  2.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:39,  3.35s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:02,  2.03s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:55,  1.40s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:12,  1.06s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:11,  1.17it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.72# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:32,  1.38it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:06,  1.57it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:48,  1.72it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:37,  1.84it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:37,  1.84it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:28,  1.94it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:23,  2.01it/s]Progress: 7.00%
---- avg training fps: 4.15# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:19,  2.06it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:17,  2.08it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:14,  2.12it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:12,  2.14it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:11,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:10,  2.16it/s]Progress: 9.00%
---- avg training fps: 5.03# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:10,  2.16it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:08,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:07,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:06,  2.19it/s]Progress: 11.00%
---- avg training fps: 5.62# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:05,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:04,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]Progress: 13.00%
---- avg training fps: 6.05# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:02,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:17,  1.94it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:12,  2.01it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:08,  2.06it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:06,  2.09it/s]Progress: 15.00%
---- avg training fps: 6.33# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:04,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:00,  2.16it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:00,  2.16it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.58# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.79# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:55,  2.18it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:46,  1.40s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:35,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:45,  1.09it/s]Progress: 21.00%
---- avg training fps: 6.32# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:11,  1.28it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:46,  1.46it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:30,  1.62it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:18,  1.75it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:09,  1.86it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.94it/s]Progress: 23.00%
---- avg training fps: 6.50# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:03,  1.94it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:59,  2.01it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:53,  2.09it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:51,  2.12it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:50,  2.13it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<02:02,  1.91it/s]Progress: 25.00%
---- avg training fps: 6.62# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:57,  1.98it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:54,  2.03it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:51,  2.07it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.76# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:45,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:44,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:43,  2.17it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:43,  2.17it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:42,  2.18it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:41,  2.18it/s]Progress: 29.00%
---- avg training fps: 6.88# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:41,  2.18it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.18it/s]Progress: 31.00%
---- avg training fps: 6.98# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:49<01:36,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 7.07# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:36,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:35,  2.17it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:34,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:34,  2.17it/s]Progress: 35.00%
---- avg training fps: 7.16# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:33,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:33,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:58<04:18,  1.31s/it]Progress: 37.00%
---- avg training fps: 6.89# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<03:27,  1.05s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:59<02:51,  1.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<02:26,  1.33it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:00<02:08,  1.51it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:01<02:07,  1.51it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:01<01:55,  1.67it/s]Progress: 39.00%
---- avg training fps: 6.95# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:02<01:46,  1.79it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:02<01:40,  1.89it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:03<01:40,  1.89it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:03<01:35,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:03<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:04<01:30,  2.07it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:04<01:28,  2.10it/s]Progress: 41.00%
---- avg training fps: 7.02# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:27,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:25,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:24,  2.16it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:06<01:23,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:22,  2.18it/s]Progress: 43.00%
---- avg training fps: 7.09# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:07<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:07<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:08<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:09<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:09<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:10<01:20,  2.17it/s]Progress: 45.00%
---- avg training fps: 7.15# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:10<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:11<01:18,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:17,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:17,  2.17it/s]Progress: 47.00%
---- avg training fps: 7.21# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:17,  2.17it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:13<01:16,  2.17it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:16,  2.17it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:14<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:15<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.26# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:13,  2.18it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:16<01:13,  2.17it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:16<01:13,  2.17it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:16<01:13,  2.17it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:17<01:12,  2.17it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:11,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:18<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.31# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:18<01:11,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:19<01:11,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:19<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:20<01:09,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.36# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:08,  2.17it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<03:51,  1.56s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<03:01,  1.23s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:26<02:26,  1.00s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<02:01,  1.19it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:27<01:44,  1.38it/s]Progress: 55.00%
---- avg training fps: 7.09# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:32,  1.55it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:28<01:23,  1.69it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:17,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:29<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:30<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.14# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:31<01:05,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:32<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:01,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:33<01:01,  2.15it/s]Progress: 59.00%
---- avg training fps: 7.19# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:33<01:01,  2.15it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:35<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.23# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:36<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:37<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:38<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.26# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:39<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:39<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:39<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:41<00:53,  2.15it/s]Progress: 65.00%
---- avg training fps: 7.30# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:42<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.34# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:45<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:46<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:46<00:47,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:47<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.37# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:47<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:48<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:29,  1.53s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:52<01:57,  1.21s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:34,  1.02it/s]Progress: 71.00%
---- avg training fps: 7.17# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:18,  1.21it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:07,  1.40it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<00:59,  1.56it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:55<00:54,  1.70it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:50,  1.81it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:47,  1.91it/s]Progress: 73.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:47,  1.91it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:45,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:43,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:42,  2.07it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:57<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:58<00:40,  2.12it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.24# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:38,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:38,  2.15it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:01<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.27# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:02<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:04<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.30# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:06<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:30,  2.16it/s]Progress: 81.00%
---- avg training fps: 7.33# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:07<00:30,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:08<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:09<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:28,  2.14it/s]Progress: 83.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:10<00:28,  2.14it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:10<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:11<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:12<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:12<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.38# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:13<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:23,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:14<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:22,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:19<01:17,  1.61s/it]Progress: 87.00%
---- avg training fps: 7.20# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:19<00:59,  1.26s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:20<00:47,  1.03s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:20<00:38,  1.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:21<00:32,  1.35it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:21<00:28,  1.52it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:22<00:25,  1.67it/s]Progress: 89.00%
---- avg training fps: 7.23# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:22<00:22,  1.79it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:23<00:21,  1.85it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:23<00:21,  1.85it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:23<00:20,  1.93it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:24<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:24<00:18,  2.03it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:25<00:17,  2.06it/s]Progress: 91.00%
---- avg training fps: 7.25# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:25<00:16,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:26<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:26<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:27<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:27<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:27<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.28# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:28<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:28<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:28<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:29<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:29<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:30<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:30<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.30# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:31<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:31<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:32<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:32<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:33<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:33<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:33<00:08,  2.13it/s]Progress: 97.00%
---- avg training fps: 7.32# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:34<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:34<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:34<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:35<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:35<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:36<00:05,  2.13it/s]Progress: 99.00%
---- avg training fps: 7.34# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:36<00:05,  2.12it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:37<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:37<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:37<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:38<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:38<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:39<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.37# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:39<00:02,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:40<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:40<00:01,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:41<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:41<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:42<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.38Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:02<00:00,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 02:51:41.127441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:51:41.218470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:51:41.218498: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:51:41.237292: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:51:41.637444: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:51:41.637529: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:51:41.637538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23134 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_02-51-43-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723510303.4602222 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 10375.90it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.15it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.56it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.77it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.05it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_02-51-43-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_02-51-43-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 427344.18it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1520083.33it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, bees are forming a blockchain.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is shown.
- In the style of TOK, the fear known as trypophobia is depicted.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a sense of visual storytelling similar to Tarsem Singh.
- In the style of TOK, a brigade of beavers is illustrated in an M. C. Escher-inspired design.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
--------------------------
GPT-4 returned the wrong number of prompts 26 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted, reminiscent of M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted, reminiscent of M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15137.84it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two individuals ...
12    in the style of <s0><s1><s2>, petroglyphs are ...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, trypophobia is v...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is show...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain is ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are pooping...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two individuals ...
39    in the style of <s0><s1><s2>, petroglyphs are ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:34,  2.92s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:33,  3.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:03,  2.44s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:08,  1.65s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:59,  1.22s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:40,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.40# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:51,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:18,  1.47it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:56,  1.65it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:41,  1.79it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:11<02:31,  1.91it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:24,  1.99it/s]Progress: 7.00%
---- avg training fps: 3.78# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:12<02:19,  2.05it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:15,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:13<02:15,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:13<02:22,  2.00it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:17,  2.07it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:14<02:14,  2.11it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:11,  2.14it/s]Progress: 9.00%
---- avg training fps: 4.64# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:15<02:10,  2.16it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:15<02:08,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:07,  2.19it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:16<02:06,  2.19it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:06,  2.20it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:17<02:05,  2.20it/s]Progress: 11.00%
---- avg training fps: 5.27# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:04,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:18<02:03,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:03,  2.22it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:19<02:02,  2.22it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:19<02:02,  2.22it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:19<01:57,  2.30it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:58,  2.27it/s]Progress: 13.00%
---- avg training fps: 5.75# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:20<01:59,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:21<02:00,  2.22it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<02:00,  2.21it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:22<02:00,  2.20it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:59,  2.21it/s]Progress: 15.00%
---- avg training fps: 6.10# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:23<01:59,  2.21it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:59,  2.20it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:58,  2.20it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:24<01:59,  2.18it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:59,  2.17it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:25<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.39# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:26<01:58,  2.17it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:26<01:54,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:26<01:55,  2.22it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:55,  2.20it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:27<01:56,  2.19it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:56,  2.18it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:28<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.60# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:56,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:56,  2.15it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:56,  2.15it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:33<05:59,  1.45s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:44,  1.15s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:34<03:52,  1.06it/s]Progress: 21.00%
---- avg training fps: 6.14# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:16,  1.25it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:35<02:51,  1.43it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:51,  1.43it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:28,  1.63it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:17,  1.76it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:36<02:09,  1.86it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:04,  1.93it/s]Progress: 23.00%
---- avg training fps: 6.33# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:37<01:59,  2.00it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:57,  2.03it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:38<01:55,  2.06it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:53,  2.08it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:39<01:52,  2.09it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:51,  2.10it/s]Progress: 25.00%
---- avg training fps: 6.48# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:40<01:50,  2.10it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:50,  2.11it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:49,  2.12it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:43,  2.21it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:43,  2.20it/s]Progress: 27.00%
---- avg training fps: 6.62# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<01:44,  2.17it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:43<01:44,  2.16it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:44,  2.15it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:44<01:44,  2.14it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:44,  2.14it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:45<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.74# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:43,  2.14it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:46<01:43,  2.13it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:42,  2.13it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:47<01:42,  2.12it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:42,  2.12it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:48<01:41,  2.12it/s]Progress: 31.00%
---- avg training fps: 6.85# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:41,  2.12it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:37,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:49<01:37,  2.19it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:38,  2.17it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:38,  2.15it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:50<01:38,  2.14it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:38,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.94# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:51<01:38,  2.13it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:37,  2.13it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:52<01:37,  2.12it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:37,  2.12it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:53<01:36,  2.12it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 7.02# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:54<01:35,  2.13it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:35,  2.12it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:35,  2.12it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:30,  2.21it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:31,  2.19it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:31,  2.17it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:58,  1.20s/it]Progress: 37.00%
---- avg training fps: 6.80# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<03:13,  1.02it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:42,  1.21it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:21,  1.38it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<02:05,  1.54it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:55,  1.67it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:47,  1.79it/s]Progress: 39.00%
---- avg training fps: 6.88# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:41,  1.87it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:03<01:37,  1.94it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:34,  1.99it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:04<01:32,  2.03it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:32,  2.03it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:27,  2.13it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:05<01:27,  2.13it/s]Progress: 41.00%
---- avg training fps: 6.95# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:26,  2.13it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:06<01:26,  2.13it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:26,  2.12it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:07<01:39,  1.83it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:34,  1.91it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:08<01:31,  1.97it/s]Progress: 43.00%
---- avg training fps: 6.99# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:28,  2.02it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:09<01:26,  2.05it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:09<01:25,  2.07it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:10<01:24,  2.09it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:10<01:23,  2.10it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:22,  2.11it/s]Progress: 45.00%
---- avg training fps: 7.06# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:11<01:22,  2.11it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:11<01:18,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:18,  2.18it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:18,  2.16it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:13<01:18,  2.15it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:18,  2.15it/s]Progress: 47.00%
---- avg training fps: 7.12# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:14<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:15<01:17,  2.14it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:15<01:16,  2.14it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:16<01:16,  2.13it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:16<01:15,  2.13it/s]Progress: 49.00%
---- avg training fps: 7.17# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:17<01:15,  2.14it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:17<01:14,  2.14it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:14,  2.14it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:11,  2.23it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:18<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:12,  2.17it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:19<01:12,  2.16it/s]Progress: 51.00%
---- avg training fps: 7.22# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:12,  2.15it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:20<01:11,  2.14it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:11,  2.15it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:21<01:10,  2.15it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:10,  2.14it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:22<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.27# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:09,  2.13it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:27<04:18,  1.75s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:27<03:20,  1.36s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:28<02:39,  1.09s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:28<02:39,  1.09s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:28<02:08,  1.13it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:29<01:49,  1.31it/s]Progress: 55.00%
---- avg training fps: 6.97# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:29<01:36,  1.48it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:30<01:27,  1.63it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:30<01:20,  1.75it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:31<01:15,  1.84it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:31<01:12,  1.92it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:31<01:09,  1.97it/s]Progress: 57.00%
---- avg training fps: 7.01# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:32<01:08,  2.01it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:32<01:06,  2.05it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:33<01:05,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:33<01:04,  2.08it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:34<01:03,  2.09it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:34<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.06# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:35<01:02,  2.10it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:35<00:59,  2.19it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:35<00:59,  2.18it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:36<00:59,  2.16it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:36<00:59,  2.15it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:37<00:59,  2.14it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:37<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 7.10# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:38<00:58,  2.13it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:38<00:58,  2.12it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:38<00:57,  2.13it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:39<00:57,  2.12it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:39<00:57,  2.12it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:40<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 7.14# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:40<00:56,  2.11it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:41<00:55,  2.11it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:41<00:55,  2.11it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:41<00:53,  2.20it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:42<00:53,  2.18it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:42<00:53,  2.16it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:43<00:53,  2.15it/s]Progress: 65.00%
---- avg training fps: 7.18# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:43<00:52,  2.14it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:44<00:52,  2.13it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:44<00:52,  2.13it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:45<00:51,  2.12it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:45<00:51,  2.12it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:45<00:50,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.21# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:46<00:50,  2.11it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:46<00:49,  2.12it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:47<00:49,  2.11it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:47<00:49,  2.10it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:48<00:49,  2.10it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:48<00:46,  2.20it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:48<00:46,  2.19it/s]Progress: 69.00%
---- avg training fps: 7.25# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:49<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:49<00:46,  2.15it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:50<00:46,  2.14it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:53<01:59,  1.21s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:53<01:44,  1.08s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:54<01:25,  1.12it/s]Progress: 71.00%
---- avg training fps: 7.11# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:54<01:12,  1.30it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:55<01:03,  1.48it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:55<00:57,  1.62it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:56<00:52,  1.75it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:56<00:49,  1.85it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:57<00:46,  1.93it/s]Progress: 73.00%
---- avg training fps: 7.14# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:57<00:46,  1.93it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:57<00:43,  2.07it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:58<00:42,  2.09it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:58<00:41,  2.10it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:58<00:40,  2.11it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:59<00:40,  2.11it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:59<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.18# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [02:00<00:39,  2.11it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [02:00<00:38,  2.12it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:01<00:38,  2.12it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:01<00:37,  2.12it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:02<00:37,  2.13it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:02<00:36,  2.13it/s]Progress: 77.00%
---- avg training fps: 7.21# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:03<00:36,  2.13it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:03<00:35,  2.13it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:04<00:35,  2.13it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:04<00:33,  2.23it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:04<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:05<00:33,  2.17it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:05<00:33,  2.15it/s]Progress: 79.00%
---- avg training fps: 7.24# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:05<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:06<00:32,  2.14it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:06<00:32,  2.13it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:07<00:31,  2.13it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:07<00:31,  2.12it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:08<00:31,  2.12it/s]Progress: 81.00%
---- avg training fps: 7.27# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:08<00:30,  2.12it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:09<00:30,  2.13it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:09<00:29,  2.13it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:10<00:29,  2.13it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:10<00:29,  2.13it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:10<00:27,  2.23it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:11<00:27,  2.21it/s]Progress: 83.00%
---- avg training fps: 7.30# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:11<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:12<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:12<00:26,  2.16it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:12<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:13<00:25,  2.15it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:13<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.32# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:14<00:24,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:14<00:24,  2.13it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:15<00:24,  2.12it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:15<00:23,  2.12it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:16<00:23,  2.13it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:20<01:10,  1.46s/it]Progress: 87.00%
---- avg training fps: 7.18# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:20<01:10,  1.46s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:20<00:53,  1.14s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:20<00:43,  1.06it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:21<00:36,  1.25it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:21<00:30,  1.43it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:22<00:27,  1.59it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:22<00:24,  1.72it/s]Progress: 89.00%
---- avg training fps: 7.21# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:23<00:22,  1.83it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:23<00:20,  1.91it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:24<00:19,  1.97it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:24<00:18,  2.02it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:25<00:18,  2.03it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:25<00:17,  2.05it/s]Progress: 91.00%
---- avg training fps: 7.23# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:26<00:16,  2.08it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:26<00:16,  2.09it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:26<00:16,  2.09it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:26<00:15,  2.20it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:27<00:14,  2.17it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:27<00:14,  2.16it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:28<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.26# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:28<00:13,  2.14it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:29<00:13,  2.14it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:29<00:12,  2.13it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:30<00:12,  2.12it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:30<00:11,  2.11it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:31<00:11,  2.12it/s]Progress: 95.00%
---- avg training fps: 7.28# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:31<00:10,  2.11it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:32<00:10,  2.12it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:32<00:09,  2.12it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:33<00:09,  2.12it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:33<00:09,  2.12it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:33<00:08,  2.22it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:33<00:08,  2.19it/s]Progress: 97.00%
---- avg training fps: 7.30# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:34<00:07,  2.16it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:34<00:07,  2.15it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:35<00:07,  2.14it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:35<00:06,  2.13it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:36<00:06,  2.14it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:36<00:05,  2.13it/s]Progress: 99.00%
---- avg training fps: 7.33# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:37<00:05,  2.13it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:37<00:04,  2.13it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:38<00:04,  2.13it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:38<00:03,  2.13it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:39<00:03,  2.12it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:39<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.35# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:40<00:02,  2.13it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:40<00:02,  2.22it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:40<00:01,  2.19it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:40<00:01,  2.16it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:41<00:00,  2.16it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:41<00:00,  2.14it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:42<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.37# Trainer step: 294, epoch: 21: : 301it [02:42,  2.13it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.10it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.61it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.56it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.53it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.48it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.45it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.44it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.43it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.43it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.42it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.42it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.41it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.41it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.40it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.40it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.39it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:06,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 02:56:39.413052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 02:56:39.504259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 02:56:39.504287: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 02:56:39.523641: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 02:56:39.926560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:56:39.926642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 02:56:39.926651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_02-56-41-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723510601.7071629 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 6232.79it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.32it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.38it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.82it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.10it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_02-56-41-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 199728.76it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.73it/s] 20%|██        | 2/10 [00:00<00:02,  3.56it/s] 30%|███       | 3/10 [00:00<00:01,  4.24it/s] 40%|████      | 4/10 [00:00<00:01,  4.46it/s] 50%|█████     | 5/10 [00:01<00:01,  4.65it/s] 60%|██████    | 6/10 [00:01<00:00,  4.83it/s] 70%|███████   | 7/10 [00:01<00:00,  4.80it/s] 80%|████████  | 8/10 [00:01<00:00,  4.94it/s] 90%|█████████ | 9/10 [00:01<00:00,  4.92it/s]100%|██████████| 10/10 [00:02<00:00,  5.07it/s]100%|██████████| 10/10 [00:02<00:00,  4.64it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, focus on vastness.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak stands in front of a building.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a camel in front of a mountain.
- In the style of TOK, a man stands on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walks through an archway.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a dog on a leash.
- In the style of TOK, a person walks on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, focus on vastness.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10286.46it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person stands ...
3     in the style of <s0><s1><s2>, a person walks i...
4     in the style of <s0><s1><s2>, a man stands on ...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person stands ...
8     in the style of <s0><s1><s2>, a person walks i...
9     in the style of <s0><s1><s2>, a person walks o...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person stands ...
13    in the style of <s0><s1><s2>, a person walks i...
14    in the style of <s0><s1><s2>, a man stands on ...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person stands ...
18    in the style of <s0><s1><s2>, a person walks i...
19    in the style of <s0><s1><s2>, a person walks o...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person stands ...
23    in the style of <s0><s1><s2>, a person walks i...
24    in the style of <s0><s1><s2>, a man stands on ...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person stands ...
28    in the style of <s0><s1><s2>, a person walks i...
29    in the style of <s0><s1><s2>, a person walks o...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person stands ...
33    in the style of <s0><s1><s2>, a person walks i...
34    in the style of <s0><s1><s2>, a man stands on ...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person stands ...
38    in the style of <s0><s1><s2>, a person walks i...
39    in the style of <s0><s1><s2>, a person walks o...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:36,  2.93s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:21,  3.90s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<11:30,  2.32s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:48,  1.58s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:46,  1.17s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:32,  1.08it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.46# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:45,  1.30it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:15,  1.50it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:54,  1.67it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:40,  1.81it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:40,  1.81it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:31,  1.91it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:24,  1.99it/s]Progress: 7.00%
---- avg training fps: 3.80# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:36,  1.83it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:27,  1.94it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:21,  2.01it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:14,  2.10it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:12,  2.14it/s]Progress: 9.00%
---- avg training fps: 4.69# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:09,  2.16it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:09,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:09,  2.17it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:08,  2.18it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:06,  2.19it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:05,  2.20it/s]Progress: 11.00%
---- avg training fps: 5.31# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:04,  2.20it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:04,  2.20it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:04,  2.20it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:04,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:03,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:03,  2.19it/s]Progress: 13.00%
---- avg training fps: 5.76# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:03,  2.19it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:02,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:01,  2.20it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:00,  2.19it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<01:59,  2.20it/s]Progress: 15.00%
---- avg training fps: 6.11# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<01:59,  2.20it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<01:59,  2.20it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<01:59,  2.19it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<01:58,  2.19it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<01:58,  2.19it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:58,  2.19it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:57,  2.19it/s]Progress: 17.00%
---- avg training fps: 6.39# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:57,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<01:56,  2.19it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:55,  2.20it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:55,  2.20it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:55,  2.20it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:54,  2.19it/s]Progress: 19.00%
---- avg training fps: 6.61# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:54,  2.19it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:53,  2.20it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:53,  2.20it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:53,  2.19it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:22,  1.54s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<05:00,  1.22s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<04:02,  1.01it/s]Progress: 21.00%
---- avg training fps: 6.10# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:22,  1.21it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:54,  1.40it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:35,  1.56it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:21,  1.71it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:11,  1.83it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:04,  1.93it/s]Progress: 23.00%
---- avg training fps: 6.29# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:04,  1.93it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:00,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<01:56,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:53,  2.08it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:51,  2.12it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<01:50,  2.13it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:49,  2.15it/s]Progress: 25.00%
---- avg training fps: 6.46# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:48,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:46,  2.17it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:46,  2.17it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:45,  2.18it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:44,  2.18it/s]Progress: 27.00%
---- avg training fps: 6.60# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:44,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:42,  2.17it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:45<01:42,  2.17it/s]Progress: 29.00%
---- avg training fps: 6.73# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:41,  2.18it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:41,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:41,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:40,  2.18it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:40,  2.17it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:39,  2.17it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 6.84# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:38,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:38,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:37,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:37,  2.17it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:36,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.94# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:51<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:35,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:34,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:33,  2.17it/s]Progress: 35.00%
---- avg training fps: 7.03# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:00<05:10,  1.57s/it]Progress: 37.00%
---- avg training fps: 6.65# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:01<04:18,  1.31s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:01<03:27,  1.06s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:02<02:51,  1.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:02<02:25,  1.33it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:03<02:07,  1.51it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:03<01:55,  1.67it/s]Progress: 39.00%
---- avg training fps: 6.74# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:04<01:46,  1.80it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:04<01:39,  1.90it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:05<01:39,  1.90it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:05<01:35,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:05<01:32,  2.04it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:05<01:29,  2.09it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:06<01:27,  2.12it/s]Progress: 41.00%
---- avg training fps: 6.82# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:06<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:07<01:25,  2.16it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:07<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:08<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:08<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:09<01:22,  2.18it/s]Progress: 43.00%
---- avg training fps: 6.90# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:09<01:22,  2.18it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:09<01:21,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:10<01:21,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:10<01:20,  2.19it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:10<01:20,  2.19it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:11<01:19,  2.19it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:11<01:19,  2.20it/s]Progress: 45.00%
---- avg training fps: 6.97# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:12<01:18,  2.20it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:12<01:18,  2.19it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:13<01:17,  2.19it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:13<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:14<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:14<01:17,  2.19it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:14<01:16,  2.19it/s]Progress: 47.00%
---- avg training fps: 7.03# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:15<01:16,  2.19it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:15<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:15<01:15,  2.19it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:16<01:15,  2.18it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:16<01:14,  2.18it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:17<01:14,  2.18it/s]Progress: 49.00%
---- avg training fps: 7.10# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:17<01:13,  2.19it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:18<01:13,  2.18it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:18<01:13,  2.18it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:18<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:19<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:19<01:11,  2.19it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:20<01:11,  2.19it/s]Progress: 51.00%
---- avg training fps: 7.15# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:20<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:21<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:21<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:21<01:09,  2.18it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:22<01:09,  2.18it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:22<01:08,  2.18it/s]Progress: 53.00%
---- avg training fps: 7.20# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:23<01:08,  2.18it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:23<01:08,  2.18it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:27<04:00,  1.62s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:28<03:07,  1.27s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:28<02:30,  1.03s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:29<02:04,  1.17it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:29<01:45,  1.36it/s]Progress: 55.00%
---- avg training fps: 6.94# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:29<01:33,  1.53it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:30<01:24,  1.68it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:30<01:18,  1.80it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:31<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:31<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:31<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:32<01:07,  2.03it/s]Progress: 57.00%
---- avg training fps: 6.99# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:32<01:06,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:33<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:33<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:34<01:02,  2.14it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:34<01:01,  2.15it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:34<01:01,  2.16it/s]Progress: 59.00%
---- avg training fps: 7.04# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:35<01:00,  2.16it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:35<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:36<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:36<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:36<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:37<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:37<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.09# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:38<00:57,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:38<00:57,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:39<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:39<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:40<00:55,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:40<00:55,  2.17it/s]Progress: 63.00%
---- avg training fps: 7.13# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:40<00:55,  2.17it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:40<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:41<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:41<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:42<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:42<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:43<00:52,  2.17it/s]Progress: 65.00%
---- avg training fps: 7.17# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:43<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:44<00:51,  2.17it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:44<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:45<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:45<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:45<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:46<00:49,  2.17it/s]Progress: 67.00%
---- avg training fps: 7.21# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:46<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:46<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:47<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:47<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:48<00:47,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:48<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.24# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:49<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:49<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:50<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:50<00:46,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:54<02:49,  1.73s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:55<02:11,  1.35s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:55<01:44,  1.09s/it]Progress: 71.00%
---- avg training fps: 7.01# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:56<01:25,  1.11it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:56<01:12,  1.29it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:57<01:03,  1.47it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:57<00:56,  1.62it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:58<00:52,  1.75it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:58<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 7.05# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:59<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:59<00:46,  1.92it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:59<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:00<00:43,  2.02it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:00<00:41,  2.05it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:01<00:40,  2.07it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:01<00:40,  2.09it/s]Progress: 75.00%
---- avg training fps: 7.08# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:01<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:02<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:02<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:03<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:03<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:03<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:04<00:36,  2.12it/s]Progress: 77.00%
---- avg training fps: 7.11# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:04<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:05<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:05<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:06<00:34,  2.12it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:06<00:34,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:07<00:33,  2.13it/s]Progress: 79.00%
---- avg training fps: 7.15# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:07<00:33,  2.12it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:08<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:08<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:08<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:09<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:09<00:31,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:09<00:31,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.17# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:10<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:10<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:11<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:11<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:12<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:12<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.20# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:13<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:13<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:13<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:14<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:14<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:15<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:15<00:25,  2.12it/s]Progress: 85.00%
---- avg training fps: 7.23# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:16<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:16<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:17<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:17<00:23,  2.09it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:18<00:23,  2.09it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:18<00:23,  2.10it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:22<01:19,  1.66s/it]Progress: 87.00%
---- avg training fps: 7.05# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:22<01:01,  1.30s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:23<00:48,  1.05s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:23<00:39,  1.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:24<00:33,  1.33it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:24<00:28,  1.50it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:25<00:25,  1.65it/s]Progress: 89.00%
---- avg training fps: 7.08# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:25<00:23,  1.78it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:26<00:21,  1.88it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:26<00:21,  1.88it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:26<00:19,  1.96it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:27<00:18,  2.01it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:27<00:18,  2.05it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:28<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 7.11# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:28<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:28<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:29<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:29<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:30<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:30<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.14# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:31<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:31<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:31<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:32<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:32<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:33<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:33<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.17# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:34<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:34<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:34<00:09,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:35<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:35<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:35<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:36<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.19# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:36<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:37<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:37<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:38<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:38<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:39<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.22# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:39<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:40<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:41<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:41<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.24# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:42<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:42<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:43<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:43<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:44<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:44<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.27Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.52it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.49it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.46it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.44it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.42it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.42it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.40it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.37it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:04<00:00,  1.23it/s]
------------------------------------------
Training done :)
2024-08-13 03:01:13.466052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:01:13.557897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:01:13.557922: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:01:13.576468: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:01:13.979733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:01:13.979813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:01:13.979822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23126 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_03-01-15-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723510875.7981896 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 17115.50it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.53it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.58it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.82it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_03-01-15-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_03-01-15-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 276210.26it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1121249.58it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a visual style like Tarsem Singh's.
- In the style of TOK, a brigade of beavers is shown in a style similar to M. C. Escher's work.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, and rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting shows lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
--------------------------
GPT-4 returned the wrong number of prompts 53 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from waste materials swims underwater in the ocean.
- In the style of TOK, a throng of tiny Lilliputians are packed inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is set in Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "best of times, worst of times" represents contrasting periods.
- In the style of TOK, bees are organized in a blockchain formation.
- In the style of TOK, a gorgon composed of sharks cannibalizes each other while swimming underwater.
- In the style of TOK, Venus and Earth are depicted circling the sun against a sunset hillside.
- In the style of TOK, an ancient temple is found in the depths of the Amazon jungle.
- In the style of TOK, cats are depicted pooping in zero-gravity.
- In the style of TOK, a goblin-goat hybrid is featured.
- In the style of TOK, the phrase "age of wisdom, age of foolishness" denotes contrasting periods.
- In the style of TOK, two people discuss quitting their monotonous corporate jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, room and space exchange occurs based on first and second-degree connections.
- In the style of TOK, images invoke a sense of trypophobia.
- In the style of TOK, a 6-pack is metaphorically described as nightmare fuel.
- In the style of TOK, a band of beavers are dancing and singing, reminiscent of Jim Henson's Muppets.
- In the style of TOK, a beaver is seen gnawing a rifle in half.
- In the style of TOK, a brigade of beavers rapidly constructs a dam as if on a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers rapidly constructs a dam in a manner reminiscent of Tarsem Singh.
- In the style of TOK, a brigade of beavers creates structures in an M. C. Escher-like fashion.
- In the style of TOK, a castle moves along grassy hills.
- In the style of TOK, a chorus line of beavers dance adorably in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, discovered in the space age.
- In the style of TOK, elephant seals model on a runway while egrets sit in the audience at a fashion show.
- In the style of TOK, a hyper-realistic painting features lemon-lime architecture.
- In the style of TOK, a mermaid made from debris and trash rises through the water's surface.
- In the style of TOK, a mermaid made from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, a mass of Lilliputians fill the pores of a giant sea-sponge.
- In the style of TOK, the scene depicts Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "best of times, worst of times" symbolizes contrasting periods.
- In the style of TOK, bees are arranged in a blockchain.
- In the style of TOK, a shark-based gorgon engages in cannibalistic behavior underwater.
- In the style of TOK, Venus and Earth are shown circling the sun over a sunset hillside.
- In the style of TOK, an ancient temple is set deep within the Amazon jungle.
- In the style of TOK, cats defy gravity to poop in zero-gravity.
- In the style of TOK, a goblin-goat hybrid creature is present.
- In the style of TOK, the phrase "age of wisdom, age of foolishness" suggests contrasting periods.
- In the style of TOK, individuals discuss quitting their dull corporate jobs.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange is portrayed based on connections.
- In the style of TOK, expressions evoke trypophobia.
- In the style of TOK, a 6-pack evokes a nightmare-like quality.
- In the style of TOK, a group of beavers engages in singing and dancing similar to Jim Henson's Muppets.
- In the style of TOK, a beaver gnaws a rifle in half.
- In the style of TOK, beavers rapidly construct a dam influenced by Hawaiian-shirt patterns.
- In the style of TOK, beavers build a dam reminiscent of Tarsem Singh’s work.
- In the style of TOK, beavers craft structures in an Escher-like manner.
- In the style of TOK, a moving castle traverses grassy hills.
- In the style of TOK, a chorus line of beavers dance in syncronization.
- In the style of TOK, a 1950s restaurant kitchen is found frozen and preserved in the space age.
- In the style of TOK, elephant seals model while egrets watch at a fashion show.
- In the style of TOK, lemon-lime architecture is depicted in hyper-realistic painting.
--------------------------
GPT-4 returned the wrong number of prompts 53 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 4...
----- GPT response: -----
Style Description: Surreal and fantastical imagery

- In the style of TOK, a mermaid constructed from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, a scenic view of Fort Kochi, Kerala, India.
- In the style of TOK, a depiction of the phrase "the best of times, the worst of times."
- In the style of TOK, a blockchain made up of bees.
- In the style of TOK, a gorgon composed of sharks eating each other, swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin is depicted as a goat.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness."
- In the style of TOK, two characters decide to quit their boring corporate job together.
- In the style of TOK, petroglyphs are etched into stone.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, an image invoking trypophobia.
- In the style of TOK, a six-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers builds a dam as seen in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers constructs a dam in a Tarsem Singh-inspired scene.
- In the style of TOK, a brigade of beavers is depicted in an M. C. Escher style.
- In the style of TOK, a castle moves along the ground on grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and sea trash swims up through the sea to peek above the water.

--------------------------
GPT-4 returned the wrong number of prompts 28 instead of 54, retrying...
WARNING: no captioning text was given and we're not doing chatgpt cleanup...
Concept mode:  style
Using GPT concept name as CLIP-segmentation prompt: Surreal and fantastical imagery
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15030.35it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, they were the be...
4     in the style of <s0><s1><s2>, a blockchain of ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats pooping in ...
9             in the style of <s0><s1><s2>, goblin goat
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, let's quit our b...
12            in the style of <s0><s1><s2>, petroglyphs
13    in the style of <s0><s1><s2>, room and space e...
14            in the style of <s0><s1><s2>, trypophobia
15    in the style of <s0><s1><s2>, a 6-pack of nigh...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle that is...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi, kera...
30    in the style of <s0><s1><s2>, they were the be...
31    in the style of <s0><s1><s2>, a blockchain of ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats pooping in ...
36            in the style of <s0><s1><s2>, goblin goat
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, let's quit our b...
39            in the style of <s0><s1><s2>, petroglyphs
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:05,  3.03s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<22:16,  4.49s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<13:07,  2.65s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:49,  1.79s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:27,  1.31s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<05:01,  1.03s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.21# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:07,  1.19it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:31,  1.38it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:07,  1.55it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:51,  1.69it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:39,  1.81it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:13<02:31,  1.89it/s]Progress: 7.00%
---- avg training fps: 3.51# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:26,  1.96it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:14<02:22,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:22,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:27,  1.93it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:15<02:23,  1.98it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:19,  2.02it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:16<02:17,  2.05it/s]Progress: 9.00%
---- avg training fps: 4.34# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:15,  2.08it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:17<02:13,  2.09it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:12,  2.10it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:18<02:11,  2.11it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:10,  2.12it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:10,  2.12it/s]Progress: 11.00%
---- avg training fps: 4.94# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:09,  2.13it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:09,  2.12it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:20<02:08,  2.13it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:08,  2.12it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:21<02:08,  2.12it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:21<02:01,  2.22it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:03,  2.19it/s]Progress: 13.00%
---- avg training fps: 5.41# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:22<02:03,  2.18it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:04,  2.16it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:23<02:04,  2.15it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:04,  2.14it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:24<02:03,  2.14it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:24<02:03,  2.14it/s]Progress: 15.00%
---- avg training fps: 5.76# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:03,  2.13it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:25<02:02,  2.13it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:02,  2.13it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:26<02:02,  2.13it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<02:01,  2.13it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:27<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.06# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<02:00,  2.14it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:55,  2.23it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:28<01:56,  2.20it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:57,  2.18it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:29<01:57,  2.16it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:29<01:57,  2.15it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:30<01:57,  2.14it/s]Progress: 19.00%
---- avg training fps: 6.28# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:30<01:57,  2.13it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:31<01:58,  2.12it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:31<01:57,  2.12it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:20,  1.29s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:35<04:18,  1.05s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:35,  1.14it/s]Progress: 21.00%
---- avg training fps: 5.98# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:36<03:04,  1.33it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:43,  1.49it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:37<02:43,  1.49it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:37<02:23,  1.70it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:37<02:14,  1.80it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:07,  1.89it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:38<02:03,  1.95it/s]Progress: 23.00%
---- avg training fps: 6.17# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:59,  2.00it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:39<01:56,  2.04it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:55,  2.06it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:40<01:53,  2.08it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<01:52,  2.09it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:41<01:51,  2.10it/s]Progress: 25.00%
---- avg training fps: 6.33# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:41<01:50,  2.11it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:42<01:49,  2.11it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:42<01:49,  2.12it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:43<01:43,  2.21it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:44<01:44,  2.19it/s]Progress: 27.00%
---- avg training fps: 6.48# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:44<01:44,  2.17it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:45,  2.15it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:44,  2.14it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:46<02:03,  1.81it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:47<01:57,  1.89it/s]Progress: 29.00%
---- avg training fps: 6.56# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:47<01:53,  1.95it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:48<01:49,  2.01it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:48<01:47,  2.04it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:45,  2.07it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:49<01:43,  2.09it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:49<01:43,  2.10it/s]Progress: 31.00%
---- avg training fps: 6.68# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:50<01:43,  2.10it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:50<01:37,  2.20it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:50<01:38,  2.18it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:51<01:38,  2.17it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:51<01:38,  2.16it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:52<01:38,  2.15it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:52<01:37,  2.15it/s]Progress: 33.00%
---- avg training fps: 6.77# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:53<01:37,  2.15it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:53<01:37,  2.14it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:54<01:36,  2.14it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:54<01:36,  2.14it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:55<01:35,  2.14it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:55<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.86# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:55<01:35,  2.12it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:56<01:34,  2.13it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:56<01:34,  2.13it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:56<01:30,  2.22it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:57<01:30,  2.20it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:57<01:31,  2.18it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [01:00<03:31,  1.07s/it]Progress: 37.00%
---- avg training fps: 6.72# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [01:00<02:54,  1.13it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:01<02:29,  1.31it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:01<02:11,  1.49it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:02<01:58,  1.63it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:02<01:49,  1.76it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:03<01:43,  1.85it/s]Progress: 39.00%
---- avg training fps: 6.80# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:03<01:39,  1.93it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:04<01:36,  1.98it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:04<01:33,  2.02it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:04<01:31,  2.05it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:05<01:31,  2.05it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:05<01:26,  2.16it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:05<01:26,  2.15it/s]Progress: 41.00%
---- avg training fps: 6.88# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:06<01:26,  2.14it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:06<01:26,  2.13it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:07<01:26,  2.13it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:07<01:25,  2.13it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:08<01:24,  2.13it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:08<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 6.94# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:09<01:24,  2.13it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:09<01:23,  2.12it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:10<01:23,  2.13it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:10<01:23,  2.12it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:11<01:22,  2.12it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:11<01:21,  2.12it/s]Progress: 45.00%
---- avg training fps: 7.01# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:11<01:21,  2.12it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:11<01:17,  2.22it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:12<01:18,  2.19it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:13<01:18,  2.16it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:13<01:18,  2.15it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:14<01:18,  2.14it/s]Progress: 47.00%
---- avg training fps: 7.07# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:14<01:18,  2.13it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:15<01:18,  2.13it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:15<01:17,  2.12it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:16<01:17,  2.13it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:16<01:16,  2.13it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:17<01:16,  2.13it/s]Progress: 49.00%
---- avg training fps: 7.12# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:17<01:15,  2.13it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:18<01:15,  2.12it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:18<01:15,  2.12it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:18<01:11,  2.22it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:18<01:12,  2.19it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:19<01:12,  2.17it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:19<01:12,  2.15it/s]Progress: 51.00%
---- avg training fps: 7.17# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:20<01:12,  2.14it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:20<01:12,  2.13it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:21<01:11,  2.13it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:21<01:19,  1.92it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:22<01:16,  1.98it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:22<01:14,  2.02it/s]Progress: 53.00%
---- avg training fps: 7.20# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:23<01:12,  2.05it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:26<03:30,  1.42s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:27<02:46,  1.14s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:27<02:16,  1.07it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:28<02:16,  1.07it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:28<01:52,  1.29it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:28<01:38,  1.46it/s]Progress: 55.00%
---- avg training fps: 7.00# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:29<01:28,  1.61it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:29<01:21,  1.74it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:30<01:16,  1.84it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:30<01:13,  1.92it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:31<01:10,  1.97it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:31<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.04# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:32<01:07,  2.04it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:32<01:05,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:32<01:04,  2.08it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:33<01:03,  2.10it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:33<01:03,  2.10it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:34<01:02,  2.11it/s]Progress: 59.00%
---- avg training fps: 7.09# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:34<01:02,  2.11it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:34<00:59,  2.20it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:35<00:59,  2.18it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:35<00:59,  2.16it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:36<00:59,  2.15it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:36<00:59,  2.14it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:37<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 7.13# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:37<00:58,  2.12it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:38<00:58,  2.12it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:38<00:58,  2.12it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:39<00:57,  2.12it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:39<00:57,  2.12it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:39<00:56,  2.12it/s]Progress: 63.00%
---- avg training fps: 7.17# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:40<00:56,  2.12it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:40<00:55,  2.12it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:41<00:55,  2.12it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:41<00:52,  2.22it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:41<01:00,  1.93it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:42<00:57,  1.98it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:42<00:56,  2.03it/s]Progress: 65.00%
---- avg training fps: 7.20# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:43<00:54,  2.06it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:43<00:53,  2.08it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:44<00:53,  2.09it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:44<00:52,  2.10it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:45<00:51,  2.11it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:45<00:51,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.23# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:46<00:50,  2.12it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:46<00:49,  2.12it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:47<00:49,  2.12it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:47<00:48,  2.13it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:48<00:48,  2.13it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:48<00:46,  2.22it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:48<00:46,  2.19it/s]Progress: 69.00%
---- avg training fps: 7.27# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:48<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:49<00:46,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:49<00:46,  2.15it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:52<01:41,  1.04s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:52<01:23,  1.16it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:53<01:11,  1.34it/s]Progress: 71.00%
---- avg training fps: 7.18# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:53<01:03,  1.51it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:54<00:56,  1.65it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:54<00:52,  1.77it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:55<00:49,  1.87it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:55<00:47,  1.93it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:56<00:45,  1.98it/s]Progress: 73.00%
---- avg training fps: 7.21# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:56<00:45,  1.98it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:56<00:42,  2.11it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:56<00:41,  2.12it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:57<00:40,  2.12it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:57<00:40,  2.13it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:58<00:40,  2.12it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:58<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.24# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:00<00:38,  2.12it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:00<00:37,  2.12it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:01<00:37,  2.12it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:01<00:36,  2.12it/s]Progress: 77.00%
---- avg training fps: 7.27# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:02<00:36,  2.12it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:02<00:37,  2.05it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:03<00:37,  2.05it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:03<00:34,  2.16it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:03<00:34,  2.16it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:03<00:33,  2.16it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:04<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.30# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:04<00:33,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:05<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:06<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:06<00:31,  2.14it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:07<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.33# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:07<00:30,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:08<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:08<00:29,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:09<00:28,  2.14it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:09<00:28,  2.14it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:09<00:26,  2.26it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:09<00:26,  2.23it/s]Progress: 83.00%
---- avg training fps: 7.36# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:10<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:10<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:11<00:26,  2.18it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:11<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:12<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:12<00:24,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.39# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:13<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:13<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:14<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:14<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:15<00:22,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:18<01:05,  1.37s/it]Progress: 87.00%
---- avg training fps: 7.26# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:18<01:05,  1.37s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:18<00:50,  1.08s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:19<00:41,  1.12it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:19<00:34,  1.31it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:20<00:29,  1.48it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:20<00:26,  1.64it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:21<00:23,  1.77it/s]Progress: 89.00%
---- avg training fps: 7.28# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:21<00:21,  1.86it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:22<00:20,  1.94it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:22<00:19,  2.00it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:23<00:18,  2.05it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:23<00:17,  2.08it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:24<00:17,  2.09it/s]Progress: 91.00%
---- avg training fps: 7.31# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:24<00:16,  2.11it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:24<00:15,  2.13it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:25<00:15,  2.13it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:25<00:14,  2.23it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:25<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:26<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:26<00:13,  2.18it/s]Progress: 93.00%
---- avg training fps: 7.34# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:27<00:13,  2.17it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:27<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:28<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:28<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:29<00:11,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:29<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.36# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:30<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:30<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:30<00:09,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:31<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:31<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:31<00:08,  2.24it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:32<00:08,  2.21it/s]Progress: 97.00%
---- avg training fps: 7.39# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:32<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:33<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:33<00:06,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:34<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:34<00:06,  2.15it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:35<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.41# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:35<00:05,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:35<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:36<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:36<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:37<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:37<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.43# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:38<00:02,  2.16it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:38<00:02,  2.26it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:38<00:01,  2.23it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:39<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:39<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:40<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:40<00:00,  2.18it/s]Progress: 100.00%
---- avg training fps: 7.45# Trainer step: 294, epoch: 21: : 301it [02:41,  2.17it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.98it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.51it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.48it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.46it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.44it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.42it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.40it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.40it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.40it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.38it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.37it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.93it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 03:06:27.930809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:06:28.022152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:06:28.022179: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:06:28.040942: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:06:28.440973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:06:28.441054: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:06:28.441063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23096 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_03-06-30-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723511190.2575362 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 18818.47it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.54it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.53it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.82it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.11it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_03-06-30-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_03-06-30-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 442368.00it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1167486.68it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and foolishness.
- In the style of TOK, the message is to quit a boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange are based on first and second-degree connections.
- In the style of TOK, the concept of trypophobia is represented.
- In the style of TOK, six-pack containers burst with nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers performs.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets as the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and other sea trash swims up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and sea trash, is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and sea trash, is swimming up through the sea to take a peak above water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from waste materials swims underwater.
- In the style of TOK, a group of tiny Lilliputians is inside a giant sea-sponge.
- In the style of TOK, the scene depicts Fort Kochi, Kerala, India.
- In the style of TOK, the statement illustrates the contrast of best and worst times.
- In the style of TOK, a chain of bees is linked together.
- In the style of TOK, a gorgon composed of intertwining sharks swims underwater.
- In the style of TOK, Venus and Earth circle the sun on a hillside at sunset.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats defecate in zero-gravity.
- In the style of TOK, a goblin that resembles a goat.
- In the style of TOK, the phrase contrasts wisdom and foolishness.
- In the style of TOK, two people discuss quitting their corporation jobs together.
- In the style of TOK, ancient petroglyphs are depicted.
- In the style of TOK, room and space exchange is based on connections.
- In the style of TOK, the imagery evokes trypophobia.
- In the style of TOK, a 6-pack contains nightmarish substances.
- In the style of TOK, a band of beavers sings and dances, similar to Jim Henson's Muppets.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers rapidly constructs a dam, patterned like Hawaiian shirts.
- In the style of TOK, a brigade of beavers builds a dam quickly, similar to a Tarsem Singh film.
- In the style of TOK, a brigade of beavers is presented as if in an M. C. Escher artwork.
- In the style of TOK, a castle moves across grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a 1950s restaurant kitchen, frozen and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as models and egrets in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid composed of waste materials swims to peek above the sea.
- In the style of TOK, a mermaid fashioned from waste swims underwater.
- In the style of TOK, many tiny Lilliputians inhabit a giant sea-sponge.
- In the style of TOK, the setting is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase contrasts the best and worst of times.
- In the style of TOK, a blockchain composed of bees.
- In the style of TOK, a gorgon made of sharks is underwater.
- In the style of TOK, at sunset, Venus and Earth circle the sun on a hillside.
- In the style of TOK, deep in the Amazon jungle, an ancient temple stands.
- In the style of TOK, cats are defecating in zero-gravity.
- In the style of TOK, a fantastical goblin goat is depicted.
- In the style of TOK, the phrase contrasts wisdom and foolishness.
- In the style of TOK, individuals decide to quit their boring corporate jobs.
- In the style of TOK, ancient petroglyphs are displayed.
- In the style of TOK, room and space exchange is based on connections.
- In the style of TOK, the visual triggers trypophobia.
- In the style of TOK, a 6-pack contains nightmare-inducing imagery.
- In the style of TOK, singing and dancing beavers perform like Jim Henson's Muppets.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers rapidly constructs a dam with Hawaiian-themed patterns.
- In the style of TOK, a brigade of beavers builds a dam swiftly, resembling a Tarsem Singh scene.
- In the style of TOK, a brigade of beavers is illustrated in an M. C. Escher style.
- In the style of TOK, a mobile castle traverses grassy hills.
- In the style of TOK, dancing beavers perform in unison.
- In the style of TOK, a preserved 1950s restaurant kitchen is rediscovered in the space age.
- In the style of TOK, elephant seals model in a fashion show with egrets as spectators.
- In the style of TOK, a painting of lemon-lime architecture appears hyper-realistic.
- In the style of TOK, a mermaid constructed from sea trash swims up to peek above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surreal and intricate marine or forest scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15582.55it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid crafte...
1     in the style of <s0><s1><s2>, a group of tiny ...
2     in the style of <s0><s1><s2>, the scene depict...
3     in the style of <s0><s1><s2>, the statement il...
4     in the style of <s0><s1><s2>, a chain of bees ...
5     in the style of <s0><s1><s2>, a gorgon compose...
6     in the style of <s0><s1><s2>, venus and earth ...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats defecate in...
9     in the style of <s0><s1><s2>, a goblin that re...
10    in the style of <s0><s1><s2>, the phrase contr...
11    in the style of <s0><s1><s2>, two people discu...
12    in the style of <s0><s1><s2>, ancient petrogly...
13    in the style of <s0><s1><s2>, room and space e...
14    in the style of <s0><s1><s2>, the imagery evok...
15    in the style of <s0><s1><s2>, a 6-pack contain...
16    in the style of <s0><s1><s2>, a band of beaver...
17    in the style of <s0><s1><s2>, a beaver chews a...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle moves a...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a 1950s restaura...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid compos...
27    in the style of <s0><s1><s2>, a mermaid fashio...
28    in the style of <s0><s1><s2>, many tiny lillip...
29    in the style of <s0><s1><s2>, the setting is f...
30    in the style of <s0><s1><s2>, the phrase contr...
31    in the style of <s0><s1><s2>, a blockchain com...
32    in the style of <s0><s1><s2>, a gorgon made of...
33    in the style of <s0><s1><s2>, at sunset, venus...
34    in the style of <s0><s1><s2>, deep in the amaz...
35    in the style of <s0><s1><s2>, cats are defecat...
36    in the style of <s0><s1><s2>, a fantastical go...
37    in the style of <s0><s1><s2>, the phrase contr...
38    in the style of <s0><s1><s2>, individuals deci...
39    in the style of <s0><s1><s2>, ancient petrogly...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:29,  2.91s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<18:56,  3.81s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<11:16,  2.28s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:04,  1.64s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:55,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:38,  1.06it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.45# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:49,  1.28it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:17,  1.48it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:55,  1.66it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:41,  1.80it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:11<02:31,  1.91it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:23,  2.00it/s]Progress: 7.00%
---- avg training fps: 3.85# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:12<02:18,  2.07it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:12<02:15,  2.12it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:13<02:15,  2.12it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:13<02:21,  2.02it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:13<02:16,  2.08it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:14<02:13,  2.13it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:14<02:10,  2.16it/s]Progress: 9.00%
---- avg training fps: 4.72# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:15<02:08,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:15<02:07,  2.20it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:05,  2.22it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:16<02:05,  2.22it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:04,  2.22it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:17<02:03,  2.23it/s]Progress: 11.00%
---- avg training fps: 5.35# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:17<02:03,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:18<02:02,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:18<02:02,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:19<02:02,  2.23it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:19<02:02,  2.23it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:19<01:57,  2.31it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:57,  2.29it/s]Progress: 13.00%
---- avg training fps: 5.84# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:20<01:58,  2.27it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:58,  2.26it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:21<01:58,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:21<01:58,  2.24it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:22<01:58,  2.24it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:22<01:58,  2.24it/s]Progress: 15.00%
---- avg training fps: 6.19# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:23<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:23<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:24<01:56,  2.23it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:56,  2.23it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:25<01:56,  2.22it/s]Progress: 17.00%
---- avg training fps: 6.49# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:25<01:56,  2.22it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:25<01:51,  2.31it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:26<01:52,  2.28it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:26<01:52,  2.26it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:27<01:52,  2.25it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:27<01:52,  2.24it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:28<01:52,  2.23it/s]Progress: 19.00%
---- avg training fps: 6.71# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:28<01:53,  2.22it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:53,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:29<01:52,  2.21it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:32<05:11,  1.26s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:33<04:10,  1.02s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:33<03:41,  1.11it/s]Progress: 21.00%
---- avg training fps: 6.32# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:34<03:07,  1.31it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:34<02:43,  1.49it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:35<02:43,  1.49it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:35<02:22,  1.71it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:35<02:12,  1.83it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:35<02:05,  1.92it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:36<01:59,  2.00it/s]Progress: 23.00%
---- avg training fps: 6.51# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:36<01:55,  2.06it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:37<01:52,  2.11it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:37<01:50,  2.14it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:38<01:49,  2.16it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:38<01:48,  2.16it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:39<01:47,  2.18it/s]Progress: 25.00%
---- avg training fps: 6.67# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:39<01:46,  2.19it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:40<01:45,  2.19it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:40<01:45,  2.19it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:40<01:44,  2.19it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:41<01:44,  2.19it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:41<01:39,  2.29it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:41<01:40,  2.26it/s]Progress: 27.00%
---- avg training fps: 6.82# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:42<01:41,  2.24it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:42<01:41,  2.22it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:43<01:41,  2.21it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:43<01:41,  2.20it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:44<01:40,  2.21it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:44<01:40,  2.20it/s]Progress: 29.00%
---- avg training fps: 6.94# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:44<01:40,  2.20it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:45<01:40,  2.19it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:45<01:39,  2.19it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:46<01:39,  2.20it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:46<01:39,  2.19it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:47<01:38,  2.19it/s]Progress: 31.00%
---- avg training fps: 7.05# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:47<01:38,  2.19it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:47<01:34,  2.28it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:48<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:48<01:35,  2.24it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:49<01:35,  2.22it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:49<01:35,  2.21it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:49<01:35,  2.21it/s]Progress: 33.00%
---- avg training fps: 7.15# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:50<01:34,  2.20it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:50<01:35,  2.18it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:51<01:34,  2.19it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:51<01:34,  2.19it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:52<01:33,  2.19it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:52<01:32,  2.19it/s]Progress: 35.00%
---- avg training fps: 7.23# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:53<01:32,  2.19it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:53<01:28,  2.28it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:54<01:28,  2.26it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:54<01:29,  2.23it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:57<03:58,  1.21s/it]Progress: 37.00%
---- avg training fps: 7.00# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:58<03:13,  1.02it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [00:58<02:52,  1.14it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [00:59<02:26,  1.33it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [00:59<02:08,  1.51it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:00<01:55,  1.67it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:00<01:47,  1.79it/s]Progress: 39.00%
---- avg training fps: 7.05# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:01<01:40,  1.90it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:01<01:36,  1.98it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:02<01:33,  2.03it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:02<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:03<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:03<01:25,  2.19it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:03<01:24,  2.19it/s]Progress: 41.00%
---- avg training fps: 7.13# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:03<01:24,  2.20it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:04<01:23,  2.20it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:04<01:23,  2.19it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:05<01:23,  2.19it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:05<01:22,  2.19it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:06<01:22,  2.19it/s]Progress: 43.00%
---- avg training fps: 7.20# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:06<01:21,  2.19it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:07<01:21,  2.19it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:07<01:20,  2.19it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:08<01:19,  2.20it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:08<01:19,  2.19it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:08<01:19,  2.19it/s]Progress: 45.00%
---- avg training fps: 7.27# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:09<01:19,  2.19it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:09<01:15,  2.29it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:09<01:16,  2.25it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:10<01:16,  2.24it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:10<01:16,  2.23it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:11<01:16,  2.22it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:11<01:16,  2.21it/s]Progress: 47.00%
---- avg training fps: 7.33# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:12<01:15,  2.20it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:12<01:15,  2.20it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:12<01:15,  2.20it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:13<01:14,  2.19it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:13<01:14,  2.19it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:14<01:13,  2.20it/s]Progress: 49.00%
---- avg training fps: 7.38# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:14<01:13,  2.19it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:15<01:13,  2.19it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:15<01:13,  2.19it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:15<01:09,  2.28it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:16<01:10,  2.25it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:16<01:10,  2.23it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:17<01:10,  2.23it/s]Progress: 51.00%
---- avg training fps: 7.43# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:17<01:10,  2.21it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:17<01:09,  2.20it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:18<01:09,  2.20it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:18<01:09,  2.20it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:19<01:08,  2.20it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:19<01:08,  2.19it/s]Progress: 53.00%
---- avg training fps: 7.48# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:20<01:08,  2.19it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:24<04:17,  1.74s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:25<03:18,  1.35s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:25<02:38,  1.08s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:26<02:38,  1.08s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:26<02:07,  1.14it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:26<01:48,  1.33it/s]Progress: 55.00%
---- avg training fps: 7.16# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:27<01:34,  1.51it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:27<01:25,  1.66it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:28<01:18,  1.80it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:28<01:13,  1.90it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:29<01:10,  1.97it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:29<01:07,  2.03it/s]Progress: 57.00%
---- avg training fps: 7.21# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:29<01:06,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:30<01:04,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:30<01:03,  2.12it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:31<01:02,  2.13it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:31<01:01,  2.15it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:32<01:01,  2.16it/s]Progress: 59.00%
---- avg training fps: 7.26# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:32<01:01,  2.16it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:32<00:58,  2.25it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:33<00:58,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:33<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:34<00:58,  2.20it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:34<00:57,  2.19it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:34<00:57,  2.19it/s]Progress: 61.00%
---- avg training fps: 7.30# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:35<00:57,  2.18it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:35<00:56,  2.18it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:36<00:56,  2.18it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:36<00:55,  2.18it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:37<00:55,  2.18it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:37<00:55,  2.18it/s]Progress: 63.00%
---- avg training fps: 7.34# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:38<00:54,  2.19it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:38<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:38<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:38<00:51,  2.27it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:39<00:51,  2.24it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:39<00:51,  2.22it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:40<00:51,  2.22it/s]Progress: 65.00%
---- avg training fps: 7.38# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:40<00:51,  2.20it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:41<00:51,  2.19it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:41<00:50,  2.19it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:42<00:50,  2.18it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:42<00:50,  2.18it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:43<00:49,  2.18it/s]Progress: 67.00%
---- avg training fps: 7.41# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:43<00:49,  2.17it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:44<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:44<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:44<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:45<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:45<00:45,  2.27it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:45<00:45,  2.24it/s]Progress: 69.00%
---- avg training fps: 7.45# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:46<00:45,  2.22it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:46<00:45,  2.21it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:47<00:45,  2.20it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:50<02:03,  1.26s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:50<01:39,  1.02s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:51<01:22,  1.17it/s]Progress: 71.00%
---- avg training fps: 7.30# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:51<01:09,  1.36it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:52<01:01,  1.53it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:52<00:55,  1.68it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:53<00:50,  1.81it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:53<00:47,  1.90it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:54<00:45,  1.98it/s]Progress: 73.00%
---- avg training fps: 7.34# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:54<00:45,  1.98it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:54<00:42,  2.11it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:54<00:41,  2.13it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:55<00:40,  2.15it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:55<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:56<00:39,  2.16it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:56<00:38,  2.16it/s]Progress: 75.00%
---- avg training fps: 7.37# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:57<00:38,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:57<00:38,  2.13it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:58<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:58<00:37,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:59<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:59<00:36,  2.16it/s]Progress: 77.00%
---- avg training fps: 7.40# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [01:59<00:35,  2.16it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:00<00:35,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:00<00:35,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:00<00:33,  2.26it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:01<00:33,  2.24it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:01<00:33,  2.21it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:02<00:32,  2.20it/s]Progress: 79.00%
---- avg training fps: 7.43# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:02<00:32,  2.19it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:03<00:32,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:03<00:31,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:04<00:31,  2.17it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:04<00:30,  2.17it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:04<00:30,  2.17it/s]Progress: 81.00%
---- avg training fps: 7.46# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:05<00:29,  2.17it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:05<00:29,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:06<00:29,  2.17it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:06<00:28,  2.17it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:07<00:28,  2.17it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:07<00:26,  2.26it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:07<00:26,  2.23it/s]Progress: 83.00%
---- avg training fps: 7.49# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:08<00:26,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:08<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:09<00:26,  2.18it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:09<00:25,  2.18it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:10<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:10<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.52# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:10<00:24,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:11<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:11<00:23,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:12<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:12<00:22,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:16<01:03,  1.33s/it]Progress: 87.00%
---- avg training fps: 7.38# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:16<01:03,  1.33s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:16<00:49,  1.05s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:17<00:40,  1.14it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:17<00:33,  1.33it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:17<00:29,  1.51it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:18<00:25,  1.66it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:18<00:23,  1.78it/s]Progress: 89.00%
---- avg training fps: 7.41# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:19<00:21,  1.89it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:19<00:20,  1.96it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:20<00:19,  2.02it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:20<00:18,  2.06it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:21<00:17,  2.10it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:17,  2.12it/s]Progress: 91.00%
---- avg training fps: 7.43# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:22<00:16,  2.13it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:15,  2.14it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:22<00:15,  2.14it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:22<00:14,  2.23it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:23<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:23<00:14,  2.20it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:24<00:13,  2.19it/s]Progress: 93.00%
---- avg training fps: 7.46# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:24<00:13,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:25<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:25<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:26<00:11,  2.18it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:26<00:11,  2.17it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:27<00:11,  2.17it/s]Progress: 95.00%
---- avg training fps: 7.48# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:28<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:29<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:29<00:08,  2.27it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:29<00:08,  2.23it/s]Progress: 97.00%
---- avg training fps: 7.51# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:30<00:07,  2.21it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:30<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:31<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:31<00:06,  2.18it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:32<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.17it/s]Progress: 99.00%
---- avg training fps: 7.53# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:33<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:33<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:34<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:35<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.55# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:35<00:02,  2.16it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:35<00:02,  2.26it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:36<00:01,  2.23it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:36<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:37<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:37<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:38<00:00,  2.17it/s]Progress: 100.00%
---- avg training fps: 7.57# Trainer step: 294, epoch: 21: : 301it [02:38,  2.17it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.98it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.56it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.49it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.48it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.45it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.44it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.44it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.43it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.42it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.42it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.42it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.40it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.40it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.40it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.40it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:01,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 03:11:26.322417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:11:26.414215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:11:26.414243: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:11:26.432774: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:11:26.833095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:11:26.833178: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:11:26.833187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23112 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_03-11-28-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723511488.6430585 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 7153.21it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 14.10it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.26it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.74it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.99it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_03-11-28-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.41it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.32it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.65it/s] 20%|██        | 2/10 [00:00<00:01,  4.58it/s] 30%|███       | 3/10 [00:00<00:01,  4.84it/s] 40%|████      | 4/10 [00:00<00:01,  4.98it/s] 50%|█████     | 5/10 [00:01<00:01,  4.92it/s] 60%|██████    | 6/10 [00:01<00:00,  4.95it/s] 70%|███████   | 7/10 [00:01<00:00,  5.17it/s] 80%|████████  | 8/10 [00:01<00:00,  5.24it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.23it/s]100%|██████████| 10/10 [00:02<00:00,  5.05it/s]100%|██████████| 10/10 [00:02<00:00,  4.97it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal blending of nature and technology

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal blending of nature and technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7292.86it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:43,  2.96s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:09,  3.25s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:45,  1.97s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:45,  1.37s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:06,  1.04s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:06,  1.19it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.77# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:28,  1.40it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:03,  1.59it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:46,  1.74it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:35,  1.87it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:35,  1.87it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:27,  1.96it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:10<02:25,  1.97it/s]Progress: 7.00%
---- avg training fps: 4.20# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:21,  2.02it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:11<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:16,  2.08it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:14,  2.11it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:12,  2.13it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:11,  2.14it/s]Progress: 9.00%
---- avg training fps: 5.07# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:10,  2.15it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:08,  2.16it/s]Progress: 11.00%
---- avg training fps: 5.65# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:16<02:06,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:06,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:04,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:04,  2.18it/s]Progress: 13.00%
---- avg training fps: 6.08# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:04,  2.18it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:02,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:02,  2.18it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:01,  2.18it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:01,  2.18it/s]Progress: 15.00%
---- avg training fps: 6.35# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:15,  1.94it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:10,  2.01it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:06,  2.06it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:04,  2.09it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:04,  2.09it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:24<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.61# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:56,  2.18it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:56,  2.18it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:55,  2.18it/s]Progress: 19.00%
---- avg training fps: 6.82# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:55,  2.18it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:54,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:47,  1.40s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:35,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:45,  1.09it/s]Progress: 21.00%
---- avg training fps: 6.34# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:11,  1.28it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:46,  1.46it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:34<02:29,  1.63it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:17,  1.76it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:35<02:09,  1.86it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]Progress: 23.00%
---- avg training fps: 6.52# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:58,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:55,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:53,  2.09it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:51,  2.12it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:49,  2.14it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:48,  2.15it/s]Progress: 25.00%
---- avg training fps: 6.67# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:48,  2.15it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:47,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:46,  2.17it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:40<01:45,  2.18it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:45,  2.18it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:45,  2.18it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:41<01:44,  2.18it/s]Progress: 27.00%
---- avg training fps: 6.78# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:57,  1.93it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:42<01:52,  2.01it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:49,  2.06it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:43<01:47,  2.08it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:45,  2.11it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.90# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:42,  2.15it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:41,  2.17it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:40,  2.17it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:39,  2.18it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.18it/s]Progress: 31.00%
---- avg training fps: 7.00# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:48<01:37,  2.19it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:36,  2.19it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:49<01:36,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 7.10# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:36,  2.18it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:33,  2.19it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:33,  2.19it/s]Progress: 35.00%
---- avg training fps: 7.18# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:53<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:54<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:58<04:14,  1.28s/it]Progress: 37.00%
---- avg training fps: 6.92# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<03:24,  1.04s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:59<02:49,  1.16it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:59<02:24,  1.35it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:00<02:07,  1.52it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:00<01:55,  1.67it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:01<01:46,  1.80it/s]Progress: 39.00%
---- avg training fps: 7.00# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:01<01:40,  1.90it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:02<01:36,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:02<01:36,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:02<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:03<01:30,  2.08it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:03<01:28,  2.10it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:04<01:27,  2.13it/s]Progress: 41.00%
---- avg training fps: 7.07# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:26,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:25,  2.16it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:24,  2.16it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:34,  1.93it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:06<01:30,  2.01it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:06<01:27,  2.05it/s]Progress: 43.00%
---- avg training fps: 7.12# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:07<01:27,  2.05it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:07<01:25,  2.09it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:07<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:08<01:22,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:08<01:21,  2.16it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:09<01:20,  2.16it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:09<01:20,  2.17it/s]Progress: 45.00%
---- avg training fps: 7.18# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:10<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:11<01:18,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:17,  2.18it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:17,  2.18it/s]Progress: 47.00%
---- avg training fps: 7.24# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:13<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:13<01:15,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:14<01:14,  2.19it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:14<01:14,  2.19it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:15<01:14,  2.18it/s]Progress: 49.00%
---- avg training fps: 7.29# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:13,  2.18it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:16<01:13,  2.19it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:16<01:13,  2.19it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:16<01:12,  2.19it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:17<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.35# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:18<01:11,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:19<01:10,  2.18it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:09,  2.18it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:20<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:20<01:09,  2.15it/s]Progress: 53.00%
---- avg training fps: 7.39# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<03:42,  1.50s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:25<02:54,  1.19s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:26<02:21,  1.03it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<01:58,  1.22it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:42,  1.41it/s]Progress: 55.00%
---- avg training fps: 7.14# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:30,  1.58it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:22,  1.72it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:16,  1.84it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:09,  2.00it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:07,  2.04it/s]Progress: 57.00%
---- avg training fps: 7.19# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:06,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:31<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.23# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:00,  2.16it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<00:59,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<00:59,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.27# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:57,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:37<00:55,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:55,  2.17it/s]Progress: 63.00%
---- avg training fps: 7.31# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:38<00:55,  2.17it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:38<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:39<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 7.35# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:51,  2.17it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:42<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:43<00:49,  2.17it/s]Progress: 67.00%
---- avg training fps: 7.38# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:49,  2.17it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:44<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:44<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:45<00:47,  2.17it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:45<00:47,  2.17it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:46<00:47,  2.17it/s]Progress: 69.00%
---- avg training fps: 7.42# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:46,  2.16it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:46,  2.17it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:46,  2.17it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:45,  2.17it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:51<02:19,  1.43s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:51<01:50,  1.14s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:52<01:29,  1.07it/s]Progress: 71.00%
---- avg training fps: 7.24# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:52<01:15,  1.27it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:53<01:04,  1.45it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:53<00:57,  1.61it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:54<01:00,  1.52it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:54<00:54,  1.67it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:55<00:50,  1.80it/s]Progress: 73.00%
---- avg training fps: 7.25# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:55<00:50,  1.80it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:55<00:46,  1.90it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:56<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:56<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:57<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:57<00:40,  2.11it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:39,  2.14it/s]Progress: 75.00%
---- avg training fps: 7.29# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:58<00:38,  2.15it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:59<00:37,  2.17it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:59<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:00<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:00<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:00<00:35,  2.17it/s]Progress: 77.00%
---- avg training fps: 7.32# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:01<00:35,  2.18it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:01<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:02<00:34,  2.17it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:02<00:34,  2.17it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:03<00:33,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:03<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.35# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:04<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:05<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:05<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:06<00:30,  2.16it/s]Progress: 81.00%
---- avg training fps: 7.38# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:06<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:07<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:07<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:08<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:08<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:09<00:27,  2.16it/s]Progress: 83.00%
---- avg training fps: 7.40# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:09<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:09<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:10<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:10<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:11<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:11<00:25,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.43# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:12<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:12<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:13<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:13<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:14<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:14<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:18<01:12,  1.51s/it]Progress: 87.00%
---- avg training fps: 7.27# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:18<00:56,  1.19s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:19<00:44,  1.02it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:19<00:37,  1.22it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:20<00:31,  1.40it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:20<00:27,  1.56it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:21<00:24,  1.70it/s]Progress: 89.00%
---- avg training fps: 7.29# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:21<00:22,  1.81it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:21<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:22<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:22<00:19,  1.97it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:22<00:18,  2.02it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:23<00:17,  2.06it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:23<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 7.32# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:24<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:24<00:16,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:25<00:15,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:25<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:26<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:26<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.34# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:27<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:27<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:27<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:28<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:28<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:28<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:29<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.37# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:29<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:30<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:30<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:31<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:31<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:31<00:08,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:32<00:08,  2.14it/s]Progress: 97.00%
---- avg training fps: 7.39# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:32<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:33<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:33<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:34<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:34<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:35<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.41# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:35<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:35<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:36<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:36<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:36<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:37<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:37<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.43# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:38<00:02,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:38<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:39<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:39<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:40<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:40<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.45Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.53it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.49it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.47it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.43it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.42it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.42it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.40it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.37it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.79it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:00<00:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 03:15:58.420114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:15:58.510816: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:15:58.510845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:15:58.529756: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:15:58.931335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:15:58.931417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:15:58.931426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23104 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_03-16-00-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723511760.7760966 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 15980.09it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 14.34it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.34it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.72it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_03-16-00-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_03-16-00-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 760041.66it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1562016.66it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a visual style like Tarsem Singh's.
- In the style of TOK, a brigade of beavers is shown in a style similar to M. C. Escher's works.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, and rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting shows lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and packing peanuts swims up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid swims underwater in the ocean, crafted from fishnets and sea trash.
- In the style of TOK, a throng of Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is illustrated.
- In the style of TOK, a blockchain of bees is depicted.
- In the style of TOK, a gorgon made out of sharks is depicted swimming underwater, the sharks eating each other.
- In the style of TOK, a hillside at sunset is shown with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle is illustrated.
- In the style of TOK, cats are shown pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is illustrated.
- In the style of TOK, the phrase "Let's quit our boring corporation job together" is illustrated.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange based on first and second-degree connection is depicted.
- In the style of TOK, trypophobia is illustrated.
- In the style of TOK, a six-pack of nightmare fuel is depicted.
- In the style of TOK, a band of dancing, singing beavers is shown.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam as depicted by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted in the manner of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is shown, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is depicted.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and packing peanuts is swimming up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from waste materials swims underwater in the ocean.
- In the style of TOK, a throng of tiny Lilliputians are packed inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is set in Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "best of times, worst of times" is visually depicted.
- In the style of TOK, bees are organized in a blockchain formation.
- In the style of TOK, a gorgon composed of sharks cannibalizes each other while swimming underwater.
- In the style of TOK, Venus and Earth are seen circling the sun against a sunset hillside.
- In the style of TOK, an ancient temple is found in the depths of the Amazon jungle.
- In the style of TOK, cats are depicted pooping in zero-gravity.
- In the style of TOK, a goblin-goat hybrid is featured.
- In the style of TOK, the concept "age of wisdom, age of foolishness" comes to life.
- In the style of TOK, two people decide to quit their mundane corporate jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, room and space exchange occurs based on first and second-degree connections.
- In the style of TOK, images invoke a sense of trypophobia.
- In the style of TOK, a 6-pack container brings forth nightmare-inducing contents.
- In the style of TOK, a band of beavers are dancing and singing, reminiscent of Jim Henson's Muppets.
- In the style of TOK, a beaver is seen gnawing a rifle in half.
- In the style of TOK, a brigade of beavers rapidly constructs a dam as if on a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers rapidly constructs a dam in a manner reminiscent of Tarsem Singh's visuals.
- In the style of TOK, a brigade of beavers is depicted with an M. C. Escher inspiration.
- In the style of TOK, a castle advances across grassy hills.
- In the style of TOK, a chorus line of beavers dances in synchrony.
- In the style of TOK, a 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, elephant seals strut in a fashion show while egrets watch from the audience.
- In the style of TOK, architectural elements are rendered in hyper-realistic lemon and lime hues.
- In the style of TOK, a mermaid made from debris and dead fish emerges from the sea to glimpse above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 4...
----- GPT response: -----
Style Description: Surreal and whimsical elements.

- In the style of TOK, a mermaid swimming underwater made out of fishnets and sea trash.
- In the style of TOK, Lilliputians cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is set in Fort Kochi, Kerala, India.
- In the style of TOK, depicting the saying "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain visualized as a series of bees.
- In the style of TOK, a gorgon made of sharks eating each other swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple found deep in the Amazon jungle.
- In the style of TOK, cats are experienced to be pooping in zero-gravity conditions.
- In the style of TOK, a depiction of a goblin goat.
- In the style of TOK, illustrating "it was the age of wisdom, it was the age of foolishness."
- In the style of TOK, two characters deciding to quit their boring corporate job together.
- In the style of TOK, depicting ancient petroglyphs.
- In the style of TOK, a scene showing room and space exchange based on first and second-degree connections.
- In the style of TOK, an illustration evoking trypophobia.
- In the style of TOK, a 6-pack containing nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a brigade of beavers building a dam.
- In the style of TOK, a moving castle traveling through grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and rediscovered in the space age.
- In the style of TOK, a fashion show featuring elephant seals as runway models and egrets in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid swimming up made out of fishnets, dead fish, packing peanuts, and sea trash.

--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
WARNING: no captioning text was given and we're not doing chatgpt cleanup...
Concept mode:  style
Using GPT concept name as CLIP-segmentation prompt: Surreal and whimsical elements.
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15261.26it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, they were the be...
4     in the style of <s0><s1><s2>, a blockchain of ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats pooping in ...
9             in the style of <s0><s1><s2>, goblin goat
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, let's quit our b...
12            in the style of <s0><s1><s2>, petroglyphs
13    in the style of <s0><s1><s2>, room and space e...
14            in the style of <s0><s1><s2>, trypophobia
15    in the style of <s0><s1><s2>, a 6-pack of nigh...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle that is...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi, kera...
30    in the style of <s0><s1><s2>, they were the be...
31    in the style of <s0><s1><s2>, a blockchain of ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats pooping in ...
36            in the style of <s0><s1><s2>, goblin goat
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, let's quit our b...
39            in the style of <s0><s1><s2>, petroglyphs
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:27,  2.90s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:36,  4.35s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:44,  2.57s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:34,  1.74s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:17,  1.28s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:54,  1.00s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.27# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:01,  1.21it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:26,  1.41it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:03,  1.58it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:48,  1.72it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:37,  1.84it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:29,  1.93it/s]Progress: 7.00%
---- avg training fps: 3.60# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:24,  1.99it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:20,  2.04it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:20,  2.04it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:24,  1.97it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:17,  2.06it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:15,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.44# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:13,  2.11it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:12,  2.12it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:11,  2.13it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:10,  2.13it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:09,  2.14it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:09,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.05# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:08,  2.15it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:07,  2.14it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:07,  2.14it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:07,  2.14it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:07,  2.14it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<02:00,  2.25it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:02,  2.21it/s]Progress: 13.00%
---- avg training fps: 5.52# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<02:02,  2.19it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:03,  2.18it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<02:03,  2.17it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:02,  2.16it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:02,  2.16it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:24<02:02,  2.16it/s]Progress: 15.00%
---- avg training fps: 5.87# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:02,  2.15it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:25<02:01,  2.15it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:01,  2.15it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<02:01,  2.15it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<02:00,  2.15it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:59,  2.15it/s]Progress: 17.00%
---- avg training fps: 6.17# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:59,  2.15it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:54,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:55,  2.21it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:55,  2.20it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:56,  2.17it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:29<01:56,  2.17it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.39# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:30<01:56,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:56,  2.15it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:55,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:14,  1.27s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:14,  1.03s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:31,  1.16it/s]Progress: 21.00%
---- avg training fps: 6.08# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:01,  1.35it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:20,  1.73it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:11,  1.84it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:05,  1.92it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:01,  1.98it/s]Progress: 23.00%
---- avg training fps: 6.28# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:57,  2.03it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:55,  2.07it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:53,  2.09it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:51,  2.11it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<01:50,  2.13it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:49,  2.13it/s]Progress: 25.00%
---- avg training fps: 6.43# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:41<01:48,  2.14it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:48,  2.15it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:47,  2.15it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:46,  2.15it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:46,  2.15it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:41,  2.26it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:42,  2.22it/s]Progress: 27.00%
---- avg training fps: 6.58# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<01:43,  2.20it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<02:02,  1.84it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:56,  1.93it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:51,  1.99it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:46<01:48,  2.04it/s]Progress: 29.00%
---- avg training fps: 6.67# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:46,  2.07it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:47<01:44,  2.10it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:43,  2.11it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:42,  2.13it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:41,  2.14it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:49<01:40,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.79# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:40,  2.14it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:49<01:36,  2.22it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:36,  2.20it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:36,  2.18it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.89# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:52<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:53<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:54<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.97# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:55<01:33,  2.16it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:28,  2.27it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:29,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:25,  1.04s/it]Progress: 37.00%
---- avg training fps: 6.83# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<02:50,  1.15it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:26,  1.34it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:08,  1.51it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<01:56,  1.66it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:48,  1.78it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:42,  1.88it/s]Progress: 39.00%
---- avg training fps: 6.91# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:37,  1.96it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:02<01:34,  2.01it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:32,  2.05it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:03<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:24,  2.20it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:04<01:25,  2.18it/s]Progress: 41.00%
---- avg training fps: 6.99# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:25,  2.17it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:05<01:25,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:06<01:24,  2.16it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:23,  2.16it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:07<01:23,  2.16it/s]Progress: 43.00%
---- avg training fps: 7.06# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:23,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:08<01:22,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:09<01:21,  2.15it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:09<01:21,  2.15it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:20,  2.15it/s]Progress: 45.00%
---- avg training fps: 7.13# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:10<01:20,  2.15it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:10<01:16,  2.26it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:17,  2.22it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:11<01:17,  2.20it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:17,  2.19it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:12<01:17,  2.18it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.17it/s]Progress: 47.00%
---- avg training fps: 7.18# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:13<01:17,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:13<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:14<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:14<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:15<01:15,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:15<01:15,  2.15it/s]Progress: 49.00%
---- avg training fps: 7.23# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:14,  2.15it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:16<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:10,  2.26it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:17<01:10,  2.23it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:18<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.29# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:11,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:19<01:11,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:18,  1.95it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:20<01:15,  2.01it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:13,  2.05it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:11,  2.09it/s]Progress: 53.00%
---- avg training fps: 7.32# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:21<01:10,  2.11it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:25<03:24,  1.38s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:25<02:42,  1.11s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:26<02:13,  1.09it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:26<02:13,  1.09it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:26<01:49,  1.32it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:27<01:36,  1.49it/s]Progress: 55.00%
---- avg training fps: 7.11# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:27<01:27,  1.64it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:28<01:20,  1.77it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:28<01:15,  1.86it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:29<01:12,  1.94it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:29<01:09,  2.00it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:30<01:07,  2.04it/s]Progress: 57.00%
---- avg training fps: 7.16# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:30<01:05,  2.08it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:30<01:04,  2.10it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:31<01:03,  2.12it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:31<01:03,  2.13it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:32<01:02,  2.14it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:32<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.21# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:33<01:01,  2.14it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:33<00:58,  2.25it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:33<00:58,  2.22it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:34<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:34<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:35<00:58,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:35<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.25# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:36<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:36<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:36<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:37<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:37<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:38<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.29# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:38<00:55,  2.15it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:39<00:54,  2.15it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:39<00:54,  2.15it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:39<00:52,  2.24it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:40<00:59,  1.96it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:40<00:57,  2.01it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:41<00:55,  2.05it/s]Progress: 65.00%
---- avg training fps: 7.31# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:41<00:54,  2.08it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:42<00:53,  2.11it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:42<00:52,  2.12it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:43<00:51,  2.14it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:43<00:50,  2.14it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:44<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.35# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:44<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:44<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:45<00:48,  2.16it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:45<00:48,  2.16it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:46<00:48,  2.16it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:46<00:45,  2.25it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:46<00:46,  2.21it/s]Progress: 69.00%
---- avg training fps: 7.39# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:47<00:46,  2.20it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:47<00:45,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:48<00:45,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:50<01:38,  1.00s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:50<01:21,  1.19it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:51<01:09,  1.37it/s]Progress: 71.00%
---- avg training fps: 7.30# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:51<01:01,  1.54it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:52<00:55,  1.68it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:52<00:51,  1.81it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:53<00:48,  1.90it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:53<00:46,  1.97it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:54<00:44,  2.02it/s]Progress: 73.00%
---- avg training fps: 7.33# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:54<00:44,  2.02it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:54<00:41,  2.14it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:55<00:41,  2.14it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:55<00:40,  2.15it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:55<00:40,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:56<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:56<00:39,  2.15it/s]Progress: 75.00%
---- avg training fps: 7.36# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:57<00:38,  2.16it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:57<00:38,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:58<00:37,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:58<00:37,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:59<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:59<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.39# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:00<00:35,  2.15it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:00<00:35,  2.15it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:00<00:35,  2.15it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:00<00:33,  2.25it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:01<00:33,  2.22it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:01<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:02<00:32,  2.18it/s]Progress: 79.00%
---- avg training fps: 7.42# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:02<00:32,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:03<00:32,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:03<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:04<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:04<00:31,  2.15it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:05<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.45# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:05<00:30,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:06<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:06<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:07<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:07<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:07<00:26,  2.28it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:07<00:26,  2.24it/s]Progress: 83.00%
---- avg training fps: 7.48# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:08<00:26,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:08<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:09<00:26,  2.18it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:09<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:10<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:10<00:25,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.50# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:11<00:24,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:11<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:12<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:12<00:23,  2.16it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:12<00:22,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:16<01:04,  1.35s/it]Progress: 87.00%
---- avg training fps: 7.37# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:16<01:04,  1.35s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:16<00:50,  1.07s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:17<00:40,  1.13it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:17<00:34,  1.32it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:18<00:29,  1.49it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:18<00:26,  1.64it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:19<00:23,  1.77it/s]Progress: 89.00%
---- avg training fps: 7.39# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:19<00:21,  1.87it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:20<00:20,  1.94it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:20<00:19,  2.01it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:20<00:18,  2.05it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:21<00:17,  2.08it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:17,  2.10it/s]Progress: 91.00%
---- avg training fps: 7.42# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:22<00:16,  2.11it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:23<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:23<00:14,  2.23it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:23<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:24<00:14,  2.18it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:24<00:13,  2.17it/s]Progress: 93.00%
---- avg training fps: 7.44# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:25<00:13,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:25<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:26<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:26<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:26<00:11,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:27<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.46# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:28<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:29<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:29<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:29<00:08,  2.25it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:30<00:08,  2.22it/s]Progress: 97.00%
---- avg training fps: 7.49# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:30<00:07,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:31<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:31<00:06,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:32<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:32<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.51# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:33<00:05,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:34<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:35<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:35<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.53# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:36<00:02,  2.14it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:36<00:02,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:36<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:37<00:01,  2.20it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:37<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:38<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:38<00:00,  2.17it/s]Progress: 100.00%
---- avg training fps: 7.55# Trainer step: 294, epoch: 21: : 301it [02:38,  2.16it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.47it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.46it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.46it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.45it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.45it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.45it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.44it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.44it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.43it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.43it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.42it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.42it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.42it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.41it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.41it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.40it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.40it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.40it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.40it/s][A100%|██████████| 30/30 [00:08<00:00,  3.46it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.55it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.46it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.44it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.42it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.41it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.40it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.40it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.39it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.38it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.38it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.38it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.38it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.36it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [03:57,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 03:21:01.703569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:21:01.794616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:21:01.794644: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:21:01.813268: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:21:02.212838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:21:02.212919: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:21:02.212928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23128 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_03-21-03-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723512064.038661 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 98621.26it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.68it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.98it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.33it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.17it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_03-21-03-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.37it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.50it/s] 20%|██        | 2/10 [00:00<00:01,  4.44it/s] 30%|███       | 3/10 [00:00<00:01,  4.72it/s] 40%|████      | 4/10 [00:00<00:01,  4.85it/s] 50%|█████     | 5/10 [00:01<00:01,  4.81it/s] 60%|██████    | 6/10 [00:01<00:00,  4.84it/s] 70%|███████   | 7/10 [00:01<00:00,  5.02it/s] 80%|████████  | 8/10 [00:01<00:00,  5.11it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.10it/s]100%|██████████| 10/10 [00:02<00:00,  4.93it/s]100%|██████████| 10/10 [00:02<00:00,  4.84it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology.

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7732.15it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:04,  3.03s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:03,  3.43s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:17,  2.08s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:07,  1.44s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:22,  1.09s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:18,  1.14it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.64# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:38,  1.34it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:12,  1.52it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:54,  1.67it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:42,  1.79it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:42,  1.79it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:33,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:28,  1.94it/s]Progress: 7.00%
---- avg training fps: 4.03# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:23,  2.00it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:20,  2.03it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:18,  2.06it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:16,  2.08it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:15,  2.09it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.89# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:10,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:10,  2.12it/s]Progress: 11.00%
---- avg training fps: 5.47# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:07,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:07,  2.12it/s]Progress: 13.00%
---- avg training fps: 5.88# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:06,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:06,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:21,  1.89it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:15,  1.96it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:11,  2.01it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:09,  2.04it/s]Progress: 15.00%
---- avg training fps: 6.15# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:07,  2.07it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:05,  2.09it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:04,  2.10it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:03,  2.11it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:03,  2.11it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:02,  2.12it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:01,  2.12it/s]Progress: 17.00%
---- avg training fps: 6.41# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:58,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:58,  2.13it/s]Progress: 19.00%
---- avg training fps: 6.61# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:57,  2.13it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<05:59,  1.45s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:45,  1.15s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:53,  1.05it/s]Progress: 21.00%
---- avg training fps: 6.15# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:17,  1.24it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:52,  1.42it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:34,  1.57it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:21,  1.71it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:12,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:06,  1.90it/s]Progress: 23.00%
---- avg training fps: 6.33# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:06,  1.90it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<02:02,  1.95it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<02:00,  1.98it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:56,  2.03it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<02:08,  1.83it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<02:03,  1.90it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:59,  1.96it/s]Progress: 25.00%
---- avg training fps: 6.44# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:55,  2.01it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:53,  2.05it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:51,  2.07it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:49,  2.09it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:49,  2.09it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:48,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:47,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.58# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.69# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:40,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.80# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:37,  2.15it/s]Progress: 33.00%
---- avg training fps: 6.89# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.98# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:33,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:32,  2.14it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.06# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:57<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:58<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:29,  2.14it/s]Progress: 39.00%
---- avg training fps: 7.13# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:29,  2.13it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:28,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:28,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:02<01:26,  2.14it/s]Progress: 41.00%
---- avg training fps: 7.19# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:03<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:04<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:24,  2.14it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:05<01:24,  2.14it/s]Progress: 43.00%
---- avg training fps: 7.25# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:24,  2.14it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:06<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:07<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.30# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:10<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:10<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:11<01:18,  2.14it/s]Progress: 47.00%
---- avg training fps: 7.35# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:11<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:12<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:13<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.39# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:14<01:15,  2.14it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:15<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:15<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:16<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:12,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.44# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:17<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:18<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:10,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:19<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.47# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:09,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:24<03:44,  1.51s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:24<02:56,  1.20s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:25<02:23,  1.02it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:25<01:59,  1.21it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:43,  1.39it/s]Progress: 55.00%
---- avg training fps: 7.21# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:26<01:31,  1.56it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:23,  1.70it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:27<01:17,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:27<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:28<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:28<01:10,  1.96it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:28<01:08,  2.02it/s]Progress: 57.00%
---- avg training fps: 7.25# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:29<01:07,  2.04it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:29<01:05,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:30<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:30<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:31<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:31<01:02,  2.12it/s]Progress: 59.00%
---- avg training fps: 7.29# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:01,  2.13it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:32<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:01,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:33<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:34<00:58,  2.14it/s]Progress: 61.00%
---- avg training fps: 7.33# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:34<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:35<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:35<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:36<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:36<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:37<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.36# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:37<00:56,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:37<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:38<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:39<00:53,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.40# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:40<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:41<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:41<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:42<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:42<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:42<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.43# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:43<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:43<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:44<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:44<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:45<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:45<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.46# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:46<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:51<02:32,  1.56s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:51<01:59,  1.23s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:52<01:35,  1.00it/s]Progress: 71.00%
---- avg training fps: 7.25# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:52<01:19,  1.19it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:53<01:08,  1.38it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:53<01:00,  1.54it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:54<00:54,  1.68it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:54<00:50,  1.80it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:54<00:47,  1.89it/s]Progress: 73.00%
---- avg training fps: 7.28# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:55<00:47,  1.89it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:55<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:55<00:43,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:56<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:56<00:41,  2.07it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:57<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:57<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.31# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:58<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:58<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:59<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:59<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:00<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:00<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:00<00:36,  2.13it/s]Progress: 77.00%
---- avg training fps: 7.34# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:01<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:01<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:01<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:02<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:02<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:03<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.36# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:03<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:04<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:04<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:04<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:05<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:05<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:06<00:30,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.39# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:06<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:07<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:07<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:08<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:08<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:09<00:28,  2.14it/s]Progress: 83.00%
---- avg training fps: 7.41# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:09<00:28,  2.14it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:09<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:09<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:10<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:10<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:11<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:11<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.44# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:12<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:12<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:13<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:13<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:14<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:14<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:14<00:22,  2.14it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.46# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:15<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:15<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:16<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:16<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:16<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:17<00:19,  2.14it/s]Progress: 89.00%
---- avg training fps: 7.48# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:17<00:19,  2.14it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:18<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:18<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:18<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:19<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:19<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:20<00:16,  2.14it/s]Progress: 91.00%
---- avg training fps: 7.51# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:20<00:16,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:21<00:15,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:21<00:15,  2.14it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:22<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:22<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:23<00:14,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.53# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:23<00:14,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:23<00:13,  2.11it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:23<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:24<00:14,  1.88it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:25<00:13,  1.95it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:25<00:12,  2.01it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:26<00:11,  2.05it/s]Progress: 95.00%
---- avg training fps: 7.54# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:26<00:11,  2.08it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:26<00:10,  2.10it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:27<00:09,  2.11it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:27<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:28<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:28<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:28<00:08,  2.14it/s]Progress: 97.00%
---- avg training fps: 7.55# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:29<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:29<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:30<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:30<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:31<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:31<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.57# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:32<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:32<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:33<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:33<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:33<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:33<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:34<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.59# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:34<00:02,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:35<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:35<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:36<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:36<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:37<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.61Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.49it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.47it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.46it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.45it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.45it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.44it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.43it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.43it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.42it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.42it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.42it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.42it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.41it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.41it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.40it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.40it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.40it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.39it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.39it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.39it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.39it/s][A100%|██████████| 30/30 [00:08<00:00,  3.45it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.55it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.45it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.38it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.37it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.37it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.36it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.35it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:56<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 03:25:30.352316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:25:30.443540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:25:30.443566: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:25:30.462405: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:25:30.861651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:25:30.861732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:25:30.861741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23132 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_03-25-32-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723512332.6346176 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 11068.48it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.40it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.68it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.87it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.19it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_03-25-32-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 187245.71it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.60it/s] 20%|██        | 2/10 [00:00<00:02,  3.45it/s] 30%|███       | 3/10 [00:00<00:01,  4.08it/s] 40%|████      | 4/10 [00:01<00:01,  4.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.49it/s] 60%|██████    | 6/10 [00:01<00:00,  4.65it/s] 70%|███████   | 7/10 [00:01<00:00,  4.63it/s] 80%|████████  | 8/10 [00:01<00:00,  4.76it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.75it/s]100%|██████████| 10/10 [00:02<00:00,  4.89it/s]100%|██████████| 10/10 [00:02<00:00,  4.47it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike scenes.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress is walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike scenes.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 11399.89it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:56,  3.00s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:49,  3.99s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:47,  2.38s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:01,  1.63s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:56,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:41,  1.04it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.39# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:54,  1.25it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:22,  1.44it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<03:01,  1.60it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:36,  1.84it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:30,  1.92it/s]Progress: 7.00%
---- avg training fps: 3.68# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:42,  1.76it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:33,  1.86it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:27,  1.93it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:23,  1.98it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:19,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:17,  2.05it/s]Progress: 9.00%
---- avg training fps: 4.54# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:15,  2.08it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:10,  2.12it/s]Progress: 11.00%
---- avg training fps: 5.13# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:20<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:07,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:21<02:07,  2.11it/s]Progress: 13.00%
---- avg training fps: 5.57# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:22<02:06,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:05,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:05,  2.12it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:04,  2.13it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:04,  2.13it/s]Progress: 15.00%
---- avg training fps: 5.91# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:03,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:02,  2.13it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:26<02:02,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:26<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<02:01,  2.12it/s]Progress: 17.00%
---- avg training fps: 6.18# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:27<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:28<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:29<01:58,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:58,  2.12it/s]Progress: 19.00%
---- avg training fps: 6.40# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:30<01:58,  2.13it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:35<06:31,  1.58s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:07,  1.25s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:36<04:09,  1.01s/it]Progress: 21.00%
---- avg training fps: 5.92# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:28,  1.17it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:59,  1.36it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:39,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:25,  1.66it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.77it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.10# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:03,  1.93it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<02:00,  1.98it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:40<01:57,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:41<01:53,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:52,  2.08it/s]Progress: 25.00%
---- avg training fps: 6.26# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:42<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:50,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:43<01:49,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:44<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:44<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:48,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.40# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:45<01:47,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:46,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:46,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:46,  2.11it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:45,  2.11it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:45,  2.11it/s]Progress: 29.00%
---- avg training fps: 6.52# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:44,  2.11it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:48<01:44,  2.11it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:44,  2.11it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:43,  2.11it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:49<01:43,  2.10it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:42,  2.11it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:50<01:42,  2.11it/s]Progress: 31.00%
---- avg training fps: 6.63# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:41,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:51<01:41,  2.11it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:41,  2.11it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:52<01:40,  2.11it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:53<01:38,  2.13it/s]Progress: 33.00%
---- avg training fps: 6.73# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:55<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.82# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:56<01:35,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:57<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:58<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:58<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:58<01:32,  2.13it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 6.90# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<01:32,  2.13it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:59<01:32,  2.13it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:00<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:01<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:01<01:30,  2.12it/s]Progress: 39.00%
---- avg training fps: 6.97# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:02<01:30,  2.12it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:02<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:02<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:02<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:03<01:28,  2.12it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:03<01:28,  2.12it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:04<01:27,  2.12it/s]Progress: 41.00%
---- avg training fps: 7.03# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:26,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:06<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 7.09# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:07<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:07<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:08<01:22,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:09<01:22,  2.13it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:09<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:10<01:22,  2.11it/s]Progress: 45.00%
---- avg training fps: 7.15# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:10<01:22,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:11<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:20,  2.10it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:19,  2.10it/s]Progress: 47.00%
---- avg training fps: 7.20# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:19,  2.10it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:13<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:18,  2.10it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:14<01:18,  2.10it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:17,  2.09it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:15<01:17,  2.09it/s]Progress: 49.00%
---- avg training fps: 7.24# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:16<01:17,  2.09it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:16<01:16,  2.09it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:17<01:16,  2.09it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:17<01:15,  2.10it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:17<01:15,  2.10it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:18<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:18<01:14,  2.11it/s]Progress: 51.00%
---- avg training fps: 7.29# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:19<01:13,  2.10it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:19<01:13,  2.10it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:20<01:12,  2.10it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:12,  2.10it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:20<01:11,  2.10it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:11,  2.10it/s]Progress: 53.00%
---- avg training fps: 7.32# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:11,  2.10it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:11,  2.10it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:26<04:13,  1.71s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:27<03:17,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:27<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<02:10,  1.11it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:28<01:51,  1.29it/s]Progress: 55.00%
---- avg training fps: 7.02# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:28<01:37,  1.46it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:29<01:27,  1.62it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:29<01:21,  1.74it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:30<01:16,  1.83it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:30<01:16,  1.83it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:30<01:12,  1.91it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:31<01:10,  1.96it/s]Progress: 57.00%
---- avg training fps: 7.06# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:31<01:08,  2.00it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:32<01:06,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:32<01:05,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:33<01:04,  2.07it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:33<01:03,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:34<01:03,  2.09it/s]Progress: 59.00%
---- avg training fps: 7.11# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:34<01:02,  2.10it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:35<01:02,  2.09it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:35<01:02,  2.09it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:35<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:36<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:36<01:00,  2.10it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:36<00:59,  2.11it/s]Progress: 61.00%
---- avg training fps: 7.14# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:37<00:59,  2.10it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:37<00:58,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:38<00:58,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:38<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:39<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:39<00:56,  2.11it/s]Progress: 63.00%
---- avg training fps: 7.18# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:40<00:56,  2.11it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:40<00:56,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:40<00:55,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:41<00:55,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:41<00:55,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:42<00:54,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:42<00:54,  2.10it/s]Progress: 65.00%
---- avg training fps: 7.21# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:43<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:43<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:44<00:52,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:44<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:45<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:45<00:51,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:45<00:51,  2.10it/s]Progress: 67.00%
---- avg training fps: 7.25# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:45<00:50,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:46<00:50,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:46<00:49,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:47<00:49,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:47<00:48,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:48<00:48,  2.11it/s]Progress: 69.00%
---- avg training fps: 7.28# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:48<00:47,  2.11it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:49<00:46,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:54<02:51,  1.75s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:54<02:12,  1.37s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:55<01:45,  1.10s/it]Progress: 71.00%
---- avg training fps: 7.04# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:55<01:26,  1.10it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:56<01:13,  1.28it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:56<01:03,  1.46it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:57<00:57,  1.60it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:57<00:52,  1.73it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:58<00:49,  1.83it/s]Progress: 73.00%
---- avg training fps: 7.07# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:58<00:49,  1.83it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:58<00:46,  1.90it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:59<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:59<00:43,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:00<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:00<00:41,  2.05it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:01<00:40,  2.06it/s]Progress: 75.00%
---- avg training fps: 7.11# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:01<00:39,  2.08it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:02<00:39,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:02<00:38,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:03<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:03<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:03<00:37,  2.10it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:03<00:37,  2.10it/s]Progress: 77.00%
---- avg training fps: 7.14# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:04<00:36,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:04<00:36,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:05<00:35,  2.10it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:05<00:35,  2.10it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:06<00:34,  2.10it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:06<00:34,  2.11it/s]Progress: 79.00%
---- avg training fps: 7.16# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:07<00:33,  2.11it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:07<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:08<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:08<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:08<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:09<00:31,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:09<00:31,  2.11it/s]Progress: 81.00%
---- avg training fps: 7.19# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:10<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:10<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:11<00:29,  2.10it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:11<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:12<00:28,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:12<00:28,  2.11it/s]Progress: 83.00%
---- avg training fps: 7.22# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:12<00:28,  2.11it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:12<00:27,  2.11it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:13<00:27,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:13<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:14<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:14<00:25,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:15<00:25,  2.12it/s]Progress: 85.00%
---- avg training fps: 7.24# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:15<00:25,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:16<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:16<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:18<00:22,  2.12it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.27# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:18<00:22,  2.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:19<00:21,  2.13it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:19<00:21,  2.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:20<00:20,  2.12it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:20<00:20,  2.12it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:21<00:19,  2.12it/s]Progress: 89.00%
---- avg training fps: 7.29# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:21<00:19,  2.12it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:21<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:22<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:22<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:22<00:17,  2.12it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:23<00:17,  2.12it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:23<00:16,  2.12it/s]Progress: 91.00%
---- avg training fps: 7.32# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:24<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:24<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:25<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:25<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:26<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:26<00:14,  2.11it/s]Progress: 93.00%
---- avg training fps: 7.34# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:27<00:14,  2.11it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:27<00:13,  2.11it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:27<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:28<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:28<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:29<00:11,  2.12it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:29<00:11,  2.11it/s]Progress: 95.00%
---- avg training fps: 7.36# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:29<00:10,  2.11it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:30<00:10,  2.11it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:30<00:10,  2.09it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:31<00:09,  2.05it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:31<00:09,  2.05it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:31<00:09,  2.07it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:32<00:08,  2.07it/s]Progress: 97.00%
---- avg training fps: 7.38# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:32<00:08,  2.08it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:33<00:07,  2.09it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:33<00:07,  2.10it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:34<00:06,  2.11it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:34<00:06,  2.11it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:35<00:05,  2.11it/s]Progress: 99.00%
---- avg training fps: 7.40# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:35<00:05,  2.11it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:36<00:05,  1.87it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:36<00:05,  1.87it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:36<00:04,  1.95it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:37<00:03,  2.00it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:37<00:03,  2.04it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:38<00:02,  2.05it/s]Progress: 100.00%
---- avg training fps: 7.41# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:38<00:02,  2.08it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:39<00:01,  2.10it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:39<00:01,  2.10it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:40<00:00,  2.11it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:40<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:41<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.43Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.58it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.48it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.47it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.45it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.45it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.44it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.44it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.43it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.42it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.42it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.41it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.41it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.41it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.40it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.40it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.40it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.40it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.39it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.39it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.39it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.48it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.37it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.36it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.36it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:00<00:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 03:29:57.560146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:29:57.650042: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:29:57.650066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:29:57.668821: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:29:58.058335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:29:58.058413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:29:58.058423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_03-29-59-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723512599.8059993 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 211582.10it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.73it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  4.41it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.29it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_03-29-59-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 201649.23it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.54it/s] 20%|██        | 2/10 [00:00<00:02,  3.40it/s] 30%|███       | 3/10 [00:00<00:01,  4.07it/s] 40%|████      | 4/10 [00:01<00:01,  4.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.30it/s] 60%|██████    | 6/10 [00:01<00:00,  4.52it/s] 70%|███████   | 7/10 [00:01<00:00,  4.55it/s] 80%|████████  | 8/10 [00:01<00:00,  4.70it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.70it/s]100%|██████████| 10/10 [00:02<00:00,  4.85it/s]100%|██████████| 10/10 [00:02<00:00,  4.40it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike scenes.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress is walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike scenes.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 9005.97it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:09,  3.04s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:57,  4.02s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:52,  2.40s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:04,  1.64s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:58,  1.22s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:43,  1.04it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.38# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:55,  1.25it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:23,  1.43it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:02,  1.59it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:38,  1.82it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:31,  1.90it/s]Progress: 7.00%
---- avg training fps: 3.65# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:43,  1.75it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:34,  1.85it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:14<02:28,  1.92it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:23,  1.98it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:15<02:20,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:17,  2.05it/s]Progress: 9.00%
---- avg training fps: 4.51# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:15,  2.07it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:10,  2.11it/s]Progress: 11.00%
---- avg training fps: 5.11# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:10,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:20<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:21<02:07,  2.12it/s]Progress: 13.00%
---- avg training fps: 5.55# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:22<02:06,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:06,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:23<02:05,  2.12it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:05,  2.12it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:04,  2.12it/s]Progress: 15.00%
---- avg training fps: 5.89# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:04,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:03,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:02,  2.12it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:02,  2.12it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:26<02:02,  2.12it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:26<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<02:01,  2.13it/s]Progress: 17.00%
---- avg training fps: 6.16# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:27<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:28<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:59,  2.12it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:29<01:59,  2.12it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:58,  2.12it/s]Progress: 19.00%
---- avg training fps: 6.38# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:30<01:57,  2.13it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:31<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:31<01:56,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:35<06:32,  1.58s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:08,  1.25s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:36<04:09,  1.01s/it]Progress: 21.00%
---- avg training fps: 5.90# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:28,  1.17it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:37<03:00,  1.35it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:39,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:38<02:25,  1.66it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.77it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.08# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:03,  1.93it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:59,  1.98it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:40<01:57,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:41<01:53,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:52,  2.08it/s]Progress: 25.00%
---- avg training fps: 6.24# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:42<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:50,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:43<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:44<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:44<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:47,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.38# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:45<01:47,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:46<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:47<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:44,  2.12it/s]Progress: 29.00%
---- avg training fps: 6.51# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:44,  2.12it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:48<01:44,  2.11it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:44,  2.11it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:49<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:50<01:42,  2.12it/s]Progress: 31.00%
---- avg training fps: 6.61# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:41,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:51<01:41,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:40,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:52<01:40,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:39,  2.11it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:53<01:39,  2.11it/s]Progress: 33.00%
---- avg training fps: 6.71# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:39,  2.11it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:39,  2.11it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:54<01:38,  2.11it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:55<01:37,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:55<01:36,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:36,  2.12it/s]Progress: 35.00%
---- avg training fps: 6.80# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:56<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:57<01:34,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:58<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:58<01:33,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:02<05:37,  1.70s/it]Progress: 37.00%
---- avg training fps: 6.44# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:03<04:22,  1.33s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:03<03:30,  1.07s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:04<02:54,  1.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:04<02:28,  1.30it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:05<02:10,  1.47it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:05<01:58,  1.62it/s]Progress: 39.00%
---- avg training fps: 6.52# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:06<01:49,  1.75it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:06<01:43,  1.84it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:07<01:43,  1.84it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:07<01:38,  1.92it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:07<01:35,  1.97it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:08<01:32,  2.01it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:08<01:31,  2.04it/s]Progress: 41.00%
---- avg training fps: 6.60# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:09<01:29,  2.06it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:09<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:10<01:27,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:10<01:26,  2.10it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:10<01:26,  2.10it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:11<01:25,  2.10it/s]Progress: 43.00%
---- avg training fps: 6.68# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:11<01:25,  2.10it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:11<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:12<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:12<01:23,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:13<01:23,  2.11it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:13<01:22,  2.11it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:14<01:22,  2.12it/s]Progress: 45.00%
---- avg training fps: 6.74# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:14<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:15<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:15<01:20,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:16<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:16<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:16<01:19,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:17<01:19,  2.12it/s]Progress: 47.00%
---- avg training fps: 6.81# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:17<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:18<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:18<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:18<01:17,  2.11it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:19<01:17,  2.11it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:19<01:16,  2.11it/s]Progress: 49.00%
---- avg training fps: 6.86# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:20<01:16,  2.11it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:21<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:21<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:21<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:22<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:22<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 6.92# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:23<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:23<01:13,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:24<01:12,  2.10it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:24<01:12,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:25<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:25<01:11,  2.11it/s]Progress: 53.00%
---- avg training fps: 6.97# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:26<01:11,  2.11it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:26<01:10,  2.11it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:30<04:13,  1.71s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:31<03:16,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:31<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:32<02:09,  1.12it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:32<01:50,  1.30it/s]Progress: 55.00%
---- avg training fps: 6.71# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:33<01:37,  1.47it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:33<01:27,  1.62it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:33<01:20,  1.75it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:34<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:34<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:34<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:35<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.76# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:35<01:07,  2.04it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:36<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:36<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:37<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:37<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:38<01:01,  2.13it/s]Progress: 59.00%
---- avg training fps: 6.81# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:38<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:39<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:39<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:39<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:40<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:40<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:40<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 6.86# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:41<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:41<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:42<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:42<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:43<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:43<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 6.91# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:44<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:44<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:44<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:45<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:45<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:46<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:46<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 6.95# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:46<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:47<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:47<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:48<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:48<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:48<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:49<00:50,  2.16it/s]Progress: 67.00%
---- avg training fps: 7.00# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:49<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:50<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:50<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:51<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:51<00:47,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:52<00:47,  2.16it/s]Progress: 69.00%
---- avg training fps: 7.04# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:52<00:46,  2.16it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:53<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:53<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:53<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:57<02:39,  1.63s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:58<02:04,  1.28s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:58<01:39,  1.03s/it]Progress: 71.00%
---- avg training fps: 6.83# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:59<01:30,  1.05it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:59<01:15,  1.25it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [02:00<01:05,  1.43it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [02:00<00:57,  1.60it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:01<00:52,  1.73it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:01<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 6.87# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:02<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:02<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:02<00:43,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:03<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:03<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:04<00:40,  2.11it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:04<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 6.91# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:05<00:38,  2.15it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:05<00:38,  2.15it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:05<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:06<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:06<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:06<00:36,  2.17it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:07<00:35,  2.17it/s]Progress: 77.00%
---- avg training fps: 6.95# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:07<00:35,  2.17it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:08<00:34,  2.18it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:08<00:34,  2.18it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:09<00:34,  2.18it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:09<00:33,  2.18it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:10<00:33,  2.18it/s]Progress: 79.00%
---- avg training fps: 6.99# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:10<00:32,  2.18it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:10<00:32,  2.18it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:11<00:32,  2.18it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:11<00:31,  2.18it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:11<00:31,  2.18it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:12<00:30,  2.18it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:12<00:30,  2.18it/s]Progress: 81.00%
---- avg training fps: 7.02# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:13<00:29,  2.18it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:13<00:29,  2.18it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:14<00:28,  2.18it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:14<00:28,  2.18it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:15<00:28,  2.17it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:15<00:27,  2.17it/s]Progress: 83.00%
---- avg training fps: 7.06# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:16<00:27,  2.17it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:16<00:27,  2.17it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:16<00:26,  2.17it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:16<00:26,  2.18it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:17<00:25,  2.18it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:17<00:25,  2.18it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:18<00:24,  2.18it/s]Progress: 85.00%
---- avg training fps: 7.09# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:18<00:24,  2.18it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:19<00:23,  2.18it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:19<00:23,  2.18it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:20<00:22,  2.18it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:20<00:22,  2.18it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:20<00:22,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:24<01:18,  1.63s/it]Progress: 87.00%
---- avg training fps: 6.93# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:25<01:00,  1.28s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:25<00:47,  1.03s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:26<00:38,  1.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:26<00:32,  1.35it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:27<00:28,  1.52it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:27<00:25,  1.67it/s]Progress: 89.00%
---- avg training fps: 6.96# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:28<00:22,  1.79it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:28<00:21,  1.89it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:29<00:21,  1.89it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:29<00:19,  1.96it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:29<00:18,  2.01it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:30<00:18,  2.05it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:30<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 6.99# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:30<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:31<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:31<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:32<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:32<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:33<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.02# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:33<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:33<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:34<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:34<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:35<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:35<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:36<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.05# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:36<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:37<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:37<00:09,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:37<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:38<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:38<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:38<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.08# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:39<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:39<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:40<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:40<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:41<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:41<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.11# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:42<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:42<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:43<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:43<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:43<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:43<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:44<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.13# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:44<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:45<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:45<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:46<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:46<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:47<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.16Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.47it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.46it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.46it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.46it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.45it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.44it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.44it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.44it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.43it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.43it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.43it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.42it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.42it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.42it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.41it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.41it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.41it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.41it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.40it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.40it/s][A100%|██████████| 30/30 [00:08<00:00,  3.46it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.46it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.43it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.41it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.40it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.39it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.39it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.39it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.38it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.38it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.38it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.36it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.75it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:06<00:00,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 03:34:31.227219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:34:31.319832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:34:31.319856: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:34:31.338315: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:34:31.737792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:34:31.737870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:34:31.737879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23134 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_03-34-33-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723512873.5619853 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 53692.14it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.65it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.73it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.82it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.14it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_03-34-33-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.40it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.50it/s] 20%|██        | 2/10 [00:00<00:01,  4.40it/s] 30%|███       | 3/10 [00:00<00:01,  4.65it/s] 40%|████      | 4/10 [00:00<00:01,  4.76it/s] 50%|█████     | 5/10 [00:01<00:01,  4.71it/s] 60%|██████    | 6/10 [00:01<00:00,  4.73it/s] 70%|███████   | 7/10 [00:01<00:00,  4.92it/s] 80%|████████  | 8/10 [00:01<00:00,  4.98it/s] 90%|█████████ | 9/10 [00:01<00:00,  4.97it/s]100%|██████████| 10/10 [00:02<00:00,  4.81it/s]100%|██████████| 10/10 [00:02<00:00,  4.74it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal blending of nature and technology

- In the style of TOK, a potted plant sits on top of a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is placed on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is set against a black background.
- In the style of TOK, a potted plant sits on top of a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is placed on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal blending of nature and technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 6753.57it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:13,  3.05s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:11,  3.46s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:21,  2.09s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:09,  1.45s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:23,  1.10s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:20,  1.13it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.63# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:39,  1.34it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:12,  1.52it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:54,  1.66it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:34,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 4.01# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:23,  2.00it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:20,  2.03it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:18,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:16,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:15,  2.09it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.87# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:10,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:09,  2.12it/s]Progress: 11.00%
---- avg training fps: 5.45# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:07,  2.11it/s]Progress: 13.00%
---- avg training fps: 5.87# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:06,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:20,  1.89it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:15,  1.96it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:11,  2.01it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:09,  2.04it/s]Progress: 15.00%
---- avg training fps: 6.14# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:06,  2.07it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:05,  2.09it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:04,  2.10it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:02,  2.11it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:02,  2.11it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:02,  2.12it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:01,  2.12it/s]Progress: 17.00%
---- avg training fps: 6.40# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:59,  2.12it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:58,  2.12it/s]Progress: 19.00%
---- avg training fps: 6.60# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:58,  2.12it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:57,  2.12it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<06:11,  1.50s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:54,  1.19s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:59,  1.03it/s]Progress: 21.00%
---- avg training fps: 6.11# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:21,  1.21it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:55,  1.39it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:36,  1.55it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:23,  1.69it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:13,  1.80it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:07,  1.89it/s]Progress: 23.00%
---- avg training fps: 6.29# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:02,  1.95it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<02:12,  1.79it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<02:05,  1.89it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<02:00,  1.95it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:57,  2.00it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:54,  2.04it/s]Progress: 25.00%
---- avg training fps: 6.41# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:52,  2.06it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:51,  2.08it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:50,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:48,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:47,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.54# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:47,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:44,  2.12it/s]Progress: 29.00%
---- avg training fps: 6.66# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:44,  2.12it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:43,  2.11it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.77# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:38,  2.13it/s]Progress: 33.00%
---- avg training fps: 6.86# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.95# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:35,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:33,  2.13it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.02# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:59<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:00<01:31,  2.11it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:30,  2.11it/s]Progress: 39.00%
---- avg training fps: 7.09# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:30,  2.11it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:29,  2.11it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:29,  2.11it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:29,  2.11it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:29,  2.10it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:28,  2.11it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:28,  2.11it/s]Progress: 41.00%
---- avg training fps: 7.15# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:27,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:05<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:06<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 7.20# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:07<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:08<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:22,  2.12it/s]Progress: 45.00%
---- avg training fps: 7.26# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:11<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:11<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:11<01:20,  2.10it/s]Progress: 47.00%
---- avg training fps: 7.30# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:19,  2.10it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:13<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:17,  2.11it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:14<01:17,  2.11it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:16,  2.11it/s]Progress: 49.00%
---- avg training fps: 7.35# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:16,  2.11it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:16<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:16<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 7.39# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:12,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:20<01:10,  2.12it/s]Progress: 53.00%
---- avg training fps: 7.42# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:10,  2.11it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<03:56,  1.60s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:25<03:05,  1.26s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:26<02:30,  1.03s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<02:04,  1.16it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:47,  1.34it/s]Progress: 55.00%
---- avg training fps: 7.14# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:34,  1.51it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:26,  1.65it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:19,  1.77it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:09,  1.98it/s]Progress: 57.00%
---- avg training fps: 7.18# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:07,  2.02it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:31<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:03,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.22# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:33<01:02,  2.09it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:34<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:34<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<01:00,  2.11it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<01:00,  2.10it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:59,  2.10it/s]Progress: 61.00%
---- avg training fps: 7.25# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:59,  2.10it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:58,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:58,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:37<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:56,  2.11it/s]Progress: 63.00%
---- avg training fps: 7.29# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:38<00:56,  2.11it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:38<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:39<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:39<00:55,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:40<00:54,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:54,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:41<00:54,  2.10it/s]Progress: 65.00%
---- avg training fps: 7.32# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:53,  2.10it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:42<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:52,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:51,  2.10it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:51,  2.10it/s]Progress: 67.00%
---- avg training fps: 7.35# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:50,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:44<00:50,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:49,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:45<00:49,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:46<00:48,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:46<00:48,  2.11it/s]Progress: 69.00%
---- avg training fps: 7.38# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:47<00:47,  2.11it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:48<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:48<00:46,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:38,  1.62s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:53<02:04,  1.28s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:39,  1.04s/it]Progress: 71.00%
---- avg training fps: 7.16# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:22,  1.15it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:10,  1.34it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<01:02,  1.50it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:55<00:56,  1.64it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:51,  1.76it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 7.19# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:46,  1.91it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:44,  1.96it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:43,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:58<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:59<00:40,  2.07it/s]Progress: 75.00%
---- avg training fps: 7.22# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:39,  2.08it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:00<00:39,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:38,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:01<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:37,  2.09it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:02<00:37,  2.09it/s]Progress: 77.00%
---- avg training fps: 7.25# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:36,  2.10it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:03<00:36,  2.10it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:35,  2.10it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:34,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:04<00:34,  2.11it/s]Progress: 79.00%
---- avg training fps: 7.27# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:05<00:33,  2.11it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:05<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:06<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:06<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:07<00:31,  2.10it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:31,  2.11it/s]Progress: 81.00%
---- avg training fps: 7.30# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:08<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:09<00:29,  2.10it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:29,  2.10it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:10<00:29,  2.10it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:28,  2.10it/s]Progress: 83.00%
---- avg training fps: 7.32# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:11<00:28,  2.10it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:11<00:28,  2.09it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:27,  2.10it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:12<00:27,  2.10it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:12<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:13<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:13<00:25,  2.11it/s]Progress: 85.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:25,  2.11it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:14<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:15<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:16<00:22,  2.12it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.37# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:16<00:22,  2.11it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:17<00:21,  2.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:17<00:21,  2.11it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:18<00:20,  2.11it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:18<00:20,  2.11it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:19<00:19,  2.11it/s]Progress: 89.00%
---- avg training fps: 7.39# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:19<00:19,  2.11it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:20<00:18,  2.11it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:20<00:18,  2.11it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:20<00:18,  2.10it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:21<00:18,  2.11it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:21<00:17,  2.11it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:21<00:17,  2.11it/s]Progress: 91.00%
---- avg training fps: 7.41# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:22<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:22<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:23<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:23<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:24<00:16,  1.87it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:25<00:15,  1.94it/s]Progress: 93.00%
---- avg training fps: 7.42# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:25<00:15,  1.94it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:25<00:14,  1.98it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:25<00:13,  2.02it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:26<00:13,  2.05it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:26<00:12,  2.07it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:27<00:11,  2.09it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:27<00:11,  2.10it/s]Progress: 95.00%
---- avg training fps: 7.44# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:28<00:10,  2.10it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:28<00:10,  2.10it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:29<00:09,  2.11it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:29<00:09,  2.11it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:30<00:09,  2.11it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:30<00:08,  2.11it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:30<00:08,  2.12it/s]Progress: 97.00%
---- avg training fps: 7.46# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:31<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:31<00:07,  2.11it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:32<00:07,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:32<00:06,  2.12it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:33<00:06,  2.11it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:33<00:05,  2.11it/s]Progress: 99.00%
---- avg training fps: 7.48# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:34<00:05,  2.11it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:34<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:34<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:34<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:35<00:03,  2.12it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:35<00:03,  2.12it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:36<00:02,  2.12it/s]Progress: 100.00%
---- avg training fps: 7.50# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:36<00:02,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:37<00:01,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:37<00:01,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:38<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:38<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:39<00:00,  2.12it/s]Progress: 100.00%
---- avg training fps: 7.52Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.58it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.49it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.48it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.46it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.45it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.44it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.44it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.43it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.43it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.42it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.41it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.41it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.41it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.39it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.37it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.36it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.18it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.18it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.25it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:58<00:00,  1.26it/s]
------------------------------------------
Training done :)
2024-08-13 03:39:02.238881: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:39:02.329762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:39:02.329790: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:39:02.349380: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:39:02.751738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:39:02.751793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:39:02.751802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23117 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_03-39-04-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723513144.5762262 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 55532.06it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 14.06it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.29it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.79it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.03it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_03-39-04-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.40it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.48it/s] 20%|██        | 2/10 [00:00<00:01,  4.40it/s] 30%|███       | 3/10 [00:00<00:01,  4.67it/s] 40%|████      | 4/10 [00:00<00:01,  4.79it/s] 50%|█████     | 5/10 [00:01<00:01,  4.69it/s] 60%|██████    | 6/10 [00:01<00:00,  4.76it/s] 70%|███████   | 7/10 [00:01<00:00,  5.01it/s] 80%|████████  | 8/10 [00:01<00:00,  5.11it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.10it/s]100%|██████████| 10/10 [00:02<00:00,  4.84it/s]100%|██████████| 10/10 [00:02<00:00,  4.79it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7594.25it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:00,  3.01s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:29,  3.32s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<09:57,  2.01s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:52,  1.39s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:10,  1.05s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:09,  1.18it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.73# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:30,  1.39it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:04,  1.58it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:47,  1.73it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:36,  1.85it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:28,  1.95it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:22,  2.02it/s]Progress: 7.00%
---- avg training fps: 4.17# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:18,  2.07it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:11<02:16,  2.09it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:15,  2.11it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:13,  2.13it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:11,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:10,  2.16it/s]Progress: 9.00%
---- avg training fps: 5.04# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:10,  2.16it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:07,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:07,  2.17it/s]Progress: 11.00%
---- avg training fps: 5.63# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:06,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:04,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]Progress: 13.00%
---- avg training fps: 6.06# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:01,  2.17it/s]Progress: 15.00%
---- avg training fps: 6.33# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:15,  1.94it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:10,  2.01it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:07,  2.05it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:04,  2.09it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:04,  2.09it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:01,  2.12it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.59# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:59,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.79# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:55,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:54,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:47,  1.40s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:36,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:46,  1.09it/s]Progress: 21.00%
---- avg training fps: 6.32# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:11,  1.28it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:47,  1.46it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:30,  1.62it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:18,  1.75it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:09,  1.86it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]Progress: 23.00%
---- avg training fps: 6.50# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:03,  1.95it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:59,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:55,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:53,  2.09it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:51,  2.12it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:50,  2.13it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:49,  2.14it/s]Progress: 25.00%
---- avg training fps: 6.65# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:48,  2.15it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:47,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:46,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<01:46,  2.16it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:46,  2.16it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:45,  2.16it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:44,  2.17it/s]Progress: 27.00%
---- avg training fps: 6.78# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:44,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:57,  1.92it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:52,  1.99it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:49,  2.05it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:46,  2.09it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:45,  2.11it/s]Progress: 29.00%
---- avg training fps: 6.87# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:40,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 6.97# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:38,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:37,  2.17it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:36,  2.19it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:35,  2.19it/s]Progress: 33.00%
---- avg training fps: 7.07# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.16# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:32,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:55<01:30,  2.18it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.23# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:56<01:30,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:56<01:30,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:57<01:29,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:57<01:29,  2.17it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:58<01:28,  2.17it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:58<01:28,  2.17it/s]Progress: 39.00%
---- avg training fps: 7.30# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [00:59<01:27,  2.18it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [00:59<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:00<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:00<01:27,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:00<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:01<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:01<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 7.36# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:01<01:25,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:03<01:24,  2.16it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:03<01:23,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:04<01:23,  2.16it/s]Progress: 43.00%
---- avg training fps: 7.42# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:04<01:23,  2.16it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:04<01:22,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:05<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:05<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:06<01:21,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:06<01:20,  2.18it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:07<01:20,  2.17it/s]Progress: 45.00%
---- avg training fps: 7.47# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:07<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:07<01:19,  2.16it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:08<01:18,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:08<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:09<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:09<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:09<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.51# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:10<01:17,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:10<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:11<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:11<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:12<01:14,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:12<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.56# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:13<01:14,  2.16it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:13<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:13<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:13<01:13,  2.17it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:14<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:14<01:12,  2.16it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:15<01:12,  2.15it/s]Progress: 51.00%
---- avg training fps: 7.60# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:15<01:11,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:16<01:11,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:16<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:17<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:17<01:09,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:18<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.63# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:18<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:18<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:22<03:49,  1.55s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:23<02:59,  1.22s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:23<02:25,  1.01it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:24<02:01,  1.20it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:24<01:44,  1.38it/s]Progress: 55.00%
---- avg training fps: 7.34# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:25<01:32,  1.55it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:25<01:23,  1.70it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:25<01:17,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:26<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:26<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:26<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:27<01:08,  2.03it/s]Progress: 57.00%
---- avg training fps: 7.38# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:27<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:28<01:05,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:28<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:29<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:29<01:02,  2.14it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:30<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.42# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:30<01:00,  2.15it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:31<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:31<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:31<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:31<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:32<00:58,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:32<00:58,  2.16it/s]Progress: 61.00%
---- avg training fps: 7.46# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:33<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:33<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:34<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:34<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:35<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:35<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.49# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:36<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:36<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:36<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:37<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:37<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:37<00:53,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:38<00:52,  2.15it/s]Progress: 65.00%
---- avg training fps: 7.52# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:38<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:39<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:39<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:40<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:40<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:40<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:41<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.55# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:41<00:50,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:42<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:42<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:43<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:43<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:44<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.58# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:44<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:44<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:45<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:45<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:49<02:29,  1.53s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:49<01:57,  1.21s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:50<01:34,  1.02it/s]Progress: 71.00%
---- avg training fps: 7.36# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:50<01:18,  1.21it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:51<01:07,  1.40it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:51<00:59,  1.56it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:52<00:54,  1.70it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:52<00:49,  1.82it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:53<00:47,  1.91it/s]Progress: 73.00%
---- avg training fps: 7.39# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:53<00:47,  1.91it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:53<00:45,  1.97it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:54<00:43,  2.02it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:54<00:42,  2.06it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:55<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:55<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:55<00:39,  2.13it/s]Progress: 75.00%
---- avg training fps: 7.42# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:56<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:56<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:57<00:37,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:57<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [01:58<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [01:58<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [01:58<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.45# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [01:59<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [01:59<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:00<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:00<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:01<00:33,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:01<00:33,  2.15it/s]Progress: 79.00%
---- avg training fps: 7.48# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:01<00:32,  2.15it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:02<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:02<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:02<00:31,  2.17it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:03<00:31,  2.17it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:03<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:04<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.50# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:04<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:05<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:05<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:06<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:06<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:07<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.53# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:07<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:07<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:08<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:08<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:08<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:09<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:09<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.55# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:10<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:10<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:11<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:11<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:12<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:12<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:12<00:22,  2.16it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.57# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:13<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:13<00:21,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:14<00:20,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:14<00:20,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:14<00:19,  2.15it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:15<00:19,  2.16it/s]Progress: 89.00%
---- avg training fps: 7.59# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:15<00:19,  2.15it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:16<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:16<00:18,  2.15it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:16<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:17<00:17,  2.15it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:17<00:17,  2.15it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:18<00:16,  2.15it/s]Progress: 91.00%
---- avg training fps: 7.62# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:18<00:16,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:19<00:15,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:19<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:20<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:20<00:14,  2.16it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:21<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.63# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:21<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:21<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:21<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:22<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:22<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:23<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:23<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.65# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:24<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:24<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:25<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:25<00:10,  1.91it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:26<00:10,  1.91it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:26<00:09,  1.97it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:26<00:08,  2.02it/s]Progress: 97.00%
---- avg training fps: 7.66# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:27<00:08,  2.06it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:27<00:07,  2.09it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:28<00:07,  2.11it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:28<00:06,  2.12it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:29<00:06,  2.08it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:29<00:05,  2.09it/s]Progress: 99.00%
---- avg training fps: 7.68# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:30<00:05,  2.09it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:30<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:31<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:31<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:31<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:31<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:32<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.69# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:32<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:33<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:33<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:34<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:34<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:35<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.71Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.96it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.22it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.15it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.19it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.22it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:55<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 03:43:32.328342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:43:32.419573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:43:32.419599: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:43:32.438276: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:43:32.839855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:43:32.839937: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:43:32.839946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23105 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_03-43-34-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723513414.6742449 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 15157.99it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.31it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.50it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.82it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_03-43-34-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.38it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.49it/s] 20%|██        | 2/10 [00:00<00:01,  4.40it/s] 30%|███       | 3/10 [00:00<00:01,  4.67it/s] 40%|████      | 4/10 [00:00<00:01,  4.86it/s] 50%|█████     | 5/10 [00:01<00:01,  4.83it/s] 60%|██████    | 6/10 [00:01<00:00,  4.86it/s] 70%|███████   | 7/10 [00:01<00:00,  5.08it/s] 80%|████████  | 8/10 [00:01<00:00,  5.15it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.14it/s]100%|██████████| 10/10 [00:02<00:00,  4.99it/s]100%|██████████| 10/10 [00:02<00:00,  4.87it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal blending of nature and technology

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal blending of nature and technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7602.51it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:44,  2.96s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:10,  3.26s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:46,  1.97s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:46,  1.37s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:06,  1.04s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:07,  1.19it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.77# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:28,  1.40it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:03,  1.59it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:46,  1.74it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:36,  1.86it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:36,  1.86it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:28,  1.95it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:10<02:22,  2.02it/s]Progress: 7.00%
---- avg training fps: 4.21# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:19,  2.06it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:11<02:16,  2.10it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:14,  2.12it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:12,  2.15it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:10,  2.16it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:09,  2.17it/s]Progress: 9.00%
---- avg training fps: 5.09# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:09,  2.18it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:08,  2.18it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:08,  2.18it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:08,  2.18it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:07,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:15<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:06,  2.18it/s]Progress: 11.00%
---- avg training fps: 5.69# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:16<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:05,  2.19it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:17<02:05,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:04,  2.18it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:18<02:03,  2.19it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:03,  2.18it/s]Progress: 13.00%
---- avg training fps: 6.11# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:03,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:02,  2.18it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:01,  2.18it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:01,  2.19it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:21<02:01,  2.18it/s]Progress: 15.00%
---- avg training fps: 6.38# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:15,  1.95it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:09,  2.02it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:06,  2.07it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:23<02:03,  2.10it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:03,  2.10it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:24<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.64# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<01:59,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:25<01:59,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:26<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:27<01:55,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.84# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:55,  2.17it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:28<01:54,  2.18it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:32<05:39,  1.37s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:32<04:30,  1.09s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:42,  1.11it/s]Progress: 21.00%
---- avg training fps: 6.38# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:33<03:08,  1.30it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:45,  1.48it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:34<02:28,  1.63it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:16,  1.77it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:35<02:08,  1.88it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:02,  1.97it/s]Progress: 23.00%
---- avg training fps: 6.56# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:36<02:02,  1.97it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:36<01:57,  2.03it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:54,  2.07it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:37<01:52,  2.11it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:37<01:50,  2.13it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:38<01:49,  2.15it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:38<01:48,  2.16it/s]Progress: 25.00%
---- avg training fps: 6.71# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:39<01:47,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:39<01:46,  2.17it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:46,  2.16it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:40<01:46,  2.17it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:41<01:46,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:41<01:45,  2.17it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:41<01:44,  2.18it/s]Progress: 27.00%
---- avg training fps: 6.84# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:42<01:44,  2.17it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:42<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:43,  2.18it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:43<01:55,  1.93it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:51,  2.00it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:44<01:48,  2.05it/s]Progress: 29.00%
---- avg training fps: 6.93# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:45,  2.09it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:45<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:45<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:45<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:46<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:46<01:40,  2.16it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:47<01:39,  2.17it/s]Progress: 31.00%
---- avg training fps: 7.03# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:47<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:48<01:38,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:48<01:37,  2.18it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:49<01:37,  2.17it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:49<01:36,  2.18it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:36,  2.19it/s]Progress: 33.00%
---- avg training fps: 7.12# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:50<01:36,  2.19it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:50<01:35,  2.19it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:50<01:35,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:51<01:34,  2.18it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:51<01:34,  2.19it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:52<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:52<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.21# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:53<01:33,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:53<01:32,  2.19it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:54<01:32,  2.18it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:54<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:55<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:55<01:31,  2.18it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:55<01:30,  2.19it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.28# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:56<01:30,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:56<01:30,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:56<01:29,  2.17it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:57<01:28,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:57<01:28,  2.18it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [00:58<01:28,  2.17it/s]Progress: 39.00%
---- avg training fps: 7.35# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [00:58<01:28,  2.17it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [00:59<01:27,  2.18it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [00:59<01:27,  2.18it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [00:59<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:00<01:26,  2.17it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:00<01:26,  2.16it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:01<01:25,  2.18it/s]Progress: 41.00%
---- avg training fps: 7.41# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:01<01:24,  2.18it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:02<01:24,  2.17it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:02<01:23,  2.17it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:03<01:23,  2.18it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:03<01:22,  2.17it/s]Progress: 43.00%
---- avg training fps: 7.46# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:04<01:22,  2.17it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:04<01:22,  2.17it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:04<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:05<01:21,  2.18it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:05<01:20,  2.18it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:06<01:20,  2.17it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:06<01:19,  2.18it/s]Progress: 45.00%
---- avg training fps: 7.51# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:07<01:19,  2.18it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:07<01:19,  2.17it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:08<01:19,  2.16it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:08<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:08<01:18,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:08<01:17,  2.17it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:09<01:17,  2.17it/s]Progress: 47.00%
---- avg training fps: 7.56# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:09<01:17,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:10<01:16,  2.18it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:10<01:16,  2.17it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:11<01:15,  2.17it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:11<01:15,  2.16it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:12<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.60# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:12<01:14,  2.17it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:13<01:14,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:13<01:14,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:13<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:14<01:12,  2.17it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:14<01:12,  2.18it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:14<01:12,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.64# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:15<01:11,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:15<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:16<01:10,  2.17it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:16<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:17<01:09,  2.17it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:17<01:08,  2.18it/s]Progress: 53.00%
---- avg training fps: 7.68# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:18<01:08,  2.18it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:18<01:08,  2.18it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:22<03:44,  1.52s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:22<02:56,  1.20s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:23<02:22,  1.02it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:23<01:59,  1.22it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:23<01:42,  1.40it/s]Progress: 55.00%
---- avg training fps: 7.39# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:24<01:31,  1.57it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:24<01:22,  1.72it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:25<01:16,  1.83it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:25<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:26<01:12,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:26<01:09,  1.99it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:26<01:06,  2.06it/s]Progress: 57.00%
---- avg training fps: 7.43# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:27<01:05,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:27<01:04,  2.12it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:28<01:03,  2.14it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:28<01:01,  2.16it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:29<01:01,  2.16it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:29<01:00,  2.17it/s]Progress: 59.00%
---- avg training fps: 7.47# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:29<01:00,  2.16it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:30<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:30<01:00,  2.16it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:30<00:59,  2.17it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:31<00:58,  2.17it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:31<00:58,  2.16it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:32<00:58,  2.17it/s]Progress: 61.00%
---- avg training fps: 7.51# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:32<00:57,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:33<00:57,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:33<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:34<00:56,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:34<00:55,  2.17it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:35<00:55,  2.17it/s]Progress: 63.00%
---- avg training fps: 7.54# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:35<00:55,  2.17it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:35<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:35<00:54,  2.18it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:36<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:36<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:37<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:37<00:52,  2.17it/s]Progress: 65.00%
---- avg training fps: 7.57# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:38<00:52,  2.17it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:38<00:51,  2.17it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:39<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:39<00:50,  2.17it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:40<00:50,  2.17it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:40<00:50,  2.17it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:40<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.60# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:41<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:41<00:48,  2.17it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:41<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:42<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:42<00:47,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:43<00:47,  2.16it/s]Progress: 69.00%
---- avg training fps: 7.63# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:43<00:46,  2.15it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:44<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:44<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:44<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:48<02:24,  1.48s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:49<01:53,  1.17s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:49<01:31,  1.05it/s]Progress: 71.00%
---- avg training fps: 7.42# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:49<01:16,  1.24it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:50<01:05,  1.43it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:50<00:58,  1.59it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:51<00:52,  1.74it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:51<00:49,  1.86it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:52<00:46,  1.94it/s]Progress: 73.00%
---- avg training fps: 7.46# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:52<00:46,  1.94it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:52<00:44,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:53<00:42,  2.06it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:53<00:41,  2.09it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:54<00:40,  2.11it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:54<00:39,  2.13it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:54<00:38,  2.16it/s]Progress: 75.00%
---- avg training fps: 7.49# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:55<00:38,  2.17it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:55<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [01:56<00:37,  2.16it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [01:56<00:36,  2.16it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [01:57<00:36,  2.16it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [01:57<00:36,  2.16it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [01:57<00:36,  2.16it/s]Progress: 77.00%
---- avg training fps: 7.51# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [01:58<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [01:58<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [01:59<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [01:59<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:00<00:33,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:00<00:33,  2.17it/s]Progress: 79.00%
---- avg training fps: 7.54# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:00<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:01<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:01<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:01<00:31,  2.17it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:02<00:31,  2.18it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:02<00:30,  2.17it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:03<00:30,  2.17it/s]Progress: 81.00%
---- avg training fps: 7.56# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:03<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:04<00:29,  2.18it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:04<00:29,  2.17it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:05<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:05<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:06<00:27,  2.17it/s]Progress: 83.00%
---- avg training fps: 7.59# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:06<00:27,  2.17it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:06<00:27,  2.17it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:06<00:26,  2.17it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:07<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:07<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:08<00:25,  2.15it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:08<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.61# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:09<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:09<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:10<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:10<00:23,  2.15it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:11<00:23,  2.15it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:11<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:11<00:22,  2.16it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.63# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:12<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:12<00:21,  2.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:12<00:20,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:13<00:20,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:13<00:19,  2.16it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:14<00:19,  2.16it/s]Progress: 89.00%
---- avg training fps: 7.65# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:14<00:18,  2.17it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:15<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:15<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:15<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:16<00:17,  2.15it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:16<00:17,  2.16it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:17<00:16,  2.15it/s]Progress: 91.00%
---- avg training fps: 7.67# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:17<00:16,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:18<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:18<00:15,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:19<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:19<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:19<00:13,  2.16it/s]Progress: 93.00%
---- avg training fps: 7.69# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:20<00:13,  2.16it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:20<00:13,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:20<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:21<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:21<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:22<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:22<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.71# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:23<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:23<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:24<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:24<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:25<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:25<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:25<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.73# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:26<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:26<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:26<00:06,  2.17it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:27<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:27<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:28<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.74# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:28<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:29<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:29<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:29<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:30<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:30<00:03,  2.17it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:31<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.76# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:31<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:32<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:32<00:01,  1.92it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:33<00:01,  1.98it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:33<00:00,  2.02it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:34<00:00,  2.07it/s]Progress: 100.00%
---- avg training fps: 7.77Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.97it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.28it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:54<00:00,  1.28it/s]
------------------------------------------
Training done :)
2024-08-13 03:47:58.629349: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:47:58.721340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:47:58.721369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:47:58.740258: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:47:59.142726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:47:59.142809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:47:59.142819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23109 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_03-48-00-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723513680.9630408 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 55402.62it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.99it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.74it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.88it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.21it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_03-48-00-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 199728.76it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.63it/s] 20%|██        | 2/10 [00:00<00:02,  3.45it/s] 30%|███       | 3/10 [00:00<00:01,  3.89it/s] 40%|████      | 4/10 [00:01<00:01,  3.98it/s] 50%|█████     | 5/10 [00:01<00:01,  4.08it/s] 60%|██████    | 6/10 [00:01<00:00,  4.22it/s] 70%|███████   | 7/10 [00:01<00:00,  4.21it/s] 80%|████████  | 8/10 [00:01<00:00,  4.33it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.26it/s]100%|██████████| 10/10 [00:02<00:00,  4.31it/s]100%|██████████| 10/10 [00:02<00:00,  4.09it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, focus on vastness.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak stands in front of a building.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a camel in front of a mountain.
- In the style of TOK, a man stands on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walks through an archway.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a dog on a leash.
- In the style of TOK, a person walks on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, focus on vastness.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10099.46it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person stands ...
3     in the style of <s0><s1><s2>, a person walks i...
4     in the style of <s0><s1><s2>, a man stands on ...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person stands ...
8     in the style of <s0><s1><s2>, a person walks i...
9     in the style of <s0><s1><s2>, a person walks o...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person stands ...
13    in the style of <s0><s1><s2>, a person walks i...
14    in the style of <s0><s1><s2>, a man stands on ...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person stands ...
18    in the style of <s0><s1><s2>, a person walks i...
19    in the style of <s0><s1><s2>, a person walks o...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person stands ...
23    in the style of <s0><s1><s2>, a person walks i...
24    in the style of <s0><s1><s2>, a man stands on ...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person stands ...
28    in the style of <s0><s1><s2>, a person walks i...
29    in the style of <s0><s1><s2>, a person walks o...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person stands ...
33    in the style of <s0><s1><s2>, a person walks i...
34    in the style of <s0><s1><s2>, a man stands on ...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person stands ...
38    in the style of <s0><s1><s2>, a person walks i...
39    in the style of <s0><s1><s2>, a person walks o...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:51,  2.98s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:45,  3.98s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:44,  2.37s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:57,  1.61s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:52,  1.20s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:37,  1.06it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.42# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:50,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:18,  1.47it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:34,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 3.72# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:39,  1.80it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:25,  1.96it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.60# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:12,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:08,  2.15it/s]Progress: 11.00%
---- avg training fps: 5.21# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.15it/s]Progress: 13.00%
---- avg training fps: 5.66# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:04,  2.14it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:03,  2.14it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:03,  2.14it/s]Progress: 15.00%
---- avg training fps: 5.99# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:02,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:01,  2.15it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:01,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:00,  2.14it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<02:00,  2.14it/s]Progress: 17.00%
---- avg training fps: 6.26# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:00,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:59,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:59,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:57,  2.14it/s]Progress: 19.00%
---- avg training fps: 6.48# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:57,  2.14it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:37,  1.60s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:11,  1.26s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:11,  1.02s/it]Progress: 21.00%
---- avg training fps: 5.96# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:30,  1.17it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<03:00,  1.35it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:39,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:25,  1.66it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.78it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.15# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:02,  1.95it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:53,  2.08it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:52,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:50,  2.11it/s]Progress: 25.00%
---- avg training fps: 6.31# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:46,  2.13it/s]Progress: 27.00%
---- avg training fps: 6.45# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.58# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:41,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.69# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:38,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.78# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:38,  2.14it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.87# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:35,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:02<05:42,  1.73s/it]Progress: 37.00%
---- avg training fps: 6.49# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:02<04:26,  1.35s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:03<03:32,  1.09s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:03<02:55,  1.11it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:04<02:29,  1.30it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:04<02:11,  1.47it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:05<01:58,  1.62it/s]Progress: 39.00%
---- avg training fps: 6.58# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:05<01:49,  1.75it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:06<01:42,  1.85it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:06<01:42,  1.85it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:06<01:38,  1.92it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:07<01:34,  1.98it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:07<01:32,  2.02it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:08<01:30,  2.05it/s]Progress: 41.00%
---- avg training fps: 6.66# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:08<01:29,  2.07it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:08<01:28,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:09<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:09<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:10<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:10<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 6.73# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:11<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:11<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:11<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:12<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:12<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:13<01:22,  2.13it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:13<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 6.80# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:14<01:21,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:14<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:15<01:20,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:15<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:16<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:16<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:16<01:19,  2.12it/s]Progress: 47.00%
---- avg training fps: 6.86# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:16<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:17<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:17<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:18<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:18<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:19<01:16,  2.12it/s]Progress: 49.00%
---- avg training fps: 6.92# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:19<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:20<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:20<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:21<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:21<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:22<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 6.97# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:22<01:13,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:23<01:12,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:23<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:24<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:24<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:25<01:10,  2.12it/s]Progress: 53.00%
---- avg training fps: 7.02# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:25<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:25<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:30<04:14,  1.72s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:30<03:17,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:31<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:31<02:10,  1.11it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:31<01:50,  1.30it/s]Progress: 55.00%
---- avg training fps: 6.75# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:32<01:36,  1.48it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:32<01:27,  1.63it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:33<01:20,  1.75it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:33<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:34<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:34<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:34<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.80# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:35<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:35<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:36<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:36<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:37<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:37<01:02,  2.11it/s]Progress: 59.00%
---- avg training fps: 6.85# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:38<01:01,  2.11it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:38<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:39<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:39<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:39<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:39<00:59,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:40<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 6.90# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:40<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:41<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:41<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:42<00:57,  2.13it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:42<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 6.94# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:43<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:43<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:44<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:44<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:45<00:54,  2.13it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:45<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:46<00:53,  2.12it/s]Progress: 65.00%
---- avg training fps: 6.98# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:46<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:47<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:47<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:47<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:48<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:48<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:48<00:50,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.02# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:49<00:50,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:49<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:50<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:50<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:51<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:51<00:47,  2.13it/s]Progress: 69.00%
---- avg training fps: 7.06# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:52<00:47,  2.12it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:52<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:53<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:53<00:46,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:57<02:51,  1.75s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:58<02:12,  1.36s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:58<01:45,  1.09s/it]Progress: 71.00%
---- avg training fps: 6.84# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:59<01:26,  1.10it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:59<01:12,  1.29it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [02:00<01:03,  1.47it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [02:00<00:56,  1.62it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:01<00:52,  1.75it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:01<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 6.88# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:02<00:48,  1.85it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:02<00:46,  1.92it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:02<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:02<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:03<00:41,  2.05it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:03<00:40,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:04<00:40,  2.09it/s]Progress: 75.00%
---- avg training fps: 6.92# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:04<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:05<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:05<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:06<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:07<00:36,  2.13it/s]Progress: 77.00%
---- avg training fps: 6.95# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:07<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:08<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:08<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:09<00:34,  2.12it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:10<00:33,  2.12it/s]Progress: 79.00%
---- avg training fps: 6.99# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:10<00:33,  2.12it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:10<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:11<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:11<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:11<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:12<00:31,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:12<00:31,  2.12it/s]Progress: 81.00%
---- avg training fps: 7.02# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:13<00:30,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:13<00:30,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:14<00:29,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:14<00:29,  2.12it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:15<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:15<00:28,  2.12it/s]Progress: 83.00%
---- avg training fps: 7.05# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:16<00:28,  2.12it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:16<00:27,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:16<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:17<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:17<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:18<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:18<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.08# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:18<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:19<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:19<00:23,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:20<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:20<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:20<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:25<01:23,  1.73s/it]Progress: 87.00%
---- avg training fps: 6.90# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:26<01:03,  1.35s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:26<00:49,  1.08s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:26<00:40,  1.11it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:27<00:33,  1.30it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:27<00:29,  1.48it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:28<00:25,  1.64it/s]Progress: 89.00%
---- avg training fps: 6.94# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:28<00:23,  1.76it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:29<00:20,  1.93it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:30<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:30<00:18,  2.04it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:31<00:17,  2.06it/s]Progress: 91.00%
---- avg training fps: 6.97# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:31<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:32<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:32<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:32<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:33<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:33<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 6.99# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:34<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:34<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:34<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:35<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:35<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:36<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:36<00:11,  2.13it/s]Progress: 95.00%
---- avg training fps: 7.02# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:37<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:37<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:38<00:09,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:38<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:39<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:39<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:39<00:08,  2.13it/s]Progress: 97.00%
---- avg training fps: 7.05# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:40<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:40<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:40<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:41<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:41<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:42<00:05,  2.12it/s]Progress: 99.00%
---- avg training fps: 7.07# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:42<00:05,  2.14it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:43<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:43<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:43<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:44<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:44<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:45<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.10# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:45<00:02,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:46<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:46<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:47<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:47<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:48<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.12Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.80it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.51it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.40it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.35it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.40it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.30it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.27it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.26it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.25it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.24it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.23it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.23it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.23it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.22it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.22it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.22it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.22it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.22it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.22it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:08<00:00,  1.21it/s]
------------------------------------------
Training done :)
2024-08-13 03:52:35.226685: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:52:35.317511: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:52:35.317542: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:52:35.336012: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:52:35.735174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:52:35.735254: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:52:35.735263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23128 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_03-52-37-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723513957.53574 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 26320.84it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.35it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.59it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.83it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_03-52-37-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 62230.03it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.59it/s] 20%|██        | 2/10 [00:00<00:02,  3.42it/s] 30%|███       | 3/10 [00:00<00:01,  4.08it/s] 40%|████      | 4/10 [00:01<00:01,  4.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.49it/s] 60%|██████    | 6/10 [00:01<00:00,  4.67it/s] 70%|███████   | 7/10 [00:01<00:00,  4.65it/s] 80%|████████  | 8/10 [00:01<00:00,  4.78it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.77it/s]100%|██████████| 10/10 [00:02<00:00,  4.92it/s]100%|██████████| 10/10 [00:02<00:00,  4.48it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and minimalist dreamscapes

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
GPT-4 returned the wrong number of prompts 8 instead of 10, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Dreamy, surreal landscape with vivid colors.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak stands in front of a building.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a camel in front of a mountain.
- In the style of TOK, a man stands on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walks through an archway.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a dog on a leash.
- In the style of TOK, a person walks on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Dreamy, surreal landscape with vivid colors.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 9739.47it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person stands ...
3     in the style of <s0><s1><s2>, a person walks i...
4     in the style of <s0><s1><s2>, a man stands on ...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person stands ...
8     in the style of <s0><s1><s2>, a person walks i...
9     in the style of <s0><s1><s2>, a person walks o...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person stands ...
13    in the style of <s0><s1><s2>, a person walks i...
14    in the style of <s0><s1><s2>, a man stands on ...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person stands ...
18    in the style of <s0><s1><s2>, a person walks i...
19    in the style of <s0><s1><s2>, a person walks o...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person stands ...
23    in the style of <s0><s1><s2>, a person walks i...
24    in the style of <s0><s1><s2>, a man stands on ...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person stands ...
28    in the style of <s0><s1><s2>, a person walks i...
29    in the style of <s0><s1><s2>, a person walks o...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person stands ...
33    in the style of <s0><s1><s2>, a person walks i...
34    in the style of <s0><s1><s2>, a man stands on ...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person stands ...
38    in the style of <s0><s1><s2>, a person walks i...
39    in the style of <s0><s1><s2>, a person walks o...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:33,  3.12s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<20:21,  4.10s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:04,  2.44s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:10,  1.66s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:01,  1.22s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:43,  1.04it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.35# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:54,  1.25it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:21,  1.45it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:00,  1.61it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:45,  1.75it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:12<02:45,  1.75it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:12<02:35,  1.85it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:29,  1.93it/s]Progress: 7.00%
---- avg training fps: 3.64# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:41,  1.78it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.88it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:14<02:25,  1.95it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:21,  2.01it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:15<02:17,  2.05it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:15,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.51# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:10,  2.13it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:09,  2.13it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:09,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.11# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:09,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:20<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:07,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:21<02:07,  2.13it/s]Progress: 13.00%
---- avg training fps: 5.55# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:07,  2.13it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:05,  2.14it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:22<02:05,  2.13it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:04,  2.14it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:23<02:05,  2.13it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:04,  2.13it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:03,  2.13it/s]Progress: 15.00%
---- avg training fps: 5.90# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:03,  2.14it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:26<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:26<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:59,  2.16it/s]Progress: 17.00%
---- avg training fps: 6.18# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:27<01:59,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:59,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:28<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:29<01:57,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:57,  2.15it/s]Progress: 19.00%
---- avg training fps: 6.40# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:35<06:36,  1.60s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:10,  1.26s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:36<04:10,  1.02s/it]Progress: 21.00%
---- avg training fps: 5.91# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:28,  1.17it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:37<02:59,  1.36it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:39,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:25,  1.66it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.78it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.10# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:03,  1.94it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:40<01:56,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:54,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:41<01:52,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:51,  2.10it/s]Progress: 25.00%
---- avg training fps: 6.26# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:42<01:50,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:43<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:44<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:44<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:47,  2.13it/s]Progress: 27.00%
---- avg training fps: 6.40# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.53# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:49<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:50<01:40,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.64# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:51<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:52<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:38,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:37,  2.15it/s]Progress: 33.00%
---- avg training fps: 6.74# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:55<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:36,  2.12it/s]Progress: 35.00%
---- avg training fps: 6.83# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:56<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:57<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:58<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:58<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:58<01:33,  2.13it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 6.91# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:59<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<01:32,  2.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:00<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:00<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:01<01:30,  2.12it/s]Progress: 39.00%
---- avg training fps: 6.98# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:01<01:30,  2.11it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:02<01:29,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:02<01:29,  2.13it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:02<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:03<01:28,  2.12it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:03<01:28,  2.11it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:04<01:27,  2.11it/s]Progress: 41.00%
---- avg training fps: 7.04# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:27,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:27,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:06<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 7.10# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:07<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:07<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:08<01:23,  2.13it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:08<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:09<01:22,  2.11it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:09<01:22,  2.11it/s]Progress: 45.00%
---- avg training fps: 7.16# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:10<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:11<01:20,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:19,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:19,  2.11it/s]Progress: 47.00%
---- avg training fps: 7.21# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:19,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:13<01:18,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:18,  2.10it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:14<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:15<01:16,  2.11it/s]Progress: 49.00%
---- avg training fps: 7.26# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:16<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:16<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:17<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:17<01:15,  2.10it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:17<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:18<01:13,  2.11it/s]Progress: 51.00%
---- avg training fps: 7.30# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:18<01:13,  2.10it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:19<01:13,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:19<01:12,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:12,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:20<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:11,  2.11it/s]Progress: 53.00%
---- avg training fps: 7.34# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:11,  2.11it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:10,  2.10it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:26<04:18,  1.74s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<03:20,  1.36s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:27<02:39,  1.10s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<02:11,  1.10it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:28<01:51,  1.29it/s]Progress: 55.00%
---- avg training fps: 7.02# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:28<01:37,  1.46it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:29<01:27,  1.62it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:29<01:20,  1.74it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:30<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:30<01:15,  1.85it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:30<01:12,  1.92it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:31<01:09,  1.98it/s]Progress: 57.00%
---- avg training fps: 7.07# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:31<01:07,  2.02it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:32<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:32<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:33<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:33<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:34<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.11# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:34<01:02,  2.10it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:34<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:35<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:35<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:35<01:00,  2.11it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:36<00:59,  2.12it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:36<00:59,  2.11it/s]Progress: 61.00%
---- avg training fps: 7.15# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:37<00:59,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:37<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:38<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:38<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:39<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:39<00:56,  2.12it/s]Progress: 63.00%
---- avg training fps: 7.19# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:40<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:40<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:40<00:55,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:41<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:41<00:54,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:42<00:54,  2.11it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:42<00:53,  2.12it/s]Progress: 65.00%
---- avg training fps: 7.22# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:42<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:43<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:43<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:44<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:44<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:44<00:51,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:45<00:51,  2.11it/s]Progress: 67.00%
---- avg training fps: 7.26# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:45<00:50,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:46<00:50,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:46<00:49,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:47<00:49,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:47<00:48,  2.11it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:48<00:48,  2.10it/s]Progress: 69.00%
---- avg training fps: 7.29# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:48<00:47,  2.11it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:49<00:47,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:49<00:46,  2.11it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:54<02:54,  1.78s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:54<02:14,  1.39s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:55<01:46,  1.11s/it]Progress: 71.00%
---- avg training fps: 7.04# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:55<01:27,  1.09it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:56<01:13,  1.28it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:56<01:03,  1.45it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:57<00:57,  1.61it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:57<00:52,  1.73it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:58<00:48,  1.84it/s]Progress: 73.00%
---- avg training fps: 7.08# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:58<00:48,  1.84it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:58<00:46,  1.91it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:59<00:44,  1.96it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:59<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:00<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:00<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:01<00:40,  2.08it/s]Progress: 75.00%
---- avg training fps: 7.11# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:01<00:39,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:01<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:02<00:38,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:02<00:37,  2.11it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:03<00:37,  2.11it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:03<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:03<00:36,  2.11it/s]Progress: 77.00%
---- avg training fps: 7.14# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:04<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:04<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:05<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:05<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:06<00:34,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:06<00:33,  2.12it/s]Progress: 79.00%
---- avg training fps: 7.17# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:07<00:33,  2.12it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:07<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:08<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:08<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:08<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:09<00:31,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:09<00:31,  2.11it/s]Progress: 81.00%
---- avg training fps: 7.20# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:10<00:30,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:10<00:30,  2.12it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:10<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:11<00:29,  2.12it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:11<00:28,  2.12it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:12<00:28,  2.12it/s]Progress: 83.00%
---- avg training fps: 7.23# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:12<00:28,  2.12it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:12<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:13<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:13<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:14<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:14<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:15<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.25# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:15<00:25,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:16<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:16<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:17<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:18<00:22,  2.12it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.28# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:18<00:22,  2.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:18<00:21,  2.13it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:19<00:21,  2.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:19<00:20,  2.12it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:20<00:20,  2.12it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:20<00:19,  2.12it/s]Progress: 89.00%
---- avg training fps: 7.30# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:21<00:19,  2.12it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:21<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:22<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:22<00:18,  2.12it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:22<00:17,  2.12it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:23<00:17,  2.11it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:23<00:16,  2.13it/s]Progress: 91.00%
---- avg training fps: 7.33# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:24<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:24<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:25<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:25<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:26<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:26<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.35# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:26<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:26<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:27<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:27<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:28<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:28<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:29<00:11,  2.13it/s]Progress: 95.00%
---- avg training fps: 7.37# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:29<00:10,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:30<00:10,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:30<00:09,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:31<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:31<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:31<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:32<00:08,  2.12it/s]Progress: 97.00%
---- avg training fps: 7.39# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:32<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:33<00:08,  1.88it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:33<00:07,  1.94it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:34<00:07,  1.99it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:34<00:06,  2.03it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:35<00:05,  2.06it/s]Progress: 99.00%
---- avg training fps: 7.40# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:35<00:05,  2.08it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:36<00:04,  2.10it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:36<00:04,  2.10it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:36<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:37<00:03,  2.12it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:37<00:03,  2.12it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:37<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.42# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:38<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:38<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:39<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:39<00:00,  2.14it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:40<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:40<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.44Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.96it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.54it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.36it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.32it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.30it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.25it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.25it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.25it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.25it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.28it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.27it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.26it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.26it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.25it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.25it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.25it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.25it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.25it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.25it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.25it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.25it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.25it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.29it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.40it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.26it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.25it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.23it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.24it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.23it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.28it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.23it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.23it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.24it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.24it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.24it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.24it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.24it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.78it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.51it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.41it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.34it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.31it/s][A
 23%|██▎       | 7/30 [00:02<00:07,  3.29it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.27it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.26it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.25it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.25it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.24it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.24it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.24it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.24it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.24it/s][A
 57%|█████▋    | 17/30 [00:05<00:04,  3.24it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.24it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.24it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s][A
 77%|███████▋  | 23/30 [00:07<00:02,  3.23it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.24it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.23it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.23it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.23it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.23it/s][A100%|██████████| 30/30 [00:09<00:00,  3.27it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:01<00:00,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 03:57:05.831434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 03:57:05.922806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 03:57:05.922834: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 03:57:05.942170: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 03:57:06.346188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:57:06.346267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 03:57:06.346276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23112 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.5 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_03-57-08-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723514228.109371 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 55705.60it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 15.41it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.40it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.79it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.06it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_03-57-08-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_03-57-08-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 308572.77it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1665385.41it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and foolishness.
- In the style of TOK, two characters express a desire to quit their boring corporation job together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam as envisioned by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted in M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
--------------------------
GPT-4 returned the wrong number of prompts 26 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing, singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted, reminiscent of M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show is held with elephant seals as the runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is displayed.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peek above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge, with a nod to C. G. Jung's "Liber Novus."
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is visually represented.
- In the style of TOK, a blockchain composed of bees is shown.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are shown pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is visually represented.
- In the style of TOK, two individuals are depicted quitting their boring corporation job together.
- In the style of TOK, petroglyphs are portrayed.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually expressed.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing, singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted, reminiscent of M. C. Escher's style.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show is held with elephant seals as the runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is displayed.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peek above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15387.76it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two individuals ...
12    in the style of <s0><s1><s2>, petroglyphs are ...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, trypophobia is v...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is show...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show i...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain com...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are shown p...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two individuals ...
39    in the style of <s0><s1><s2>, petroglyphs are ...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:45,  2.96s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:53,  4.41s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:52,  2.60s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:37,  1.75s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:17,  1.28s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:52,  1.01it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.26# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:58,  1.23it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:23,  1.43it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:00,  1.61it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.76it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:33,  1.88it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:25,  1.98it/s]Progress: 7.00%
---- avg training fps: 3.61# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:20,  2.05it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:21,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:16,  2.07it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:13,  2.12it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:10,  2.15it/s]Progress: 9.00%
---- avg training fps: 4.48# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:09,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:08,  2.19it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:06,  2.21it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:05,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:04,  2.22it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:03,  2.23it/s]Progress: 11.00%
---- avg training fps: 5.12# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:03,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:03,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:02,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:02,  2.23it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:02,  2.23it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:57,  2.32it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:57,  2.29it/s]Progress: 13.00%
---- avg training fps: 5.61# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<01:58,  2.27it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:58,  2.26it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<01:58,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<01:58,  2.24it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<01:58,  2.24it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:57,  2.24it/s]Progress: 15.00%
---- avg training fps: 5.98# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:57,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<01:57,  2.22it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:56,  2.22it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:56,  2.22it/s]Progress: 17.00%
---- avg training fps: 6.28# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:26<01:56,  2.22it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:26<01:51,  2.31it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:52,  2.28it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:52,  2.26it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:53,  2.24it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:53,  2.22it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:53,  2.23it/s]Progress: 19.00%
---- avg training fps: 6.52# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:53,  2.21it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:53,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:53,  2.20it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:59,  1.45s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:43,  1.15s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:51,  1.06it/s]Progress: 21.00%
---- avg training fps: 6.09# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:14,  1.26it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:35<02:48,  1.45it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:48,  1.45it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:26,  1.66it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:14,  1.80it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:07,  1.90it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:01,  1.97it/s]Progress: 23.00%
---- avg training fps: 6.29# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:57,  2.04it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:54,  2.08it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:52,  2.11it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:50,  2.13it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:39<01:49,  2.15it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:47,  2.17it/s]Progress: 25.00%
---- avg training fps: 6.45# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:40<01:47,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:46,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:46,  2.16it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:46,  2.17it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:46,  2.17it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:40,  2.27it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:41,  2.24it/s]Progress: 27.00%
---- avg training fps: 6.61# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<01:42,  2.22it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:42,  2.21it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:42,  2.20it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:44<01:42,  2.19it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:45<01:41,  2.18it/s]Progress: 29.00%
---- avg training fps: 6.73# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:41,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:46<01:41,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:47<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:39,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:48<01:39,  2.18it/s]Progress: 31.00%
---- avg training fps: 6.85# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:39,  2.18it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:34,  2.28it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:49<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:49<01:35,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:35,  2.22it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:50<01:35,  2.21it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:35,  2.20it/s]Progress: 33.00%
---- avg training fps: 6.95# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:51<01:35,  2.20it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:35,  2.18it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:52<01:34,  2.19it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:34,  2.19it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:53<01:33,  2.18it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.04# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:54<01:33,  2.18it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:32,  2.18it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:32,  2.18it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:28,  2.28it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:55<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:29,  2.22it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:56,  1.20s/it]Progress: 37.00%
---- avg training fps: 6.83# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<03:11,  1.03it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:40,  1.22it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:18,  1.40it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<02:03,  1.57it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:52,  1.71it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:44,  1.83it/s]Progress: 39.00%
---- avg training fps: 6.92# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:39,  1.92it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:02<01:35,  1.99it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:32,  2.04it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:03<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:25,  2.20it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:04<01:24,  2.19it/s]Progress: 41.00%
---- avg training fps: 7.00# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:24,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:05<01:24,  2.19it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:23,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:06<01:23,  2.18it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:23,  2.18it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:07<01:22,  2.19it/s]Progress: 43.00%
---- avg training fps: 7.07# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:07<01:22,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:21,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:08<01:21,  2.18it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:09<01:20,  2.18it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:10<01:33,  1.88it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:28,  1.96it/s]Progress: 45.00%
---- avg training fps: 7.11# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:10<01:28,  1.96it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:10<01:22,  2.11it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:20,  2.13it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:11<01:19,  2.16it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:18,  2.16it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:12<01:17,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.18it/s]Progress: 47.00%
---- avg training fps: 7.18# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:13<01:16,  2.18it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:15,  2.20it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:14<01:15,  2.19it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:14<01:15,  2.19it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:15<01:14,  2.19it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:15<01:13,  2.19it/s]Progress: 49.00%
---- avg training fps: 7.23# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:13,  2.19it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:16<01:13,  2.19it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:13,  2.19it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:09,  2.29it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:17<01:09,  2.26it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:10,  2.23it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:18<01:10,  2.22it/s]Progress: 51.00%
---- avg training fps: 7.29# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:10,  2.20it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:19<01:09,  2.20it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:19<01:09,  2.19it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:20<01:08,  2.20it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:20<01:08,  2.20it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:08,  2.19it/s]Progress: 53.00%
---- avg training fps: 7.34# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:21<01:08,  2.19it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:26<04:20,  1.76s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:27<03:21,  1.37s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:27<02:39,  1.09s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:27<02:39,  1.09s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:27<02:08,  1.13it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:28<01:48,  1.32it/s]Progress: 55.00%
---- avg training fps: 7.03# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:28<01:35,  1.50it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:29<01:25,  1.66it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:29<01:18,  1.79it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:30<01:13,  1.90it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:30<01:10,  1.97it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:31<01:07,  2.03it/s]Progress: 57.00%
---- avg training fps: 7.08# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:31<01:06,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:31<01:04,  2.11it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:32<01:03,  2.13it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:32<01:02,  2.15it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:33<01:01,  2.16it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:33<01:00,  2.17it/s]Progress: 59.00%
---- avg training fps: 7.14# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:34<01:00,  2.17it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:34<00:57,  2.27it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:34<00:57,  2.25it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:35<00:57,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:35<00:57,  2.21it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:36<00:57,  2.20it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:36<00:57,  2.20it/s]Progress: 61.00%
---- avg training fps: 7.18# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:36<00:56,  2.20it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:37<00:56,  2.20it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:37<00:55,  2.20it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:38<00:55,  2.20it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:38<00:55,  2.19it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:39<00:54,  2.19it/s]Progress: 63.00%
---- avg training fps: 7.22# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:39<00:54,  2.19it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:40<00:53,  2.19it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:40<00:53,  2.19it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:40<00:51,  2.29it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:40<00:51,  2.26it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:41<00:51,  2.23it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:41<00:51,  2.23it/s]Progress: 65.00%
---- avg training fps: 7.27# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:42<00:50,  2.22it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:42<00:50,  2.21it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:43<00:50,  2.20it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:43<00:50,  2.19it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:44<00:49,  2.19it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:44<00:49,  2.19it/s]Progress: 67.00%
---- avg training fps: 7.31# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:45<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:45<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:46<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:46<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:46<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:46<00:45,  2.27it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:47<00:45,  2.25it/s]Progress: 69.00%
---- avg training fps: 7.35# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:47<00:45,  2.22it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:48<00:45,  2.22it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:48<00:44,  2.21it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:51<01:54,  1.17s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:51<01:32,  1.05it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:52<01:17,  1.24it/s]Progress: 71.00%
---- avg training fps: 7.23# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:52<01:06,  1.42it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:53<00:58,  1.60it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:53<00:53,  1.73it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:54<00:57,  1.60it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:55<00:52,  1.74it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:55<00:48,  1.85it/s]Progress: 73.00%
---- avg training fps: 7.25# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:55<00:48,  1.85it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:55<00:44,  2.02it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:56<00:42,  2.07it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:56<00:41,  2.11it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:57<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:57<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:58<00:38,  2.16it/s]Progress: 75.00%
---- avg training fps: 7.29# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:58<00:38,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:59<00:37,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:59<00:36,  2.19it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:59<00:36,  2.19it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:00<00:36,  2.19it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:00<00:35,  2.18it/s]Progress: 77.00%
---- avg training fps: 7.32# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:01<00:35,  2.19it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:01<00:34,  2.19it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:02<00:34,  2.19it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:02<00:32,  2.29it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:02<00:32,  2.26it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:03<00:32,  2.24it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:03<00:32,  2.22it/s]Progress: 79.00%
---- avg training fps: 7.36# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:03<00:31,  2.22it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:04<00:31,  2.22it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:04<00:31,  2.20it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:05<00:30,  2.20it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:05<00:30,  2.20it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:06<00:29,  2.20it/s]Progress: 81.00%
---- avg training fps: 7.39# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:06<00:29,  2.19it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:07<00:29,  2.19it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:07<00:28,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:08<00:28,  2.19it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:08<00:28,  2.19it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:08<00:26,  2.30it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:08<00:26,  2.26it/s]Progress: 83.00%
---- avg training fps: 7.42# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:09<00:26,  2.24it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:09<00:26,  2.22it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:10<00:25,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:10<00:25,  2.20it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:11<00:25,  2.20it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:11<00:24,  2.19it/s]Progress: 85.00%
---- avg training fps: 7.45# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:12<00:24,  2.19it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:12<00:23,  2.19it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:13<00:23,  2.19it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:13<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:13<00:22,  2.18it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:17<01:08,  1.43s/it]Progress: 87.00%
---- avg training fps: 7.30# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:18<01:08,  1.43s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:18<00:52,  1.12s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:18<00:42,  1.09it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:18<00:35,  1.28it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:19<00:29,  1.47it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:19<00:26,  1.63it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:20<00:23,  1.77it/s]Progress: 89.00%
---- avg training fps: 7.33# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:20<00:21,  1.88it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:21<00:20,  1.96it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:21<00:19,  2.02it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:22<00:18,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:22<00:17,  2.11it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:23<00:16,  2.13it/s]Progress: 91.00%
---- avg training fps: 7.36# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:23<00:16,  2.15it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:23<00:15,  2.16it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:24<00:15,  2.16it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:24<00:14,  2.27it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:24<00:14,  2.24it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:25<00:13,  2.23it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:25<00:13,  2.21it/s]Progress: 93.00%
---- avg training fps: 7.39# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:26<00:13,  2.20it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:26<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:27<00:12,  2.20it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:27<00:11,  2.20it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:28<00:11,  2.19it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:28<00:11,  2.18it/s]Progress: 95.00%
---- avg training fps: 7.41# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:28<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:29<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:29<00:09,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:30<00:09,  2.18it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:30<00:09,  2.18it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:30<00:08,  2.27it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:31<00:08,  2.24it/s]Progress: 97.00%
---- avg training fps: 7.44# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:31<00:07,  2.23it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:32<00:07,  2.22it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:32<00:06,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:33<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:33<00:05,  2.20it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:33<00:05,  2.19it/s]Progress: 99.00%
---- avg training fps: 7.46# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:34<00:05,  2.18it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:34<00:04,  2.18it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:35<00:04,  2.19it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:35<00:03,  2.18it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:36<00:03,  2.18it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:36<00:02,  2.17it/s]Progress: 100.00%
---- avg training fps: 7.49# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:37<00:02,  2.17it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:37<00:02,  2.28it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:37<00:01,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:38<00:01,  2.22it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:38<00:00,  2.20it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:38<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:39<00:00,  2.18it/s]Progress: 100.00%
---- avg training fps: 7.51# Trainer step: 294, epoch: 21: : 301it [02:39,  2.19it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  4.05it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.51it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.49it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.47it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.46it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.44it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.43it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.42it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.42it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.42it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.41it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.40it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.39it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.38it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.38it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.43it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:03,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 04:02:15.566913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:02:15.657881: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:02:15.657908: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:02:15.676422: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:02:16.086960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:02:16.087022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:02:16.087031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23132 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_04-02-17-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723514537.871367 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 4379.53it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 18.33it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.73it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.80it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_04-02-17-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_04-02-17-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 512426.28it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1179648.00it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene depicts Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" evokes mixed emotions and contrasting scenarios.
- In the style of TOK, bees form a blockchain.
- In the style of TOK, a gorgon made out of sharks swims underwater as they eat each other.
- In the style of TOK, a hillside shows Venus and Earth circling the sun at sunset.
- In the style of TOK, an ancient temple is depicted deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat stands out.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness" portrays contrasting eras.
- In the style of TOK, a suggestion is made to quit the boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space are exchanged based on first and second-degree connections.
- In the style of TOK, the condition of trypophobia is displayed.
- In the style of TOK, a 6-pack of nightmare fuel is presented.
- In the style of TOK, a band of dancing, singing beavers performs.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dance in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing, singing beavers is featured.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is shown.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid swimming underwater, made from sea trash.
- In the style of TOK, Lilliputians cramped inside giant sea-sponge pores.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, a reflection on the best and worst times.
- In the style of TOK, a blockchain formed by bees.
- In the style of TOK, a gorgon of sharks eating each other underwater.
- In the style of TOK, Venus and Earth circling the sun at sunset on a hillside.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, a reflection on the age of wisdom and foolishness.
- In the style of TOK, quitting a boring corporation job together.
- In the style of TOK, petroglyphs.
- In the style of TOK, room and space exchange based on degrees of connection.
- In the style of TOK, trypophobia triggers.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, beavers quickly building a dam.
- In the style of TOK, a brigade of beavers building a dam.
- In the style of TOK, a brigade of beavers.
- In the style of TOK, a moving castle on grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing.
- In the style of TOK, a frozen 1950s restaurant kitchen, preserved and rediscovered in the space age.
- In the style of TOK, an elephant seal fashion show with egrets in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made from fishnets, dead fish, and packing peanuts, swimming up to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from waste materials swims underwater in the ocean.
- In the style of TOK, a throng of tiny Lilliputians are packed inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is set in Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "best of times, worst of times" is illustrated.
- In the style of TOK, a blockchain made of bees.
- In the style of TOK, a gorgon composed of sharks swimming and consuming each other underwater.
- In the style of TOK, Venus and Earth circle the sun over a hillside at sunset.
- In the style of TOK, an ancient temple is hidden deep in the Amazon jungle.
- In the style of TOK, cats are depicted defecating in zero-gravity.
- In the style of TOK, an image of a goblin goat.
- In the style of TOK, the phrase "age of wisdom, age of foolishness" is illustrated.
- In the style of TOK, two people decide to quit their unfulfilling corporate jobs together.
- In the style of TOK, a set of ancient petroglyphs.
- In the style of TOK, a system for room and space exchange based on social connections.
- In the style of TOK, an image that induces trypophobia.
- In the style of TOK, a collection of six terrifying objects.
- In the style of TOK, a band of beavers sing and dance like Jim Henson's Muppets.
- In the style of TOK, a beaver gnaws a rifle in half.
- In the style of TOK, a brigade of beavers quickly constructs a dam, inspired by Hawaiian-shirt patterns.
- In the style of TOK, a brigade of beavers builds a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers inspired by M. C. Escher’s art.
- In the style of TOK, a castle moves along grassy hills.
- In the style of TOK, a chorus line of beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is preserved and discovered in the space age.
- In the style of TOK, a fashion show with elephant seals on the runway and egrets in the audience.
- In the style of TOK, a hyper-realistic painting shows lemon-lime colored architecture.
- In the style of TOK, a mermaid made of waste materials swims up to the surface of the sea.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 4...
----- GPT response: -----
Style Description: Surreal and fantastical imagery

- In the style of TOK, a mermaid constructed from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, a scenic view of Fort Kochi, Kerala, India.
- In the style of TOK, a depiction of the phrase "the best of times, the worst of times."
- In the style of TOK, a blockchain made up of bees.
- In the style of TOK, a gorgon composed of sharks eating each other, swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, a depiction of the phrase "the age of wisdom, the age of foolishness."
- In the style of TOK, the concept of quitting a boring corporate job together.
- In the style of TOK, various petroglyphs.
- In the style of TOK, an idea of room and space exchange based on first and second-degree connections.
- In the style of TOK, something that triggers trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly constructing a dam, resembling a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers quickly constructing a dam as portrayed by Tarsem Singh.
- In the style of TOK, a brigade of beavers in the style of M. C. Escher.
- In the style of TOK, a castle moving across grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and rediscovered in the space age.
- In the style of TOK, a fashion show featuring elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid constructed from fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
WARNING: no captioning text was given and we're not doing chatgpt cleanup...
Concept mode:  style
Using GPT concept name as CLIP-segmentation prompt: Surreal and fantastical imagery
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15202.87it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, they were the be...
4     in the style of <s0><s1><s2>, a blockchain of ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats pooping in ...
9             in the style of <s0><s1><s2>, goblin goat
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, let's quit our b...
12            in the style of <s0><s1><s2>, petroglyphs
13    in the style of <s0><s1><s2>, room and space e...
14            in the style of <s0><s1><s2>, trypophobia
15    in the style of <s0><s1><s2>, a 6-pack of nigh...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle that is...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi, kera...
30    in the style of <s0><s1><s2>, they were the be...
31    in the style of <s0><s1><s2>, a blockchain of ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats pooping in ...
36            in the style of <s0><s1><s2>, goblin goat
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, let's quit our b...
39            in the style of <s0><s1><s2>, petroglyphs
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<14:59,  3.01s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<22:06,  4.45s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:59,  2.63s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:42,  1.77s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:20,  1.29s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:56,  1.01s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.24# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:02,  1.21it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:26,  1.42it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:02,  1.59it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:46,  1.74it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:34,  1.87it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:27,  1.96it/s]Progress: 7.00%
---- avg training fps: 3.57# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:21,  2.02it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:18,  2.07it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:18,  2.07it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:23,  1.98it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:19,  2.04it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:15,  2.09it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:13,  2.12it/s]Progress: 9.00%
---- avg training fps: 4.43# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:11,  2.14it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:10,  2.15it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:08,  2.17it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:07,  2.17it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:06,  2.19it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:06,  2.19it/s]Progress: 11.00%
---- avg training fps: 5.05# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:05,  2.20it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:05,  2.19it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:04,  2.19it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:04,  2.19it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:04,  2.19it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:58,  2.28it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<01:59,  2.26it/s]Progress: 13.00%
---- avg training fps: 5.53# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<02:00,  2.23it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:00,  2.22it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<02:00,  2.21it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:00,  2.21it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:00,  2.20it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:59,  2.21it/s]Progress: 15.00%
---- avg training fps: 5.90# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<01:59,  2.19it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:59,  2.19it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<01:58,  2.20it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<01:58,  2.20it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<01:57,  2.20it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:57,  2.20it/s]Progress: 17.00%
---- avg training fps: 6.20# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:57,  2.20it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:52,  2.29it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:53,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:53,  2.24it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:54,  2.22it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:54,  2.21it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:55,  2.18it/s]Progress: 19.00%
---- avg training fps: 6.43# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:55,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:54,  2.18it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:53,  2.19it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:23,  1.30s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:19,  1.05s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:34<03:34,  1.15it/s]Progress: 21.00%
---- avg training fps: 6.10# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:03,  1.33it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:35<02:41,  1.51it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:41,  1.51it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:21,  1.72it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:11,  1.84it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:05,  1.92it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:00,  1.99it/s]Progress: 23.00%
---- avg training fps: 6.30# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:56,  2.05it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:54,  2.08it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:52,  2.10it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:51,  2.12it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:39<01:49,  2.15it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:49,  2.14it/s]Progress: 25.00%
---- avg training fps: 6.46# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:40<01:48,  2.14it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:47,  2.15it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:47,  2.15it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:46,  2.15it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:46,  2.15it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:42,  2.24it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:42,  2.22it/s]Progress: 27.00%
---- avg training fps: 6.56# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<02:01,  1.87it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:56,  1.95it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:52,  2.01it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<01:49,  2.05it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:47,  2.08it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:46<01:45,  2.10it/s]Progress: 29.00%
---- avg training fps: 6.69# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:44,  2.12it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:47<01:42,  2.14it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:42,  2.14it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:41,  2.14it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:41,  2.14it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:48<01:41,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.80# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:41,  2.14it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:36,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:49<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:36,  2.20it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:36,  2.19it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:37,  2.18it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.17it/s]Progress: 33.00%
---- avg training fps: 6.90# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:52<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:35,  2.18it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:53<01:35,  2.18it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:54<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:34,  2.17it/s]Progress: 35.00%
---- avg training fps: 6.99# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:54<01:33,  2.16it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:29,  2.25it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:29,  2.23it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:29,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:29,  1.06s/it]Progress: 37.00%
---- avg training fps: 6.84# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<02:53,  1.14it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:27,  1.32it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:10,  1.50it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<01:57,  1.65it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:49,  1.77it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:01<01:42,  1.87it/s]Progress: 39.00%
---- avg training fps: 6.92# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:38,  1.95it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:02<01:34,  2.00it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:32,  2.04it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:03<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:26,  2.17it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:04<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 6.99# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:26,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:05<01:25,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:25,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:06<01:24,  2.14it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:24,  2.15it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:07<01:23,  2.15it/s]Progress: 43.00%
---- avg training fps: 7.06# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:07<01:23,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:08<01:22,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:09<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:09<01:21,  2.15it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.13# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:10<01:21,  2.14it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:10<01:17,  2.24it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:18,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:11<01:18,  2.19it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:18,  2.18it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:12<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.18# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:13<01:17,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:13<01:17,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:14<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:14<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:15<01:15,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:15<01:15,  2.16it/s]Progress: 49.00%
---- avg training fps: 7.23# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:14,  2.15it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:16<01:14,  2.14it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:14,  2.14it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:11,  2.23it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:17<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:12,  2.18it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:18<01:12,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.29# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:11,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:19<01:19,  1.93it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:16,  2.00it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:20<01:14,  2.04it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:12,  2.08it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:11,  2.10it/s]Progress: 53.00%
---- avg training fps: 7.32# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:10,  2.12it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:25<03:24,  1.38s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:25<02:42,  1.11s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:26<02:13,  1.09it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:26<02:13,  1.09it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:26<01:50,  1.31it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:27<01:37,  1.48it/s]Progress: 55.00%
---- avg training fps: 7.11# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:27<01:27,  1.63it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:28<01:20,  1.76it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:28<01:15,  1.86it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:29<01:12,  1.94it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:29<01:09,  2.00it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:30<01:07,  2.06it/s]Progress: 57.00%
---- avg training fps: 7.16# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:30<01:05,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:31<01:04,  2.12it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:31<01:03,  2.13it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:31<01:02,  2.15it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:32<01:01,  2.15it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:32<01:00,  2.16it/s]Progress: 59.00%
---- avg training fps: 7.21# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:33<01:00,  2.16it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:33<00:57,  2.26it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:33<00:58,  2.23it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:34<00:58,  2.22it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:34<00:58,  2.20it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:35<00:57,  2.20it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:35<00:57,  2.19it/s]Progress: 61.00%
---- avg training fps: 7.25# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:36<00:57,  2.18it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:36<00:57,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:36<00:56,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:37<00:56,  2.17it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:37<00:55,  2.18it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:38<00:55,  2.17it/s]Progress: 63.00%
---- avg training fps: 7.29# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:38<00:54,  2.17it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:39<00:54,  2.17it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:39<00:54,  2.17it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:39<00:51,  2.27it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:40<00:58,  1.99it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:40<00:56,  2.05it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:41<00:54,  2.09it/s]Progress: 65.00%
---- avg training fps: 7.32# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:41<00:53,  2.12it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:42<00:52,  2.13it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:42<00:51,  2.15it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:43<00:50,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:43<00:50,  2.17it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:43<00:49,  2.17it/s]Progress: 67.00%
---- avg training fps: 7.36# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:44<00:49,  2.17it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:44<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:45<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:45<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:46<00:47,  2.17it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:46<00:45,  2.27it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:46<00:45,  2.24it/s]Progress: 69.00%
---- avg training fps: 7.40# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:47<00:45,  2.23it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:47<00:45,  2.21it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:48<00:45,  2.20it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:50<01:39,  1.01s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:50<01:22,  1.18it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:51<01:10,  1.37it/s]Progress: 71.00%
---- avg training fps: 7.30# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:51<01:01,  1.54it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:52<00:55,  1.69it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:52<00:51,  1.82it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:53<00:48,  1.91it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:53<00:45,  1.98it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:54<00:44,  2.04it/s]Progress: 73.00%
---- avg training fps: 7.34# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:54<00:44,  2.04it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:54<00:41,  2.17it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:54<00:40,  2.17it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:55<00:39,  2.18it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:55<00:39,  2.17it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:56<00:39,  2.17it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:56<00:38,  2.17it/s]Progress: 75.00%
---- avg training fps: 7.37# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:57<00:38,  2.18it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:57<00:37,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:58<00:37,  2.16it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:58<00:37,  2.16it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:59<00:36,  2.17it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:59<00:36,  2.17it/s]Progress: 77.00%
---- avg training fps: 7.40# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [01:59<00:35,  2.16it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:00<00:35,  2.16it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:00<00:35,  2.16it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:00<00:33,  2.27it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:01<00:33,  2.24it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:01<00:32,  2.21it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:02<00:32,  2.20it/s]Progress: 79.00%
---- avg training fps: 7.44# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:02<00:32,  2.19it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:03<00:31,  2.19it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:03<00:31,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:04<00:31,  2.18it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:04<00:31,  2.15it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:04<00:30,  2.16it/s]Progress: 81.00%
---- avg training fps: 7.46# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:05<00:30,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:05<00:29,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:06<00:29,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:06<00:28,  2.16it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:07<00:28,  2.16it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:07<00:26,  2.30it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:07<00:26,  2.25it/s]Progress: 83.00%
---- avg training fps: 7.49# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:08<00:26,  2.22it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:08<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:09<00:25,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:09<00:25,  2.19it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:09<00:25,  2.18it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:10<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.52# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:10<00:24,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:11<00:24,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:11<00:23,  2.16it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:12<00:23,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:12<00:22,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:16<01:05,  1.36s/it]Progress: 87.00%
---- avg training fps: 7.38# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:16<01:05,  1.36s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:16<00:50,  1.07s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:17<00:40,  1.13it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:17<00:34,  1.32it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:17<00:29,  1.49it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:18<00:26,  1.65it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:18<00:23,  1.79it/s]Progress: 89.00%
---- avg training fps: 7.41# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:19<00:21,  1.88it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:19<00:20,  1.96it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:20<00:19,  2.02it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:20<00:18,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:21<00:17,  2.10it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:17,  2.11it/s]Progress: 91.00%
---- avg training fps: 7.43# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:22<00:16,  2.12it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:22<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:22<00:14,  2.26it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:23<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:23<00:14,  2.20it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:24<00:13,  2.19it/s]Progress: 93.00%
---- avg training fps: 7.46# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:24<00:13,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:25<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:25<00:12,  2.18it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:26<00:11,  2.18it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:26<00:11,  2.18it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:27<00:11,  2.18it/s]Progress: 95.00%
---- avg training fps: 7.48# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:28<00:10,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:28<00:09,  2.16it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:29<00:09,  2.16it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:29<00:08,  2.26it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:29<00:08,  2.23it/s]Progress: 97.00%
---- avg training fps: 7.51# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:30<00:07,  2.21it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:30<00:07,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:31<00:06,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:31<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:32<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.53# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:33<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:33<00:04,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:34<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:35<00:02,  2.17it/s]Progress: 100.00%
---- avg training fps: 7.55# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:35<00:02,  2.17it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:35<00:02,  2.27it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:36<00:01,  2.23it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:36<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:37<00:00,  2.21it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:37<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:38<00:00,  2.17it/s]Progress: 100.00%
---- avg training fps: 7.57# Trainer step: 294, epoch: 21: : 301it [02:38,  2.17it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.98it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.48it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.45it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.37it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.26it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.94it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [03:58,  1.26it/s]
------------------------------------------
Training done :)
2024-08-13 04:07:27.940317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:07:28.033783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:07:28.033809: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:07:28.052828: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:07:28.454170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:07:28.454246: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:07:28.454254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23130 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_04-07-30-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723514850.2719877 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 46391.13it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.59it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.53it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.83it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_04-07-30-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 190650.18it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.64it/s] 20%|██        | 2/10 [00:00<00:02,  3.46it/s] 30%|███       | 3/10 [00:00<00:01,  4.13it/s] 40%|████      | 4/10 [00:01<00:01,  4.34it/s] 50%|█████     | 5/10 [00:01<00:01,  4.51it/s] 60%|██████    | 6/10 [00:01<00:00,  4.71it/s] 70%|███████   | 7/10 [00:01<00:00,  4.69it/s] 80%|████████  | 8/10 [00:01<00:00,  4.71it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.74it/s]100%|██████████| 10/10 [00:02<00:00,  4.91it/s]100%|██████████| 10/10 [00:02<00:00,  4.49it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, bold compositions

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, bold compositions
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 11091.64it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:40,  2.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:36,  3.95s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:39,  2.35s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:54,  1.60s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:50,  1.19s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:36,  1.06it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.43# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:49,  1.28it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:17,  1.48it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:56,  1.65it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:32,  1.90it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:26,  1.97it/s]Progress: 7.00%
---- avg training fps: 3.75# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:38,  1.81it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:29,  1.91it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:23,  1.98it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:19,  2.04it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:16,  2.08it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:13,  2.11it/s]Progress: 9.00%
---- avg training fps: 4.63# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:11,  2.14it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:10,  2.15it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:09,  2.16it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:08,  2.16it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:07,  2.17it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:06,  2.18it/s]Progress: 11.00%
---- avg training fps: 5.25# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:06,  2.18it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:06,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:05,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:04,  2.17it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:04,  2.17it/s]Progress: 13.00%
---- avg training fps: 5.70# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:04,  2.17it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:01,  2.18it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:01,  2.18it/s]Progress: 15.00%
---- avg training fps: 6.04# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:01,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<01:59,  2.18it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.32# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:57,  2.18it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:56,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.54# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:55,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:54,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:25,  1.55s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<05:02,  1.22s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:05,  1.00it/s]Progress: 21.00%
---- avg training fps: 6.04# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:24,  1.20it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:56,  1.39it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:37,  1.55it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:23,  1.69it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:13,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]Progress: 23.00%
---- avg training fps: 6.23# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:01,  1.97it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:57,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:54,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:53,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:50,  2.12it/s]Progress: 25.00%
---- avg training fps: 6.39# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:48,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.53# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:45,  2.15it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:44,  2.15it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:44,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.15it/s]Progress: 29.00%
---- avg training fps: 6.65# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:40,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:40,  2.15it/s]Progress: 31.00%
---- avg training fps: 6.76# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:39,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:39,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 6.86# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:36,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:36,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:35,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:35,  2.16it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.16it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.95# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:33,  2.17it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:31,  2.17it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:31,  2.16it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.03# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<01:31,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:31,  2.15it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:58<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:59<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:29,  2.14it/s]Progress: 39.00%
---- avg training fps: 7.10# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:29,  2.14it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:27,  2.15it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:27,  2.15it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:27,  2.14it/s]Progress: 41.00%
---- avg training fps: 7.16# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:26,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:05<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:05<01:23,  2.15it/s]Progress: 43.00%
---- avg training fps: 7.22# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:23,  2.15it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:06<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:22,  2.15it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:07<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:21,  2.15it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:21,  2.15it/s]Progress: 45.00%
---- avg training fps: 7.28# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:20,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:19,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:11<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:11<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:11<01:18,  2.15it/s]Progress: 47.00%
---- avg training fps: 7.33# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:12<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:13<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.38# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:14<01:15,  2.14it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:15<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:15<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:16<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:12,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.42# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:19<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.46# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:09,  2.14it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<04:13,  1.71s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:25<03:16,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:25<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<02:09,  1.12it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:50,  1.31it/s]Progress: 55.00%
---- avg training fps: 7.14# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:36,  1.48it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:26,  1.63it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:20,  1.76it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 7.19# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:06,  2.06it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:31<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.23# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.27# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:37<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.31# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:38<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:38<00:54,  2.17it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:39<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:53,  2.17it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 7.34# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:52,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:42<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:51,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:43<00:50,  2.15it/s]Progress: 67.00%
---- avg training fps: 7.38# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:44<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:45<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:45<00:47,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:46<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.41# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:46,  2.16it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:45,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:48,  1.72s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:52<02:10,  1.35s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:43,  1.08s/it]Progress: 71.00%
---- avg training fps: 7.17# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:24,  1.12it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:11,  1.31it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<01:02,  1.49it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:55<00:56,  1.64it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:51,  1.78it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:47,  1.88it/s]Progress: 73.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:47,  1.88it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:41,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:58<00:40,  2.11it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:39,  2.12it/s]Progress: 75.00%
---- avg training fps: 7.24# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:37,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:01<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.27# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:35,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:02<00:35,  2.17it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:33,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:04<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.30# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:32,  2.15it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:05<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:06<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.33# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:07<00:30,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:08<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:28,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:09<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:10<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:10<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:11<00:26,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:12<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:12<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.38# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:13<00:24,  2.15it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:23,  2.15it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:14<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:22,  2.15it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:15<00:22,  2.15it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.40# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:16<00:21,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:16<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:17<00:21,  2.13it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:17<00:20,  2.13it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:18<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:18<00:19,  2.14it/s]Progress: 89.00%
---- avg training fps: 7.43# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:18<00:19,  2.14it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:19<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:19<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:19<00:18,  2.16it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:20<00:17,  2.16it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:20<00:17,  2.15it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:21<00:16,  2.15it/s]Progress: 91.00%
---- avg training fps: 7.45# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:21<00:16,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:22<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:22<00:15,  2.15it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:23<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:23<00:14,  2.15it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:24<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.47# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:24<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:24<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:24<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:25<00:12,  2.16it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:25<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:26<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:26<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.50# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:27<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:27<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:28<00:09,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:28<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:29<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:29<00:08,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:29<00:08,  2.14it/s]Progress: 97.00%
---- avg training fps: 7.52# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:30<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:30<00:08,  1.90it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:31<00:07,  1.97it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:31<00:06,  2.02it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:32<00:06,  2.07it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:32<00:05,  2.09it/s]Progress: 99.00%
---- avg training fps: 7.53# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:33<00:05,  2.10it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:33<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:34<00:04,  2.12it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:34<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:34<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:34<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:35<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.55# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:35<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:36<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:36<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:37<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:37<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:38<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.56Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:57<00:00,  1.26it/s]
------------------------------------------
Training done :)
2024-08-13 04:11:57.346856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:11:57.439928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:11:57.439954: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:11:57.458681: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:11:57.861335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:11:57.861418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:11:57.861427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23106 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_04-11-59-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723515119.6881795 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 18189.58it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 12.51it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.09it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.78it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.99it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_04-11-59-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 83886.08it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.62it/s] 20%|██        | 2/10 [00:00<00:02,  3.49it/s] 30%|███       | 3/10 [00:00<00:01,  4.18it/s] 40%|████      | 4/10 [00:00<00:01,  4.40it/s] 50%|█████     | 5/10 [00:01<00:01,  4.43it/s] 60%|██████    | 6/10 [00:01<00:00,  4.68it/s] 70%|███████   | 7/10 [00:01<00:00,  4.70it/s] 80%|████████  | 8/10 [00:01<00:00,  4.86it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.87it/s]100%|██████████| 10/10 [00:02<00:00,  5.04it/s]100%|██████████| 10/10 [00:02<00:00,  4.55it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike landscapes.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress is walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike landscapes.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 11180.34it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:13,  3.06s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<20:03,  4.04s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:53,  2.40s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:04,  1.64s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:57,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:40,  1.05it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.38# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:52,  1.26it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:19,  1.46it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:44,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:33,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 3.68# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:40,  1.79it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:30,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:24,  1.97it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.03it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:16,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.56# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:12,  2.12it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:08,  2.15it/s]Progress: 11.00%
---- avg training fps: 5.17# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.15it/s]Progress: 13.00%
---- avg training fps: 5.62# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:04,  2.14it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 5.96# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:01,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:01,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:00,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:00,  2.16it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:00,  2.16it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:59,  2.15it/s]Progress: 17.00%
---- avg training fps: 6.24# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:57,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:57,  2.15it/s]Progress: 19.00%
---- avg training fps: 6.46# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:56,  2.15it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:34,  1.59s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:09,  1.25s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:09,  1.02s/it]Progress: 21.00%
---- avg training fps: 5.96# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:27,  1.18it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:59,  1.36it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:39,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:24,  1.67it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:14,  1.79it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:07,  1.88it/s]Progress: 23.00%
---- avg training fps: 6.14# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:07,  1.88it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:02,  1.94it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:55,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:53,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:50,  2.11it/s]Progress: 25.00%
---- avg training fps: 6.31# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:46,  2.13it/s]Progress: 27.00%
---- avg training fps: 6.45# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.57# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:40,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.68# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 6.78# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:36,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.87# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:58<01:32,  2.15it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 6.95# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<01:31,  2.15it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:59<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:59<01:31,  2.14it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:00<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:00<01:30,  2.14it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:01<01:29,  2.15it/s]Progress: 39.00%
---- avg training fps: 7.03# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:01<01:29,  2.14it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:02<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:02<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:03<01:27,  2.14it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:27,  2.14it/s]Progress: 41.00%
---- avg training fps: 7.09# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:04<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:26,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:05<01:25,  2.14it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:05<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:06<01:24,  2.14it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:06<01:24,  2.14it/s]Progress: 43.00%
---- avg training fps: 7.15# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:07<01:24,  2.14it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:07<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:07<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:08<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:08<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:21,  2.13it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:09<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 7.21# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:10<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:19,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:11<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:11<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:11<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:12<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.26# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:18,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:13<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:13<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:14<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:14<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:15<01:15,  2.13it/s]Progress: 49.00%
---- avg training fps: 7.31# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:15,  2.13it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:16<01:14,  2.14it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:17<01:13,  2.15it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:12,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.35# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:18<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:19<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:20<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:20<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.39# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:21<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:21<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:25<04:14,  1.72s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<03:17,  1.34s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:26<02:37,  1.08s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<02:09,  1.12it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:27<01:49,  1.31it/s]Progress: 55.00%
---- avg training fps: 7.08# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:28<01:36,  1.49it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:28<01:26,  1.64it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:29<01:19,  1.77it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:29<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:11,  1.95it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:30<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.13# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:30<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:31<01:05,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:31<01:04,  2.11it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:32<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:32<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:33<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.18# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:33<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:34<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:34<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:34<01:00,  2.14it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:35<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:35<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:58,  2.14it/s]Progress: 61.00%
---- avg training fps: 7.22# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:36<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:37<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:38<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:55,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.25# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:39<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:39<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:39<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:40<00:54,  2.15it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:41<00:53,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:41<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.29# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:42<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:42<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.32# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:45<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:46<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:46<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:47<00:47,  2.13it/s]Progress: 69.00%
---- avg training fps: 7.36# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:47<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:53<02:52,  1.76s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:53<02:13,  1.37s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:54<01:45,  1.10s/it]Progress: 71.00%
---- avg training fps: 7.11# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:54<01:26,  1.10it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:55<01:13,  1.29it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:55<01:03,  1.46it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:56<00:56,  1.62it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:56<00:51,  1.75it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:57<00:48,  1.86it/s]Progress: 73.00%
---- avg training fps: 7.14# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:57<00:48,  1.86it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:57<00:46,  1.93it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:58<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:58<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:41,  2.07it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:59<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:59<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.18# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:00<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:00<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:01<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:02<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:02<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:02<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.21# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:03<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:03<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:04<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:05<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:05<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.24# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:05<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:06<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:07<00:31,  2.15it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:07<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:08<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.27# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:08<00:30,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:09<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:09<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:10<00:28,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:10<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:11<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.30# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:11<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:11<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:12<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:12<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:12<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:13<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:13<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.32# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:14<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:14<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:15<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:15<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:16<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:16<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:16<00:22,  2.14it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.35# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:17<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:17<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:18<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:18<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:19<00:19,  2.15it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:19<00:19,  2.14it/s]Progress: 89.00%
---- avg training fps: 7.37# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:19<00:19,  2.14it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:20<00:18,  2.13it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:20<00:18,  2.13it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:20<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:21<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:21<00:17,  2.13it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:22<00:16,  2.15it/s]Progress: 91.00%
---- avg training fps: 7.40# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:22<00:16,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:23<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:23<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:24<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:24<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:25<00:14,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.42# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:25<00:14,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:25<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:26<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:26<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:27<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:27<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:27<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.44# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:28<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:28<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:29<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:29<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:30<00:09,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:30<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:30<00:08,  2.13it/s]Progress: 97.00%
---- avg training fps: 7.46# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:31<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:31<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:32<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:32<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:33<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:33<00:06,  1.86it/s]Progress: 99.00%
---- avg training fps: 7.47# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:34<00:05,  1.94it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:34<00:05,  1.99it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:35<00:05,  1.99it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:35<00:04,  2.03it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:35<00:03,  2.06it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:36<00:03,  2.09it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:36<00:02,  2.10it/s]Progress: 100.00%
---- avg training fps: 7.49# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:37<00:02,  2.12it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:37<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:38<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:38<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:38<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:39<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.51Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.30it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.27it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.56it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:59<00:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 04:16:23.494439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:16:23.585720: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:16:23.585750: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:16:23.604492: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:16:24.007490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:16:24.007571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:16:24.007580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23115 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_04-16-25-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723515385.7808163 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 6377.17it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.79it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.74it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.86it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.18it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_04-16-25-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_04-16-25-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 749974.89it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1665385.41it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene depicts Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is featured.
- In the style of TOK, a blockchain formed by bees is shown.
- In the style of TOK, a gorgon made out of sharks swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple is hidden deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness" is featured.
- In the style of TOK, someone suggests quitting their boring corporation job together.
- In the style of TOK, petroglyphs are shown.
- In the style of TOK, a room and space exchange is based on first and second degree connections.
- In the style of TOK, a 6-pack of nightmare fuel is portrayed.
- In the style of TOK, a band of dancing, singing beavers is shown.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show has elephant seals as runway models and egrets in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is featured.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 24 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid swims underwater in the ocean, crafted from fishnets and sea trash.
- In the style of TOK, a throng of Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is illustrated.
- In the style of TOK, a blockchain of bees is depicted.
- In the style of TOK, a gorgon made out of sharks is depicted swimming underwater, the sharks eating each other.
- In the style of TOK, a hillside at sunset is shown with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle is illustrated.
- In the style of TOK, cats are shown pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is illustrated.
- In the style of TOK, the phrase "Let's quit our boring corporation job together" is illustrated.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange based on first and second-degree connection is depicted.
- In the style of TOK, trypophobia is illustrated.
- In the style of TOK, a six-pack of nightmare fuel is depicted.
- In the style of TOK, a band of dancing, singing beavers is shown.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam as depicted by Tarsem Singh.
- In the style of TOK, a brigade of beavers is illustrated in the manner of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is shown, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is depicted.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and packing peanuts is swimming up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple sits deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, let's quit our boring corporation job together.
- In the style of TOK, petroglyphs.
- In the style of TOK, room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple sits deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, let's quit our boring corporation job together.
- In the style of TOK, petroglyphs.
- In the style of TOK, room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.

--------------------------
GPT-4 returned the wrong number of prompts 53 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or nature scenes

- In the style of TOK, a mermaid crafted from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, narrating the best and worst of times.
- In the style of TOK, a blockchain composed of bees.
- In the style of TOK, a gorgon formed from sharks cannibalizing each other, swimming underwater.
- In the style of TOK, a sunset over a hillside with Venus and Earth orbiting the sun.
- In the style of TOK, an ancient temple nestled in the Amazon jungle.
- In the style of TOK, cats defecating in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, it was the age of wisdom and foolishness.
- In the style of TOK, two people planning to leave their corporate jobs together.
- In the style of TOK, ancient rock carvings.
- In the style of TOK, room and space exchange based on connections.
- In the style of TOK, a pattern inducing trypophobia.
- In the style of TOK, a six-pack of nightmare fuel.
- In the style of TOK, dancing and singing beavers, reminiscent of Jim Henson's Muppets.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers rapidly constructing a dam, akin to a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers rapidly constructing a dam, similar to Tarsem Singh's visuals.
- In the style of TOK, a brigade of beavers in an M.C. Escher-like scene.
- In the style of TOK, a moving castle traversing grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing together.
- In the style of TOK, a preserved, frozen 1950s restaurant kitchen rediscovered in the space age.
- In the style of TOK, elephant seals strutting down the runway with egrets in the audience at a fashion show.
- In the style of TOK, a hyper-realistic painting featuring lemon-lime architecture.
- In the style of TOK, a mermaid made from fishnets, dead fish, packing peanuts, and sea trash, swimming to peek above the water.
- In the style of TOK, a mermaid fashioned from fishnets and sea trash, swimming underwater in the ocean.
- In the style of TOK, Lilliputians crammed into the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India.
- In the style of TOK, the best and worst of times described.
- In the style of TOK, bees forming a blockchain.
- In the style of TOK, a gorgon created from sharks eating each other, swimming underwater.
- In the style of TOK, a sunset with Venus and Earth orbiting the sun over a hillside.
- In the style of TOK, an ancient temple deep within the Amazon jungle.
- In the style of TOK, zero-gravity cats pooping.
- In the style of TOK, a goblin goat depiction.
- In the style of TOK, an age of wisdom and foolishness.
- In the style of TOK, let's quit our boring corporate jobs.
- In the style of TOK, ancient petroglyphs.
- In the style of TOK, room and space swap based on connections.
- In the style of TOK, a trypophobia-provoking pattern.
- In the style of TOK, a six-pack of nightmare fuel.
- In the style of TOK, singing and dancing beavers like Jim Henson's Muppets.
- In the style of TOK, a beaver gnawing a rifle in two.
- In the style of TOK, a brigade of beavers building a dam quickly, evoking a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers constructing a dam rapidly, reminiscent of Tarsem Singh's work.
- In the style of TOK, a brigade of beavers in an M.C. Escher-inspired scene.
- In the style of TOK, a mobile castle moving along grassy hills.
- In the style of TOK, a synchronized chorus line of adorable beavers.
- In the style of TOK, a frozen, preserved 1950s restaurant kitchen rediscovered in the space age.
- In the style of TOK, a fashion show featuring elephant seals on the runway and egrets in the audience.
- In the style of TOK, an ultra-realistic painting with lemon-lime architectural details.
- In the style of TOK, a mermaid made from fishnets, dead fish, packing peanuts, and other sea trash ascending to peek above the ocean surface.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surreal and intricate marine or nature scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15730.82it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid crafte...
1     in the style of <s0><s1><s2>, lilliputians are...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, narrating the be...
4     in the style of <s0><s1><s2>, a blockchain com...
5     in the style of <s0><s1><s2>, a gorgon formed ...
6     in the style of <s0><s1><s2>, a sunset over a ...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats defecating ...
9          in the style of <s0><s1><s2>, a goblin goat.
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, two people plann...
12    in the style of <s0><s1><s2>, ancient rock car...
13    in the style of <s0><s1><s2>, room and space e...
14    in the style of <s0><s1><s2>, a pattern induci...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, dancing and sing...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a moving castle ...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a preserved, fro...
24    in the style of <s0><s1><s2>, elephant seals s...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made f...
27    in the style of <s0><s1><s2>, a mermaid fashio...
28    in the style of <s0><s1><s2>, lilliputians cra...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the best and wor...
31    in the style of <s0><s1><s2>, bees forming a b...
32    in the style of <s0><s1><s2>, a gorgon created...
33    in the style of <s0><s1><s2>, a sunset with ve...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, zero-gravity cat...
36    in the style of <s0><s1><s2>, a goblin goat de...
37    in the style of <s0><s1><s2>, an age of wisdom...
38    in the style of <s0><s1><s2>, let's quit our b...
39    in the style of <s0><s1><s2>, ancient petrogly...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:35,  2.93s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<20:56,  4.22s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:20,  2.49s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:18,  1.69s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:05,  1.24s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:45,  1.03it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.34# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:53,  1.25it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:20,  1.45it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<02:58,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:42,  1.78it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:32,  1.89it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:25,  1.98it/s]Progress: 7.00%
---- avg training fps: 3.70# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:12<02:19,  2.05it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:13<02:16,  2.10it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:13<02:22,  2.00it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:17,  2.06it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:14<02:14,  2.10it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:11,  2.14it/s]Progress: 9.00%
---- avg training fps: 4.56# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:15<02:09,  2.16it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:08,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:07,  2.20it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:06,  2.20it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:05,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:04,  2.21it/s]Progress: 11.00%
---- avg training fps: 5.19# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:04,  2.20it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:18<02:04,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:03,  2.21it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:19<02:02,  2.21it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:02,  2.21it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:57,  2.30it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:59,  2.27it/s]Progress: 13.00%
---- avg training fps: 5.68# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<01:59,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:59,  2.24it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:22<01:59,  2.23it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:58,  2.22it/s]Progress: 15.00%
---- avg training fps: 6.04# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:23<01:58,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:58,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:57,  2.22it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<01:57,  2.22it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:56,  2.22it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:56,  2.22it/s]Progress: 17.00%
---- avg training fps: 6.34# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:26<01:56,  2.22it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:26<01:51,  2.30it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:26<01:52,  2.28it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:52,  2.26it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:27<01:52,  2.25it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:52,  2.24it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:28<01:53,  2.23it/s]Progress: 19.00%
---- avg training fps: 6.58# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:52,  2.23it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:52,  2.23it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:52,  2.22it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:33<05:06,  1.23s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:33<04:07,  1.00s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:34<03:26,  1.19it/s]Progress: 21.00%
---- avg training fps: 6.26# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:34<02:56,  1.38it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:34<02:36,  1.56it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:35<02:36,  1.56it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:35<02:18,  1.76it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:35<02:09,  1.87it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:36<02:03,  1.96it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:36<01:58,  2.03it/s]Progress: 23.00%
---- avg training fps: 6.45# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:37<01:54,  2.08it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:37<01:52,  2.11it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:38<01:51,  2.13it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:38<01:50,  2.14it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:39<01:48,  2.16it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:39<01:47,  2.18it/s]Progress: 25.00%
---- avg training fps: 6.61# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:39<01:46,  2.18it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:40<01:46,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:40<01:45,  2.18it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:41<01:45,  2.18it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:41<01:45,  2.18it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:41<01:40,  2.27it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:42<01:41,  2.25it/s]Progress: 27.00%
---- avg training fps: 6.76# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:42<01:41,  2.23it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:43<01:42,  2.21it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:43<01:42,  2.20it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:44<01:42,  2.19it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:44<01:42,  2.18it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:44<01:41,  2.19it/s]Progress: 29.00%
---- avg training fps: 6.87# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:45<01:41,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:45<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:46<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:47<01:58,  1.84it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:47<01:52,  1.92it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:47<01:48,  1.99it/s]Progress: 31.00%
---- avg training fps: 6.95# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:48<01:48,  1.99it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:48<01:41,  2.12it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:48<01:39,  2.14it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:49<01:38,  2.15it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:49<01:38,  2.16it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:50<01:37,  2.17it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:50<01:36,  2.17it/s]Progress: 33.00%
---- avg training fps: 7.04# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:51<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:51<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:52<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:52<01:34,  2.18it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:52<01:34,  2.18it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:53<01:33,  2.18it/s]Progress: 35.00%
---- avg training fps: 7.13# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:53<01:33,  2.17it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:54<01:33,  2.17it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:54<01:33,  2.17it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:54<01:28,  2.26it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:55<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:55<01:29,  2.22it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:58<03:42,  1.12s/it]Progress: 37.00%
---- avg training fps: 6.94# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:58<03:02,  1.08it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [00:59<02:33,  1.27it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [00:59<02:13,  1.46it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:00<02:00,  1.62it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:00<01:50,  1.75it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:01<01:43,  1.86it/s]Progress: 39.00%
---- avg training fps: 7.02# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:01<01:38,  1.94it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:02<01:35,  2.00it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:02<01:32,  2.05it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:02<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:03<01:30,  2.08it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:03<01:25,  2.19it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:03<01:25,  2.19it/s]Progress: 41.00%
---- avg training fps: 7.09# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:04<01:24,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:04<01:24,  2.17it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:05<01:24,  2.18it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:05<01:23,  2.18it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:06<01:23,  2.17it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:06<01:23,  2.17it/s]Progress: 43.00%
---- avg training fps: 7.16# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:07<01:23,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:07<01:22,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:07<01:22,  2.16it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:08<01:21,  2.16it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:08<01:20,  2.17it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:09<01:20,  2.17it/s]Progress: 45.00%
---- avg training fps: 7.22# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:09<01:20,  2.17it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:09<01:16,  2.26it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:10<01:17,  2.23it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:10<01:17,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:11<01:17,  2.21it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:11<01:16,  2.20it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:12<01:16,  2.19it/s]Progress: 47.00%
---- avg training fps: 7.28# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:12<01:16,  2.19it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:12<01:15,  2.19it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:13<01:15,  2.18it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:13<01:15,  2.17it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:14<01:15,  2.17it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:14<01:14,  2.17it/s]Progress: 49.00%
---- avg training fps: 7.33# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:15<01:14,  2.17it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:15<01:13,  2.17it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:16<01:13,  2.17it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:16<01:10,  2.27it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:16<01:10,  2.24it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:17<01:19,  1.99it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:17<01:16,  2.04it/s]Progress: 51.00%
---- avg training fps: 7.37# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:18<01:14,  2.08it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:18<01:13,  2.10it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:19<01:12,  2.12it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:19<01:10,  2.14it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:20<01:10,  2.14it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:20<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.41# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:20<01:08,  2.16it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:25<03:55,  1.59s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:25<03:03,  1.25s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:26<02:27,  1.01s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:26<02:27,  1.01s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:26<01:59,  1.21it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:26<01:43,  1.39it/s]Progress: 55.00%
---- avg training fps: 7.12# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:27<01:40,  1.42it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:28<01:29,  1.59it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:28<01:21,  1.73it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:28<01:16,  1.84it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:29<01:11,  1.93it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:29<01:08,  2.00it/s]Progress: 57.00%
---- avg training fps: 7.17# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:30<01:06,  2.06it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:30<01:05,  2.08it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:31<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:31<01:02,  2.13it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:32<01:01,  2.15it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:32<01:01,  2.16it/s]Progress: 59.00%
---- avg training fps: 7.22# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:33<01:01,  2.16it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:33<00:57,  2.27it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:33<00:57,  2.24it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:33<00:57,  2.22it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:34<00:57,  2.22it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:34<00:57,  2.21it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:35<00:57,  2.19it/s]Progress: 61.00%
---- avg training fps: 7.27# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:35<00:57,  2.19it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:36<00:57,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:36<00:56,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:37<00:55,  2.18it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:37<00:55,  2.17it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:38<00:55,  2.17it/s]Progress: 63.00%
---- avg training fps: 7.31# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:38<00:54,  2.17it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:39<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:39<00:54,  2.18it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:39<00:51,  2.28it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:39<00:51,  2.26it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:40<00:51,  2.23it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:40<00:51,  2.22it/s]Progress: 65.00%
---- avg training fps: 7.35# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:41<00:51,  2.21it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:41<00:50,  2.21it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:42<00:50,  2.20it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:42<00:50,  2.19it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:43<00:49,  2.19it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:43<00:49,  2.19it/s]Progress: 67.00%
---- avg training fps: 7.39# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:43<00:49,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:44<00:48,  2.17it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:44<00:48,  2.18it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:45<00:47,  2.18it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:45<00:47,  2.18it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:45<00:45,  2.28it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:46<00:45,  2.26it/s]Progress: 69.00%
---- avg training fps: 7.43# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:46<00:45,  2.23it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:47<00:45,  2.20it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:47<00:45,  2.19it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:50<02:00,  1.23s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:51<01:36,  1.00it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:51<01:20,  1.19it/s]Progress: 71.00%
---- avg training fps: 7.29# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:52<01:09,  1.37it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:52<01:01,  1.54it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:53<01:00,  1.54it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:53<00:54,  1.69it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:54<00:50,  1.81it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:54<00:47,  1.91it/s]Progress: 73.00%
---- avg training fps: 7.31# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:54<00:47,  1.91it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:54<00:43,  2.07it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:55<00:41,  2.10it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:55<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:56<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:56<00:39,  2.15it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:57<00:38,  2.16it/s]Progress: 75.00%
---- avg training fps: 7.35# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:57<00:38,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:58<00:37,  2.18it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:58<00:37,  2.18it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:59<00:36,  2.17it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:59<00:36,  2.17it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:59<00:35,  2.18it/s]Progress: 77.00%
---- avg training fps: 7.38# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:00<00:35,  2.18it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:00<00:34,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:01<00:34,  2.17it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:01<00:33,  2.27it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:01<00:33,  2.23it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:02<00:32,  2.23it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:02<00:32,  2.21it/s]Progress: 79.00%
---- avg training fps: 7.41# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:03<00:32,  2.20it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:03<00:32,  2.18it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:04<00:31,  2.19it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:04<00:31,  2.19it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:04<00:30,  2.17it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:05<00:30,  2.17it/s]Progress: 81.00%
---- avg training fps: 7.44# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:05<00:29,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:06<00:29,  2.18it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:06<00:29,  2.17it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:07<00:28,  2.16it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:07<00:28,  2.16it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:07<00:26,  2.26it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:08<00:26,  2.24it/s]Progress: 83.00%
---- avg training fps: 7.47# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:08<00:26,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:09<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:09<00:25,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:09<00:25,  2.18it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:10<00:25,  2.18it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:10<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.49# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:11<00:24,  2.17it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:11<00:23,  2.18it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:12<00:23,  2.18it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:12<00:22,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:13<00:22,  2.17it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:16<00:59,  1.25s/it]Progress: 87.00%
---- avg training fps: 7.38# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:16<00:59,  1.25s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:16<00:46,  1.01it/s]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:17<00:38,  1.20it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:17<00:34,  1.29it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:18<00:29,  1.47it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:18<00:26,  1.63it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:19<00:23,  1.76it/s]Progress: 89.00%
---- avg training fps: 7.39# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:19<00:21,  1.88it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:20<00:20,  1.96it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:20<00:19,  2.01it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:20<00:18,  2.06it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:21<00:17,  2.10it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:16,  2.12it/s]Progress: 91.00%
---- avg training fps: 7.42# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:22<00:16,  2.14it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:23<00:15,  2.15it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:23<00:14,  2.24it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:23<00:14,  2.23it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:24<00:13,  2.21it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:24<00:13,  2.21it/s]Progress: 93.00%
---- avg training fps: 7.45# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:25<00:13,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:25<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:25<00:12,  2.19it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:26<00:11,  2.19it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:26<00:11,  2.17it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:27<00:11,  2.17it/s]Progress: 95.00%
---- avg training fps: 7.47# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.18it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:28<00:10,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.17it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:29<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:29<00:09,  2.17it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:29<00:08,  2.26it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:30<00:08,  2.23it/s]Progress: 97.00%
---- avg training fps: 7.50# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:30<00:07,  2.21it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:30<00:07,  2.20it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:31<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:31<00:06,  2.19it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:32<00:05,  2.18it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.18it/s]Progress: 99.00%
---- avg training fps: 7.52# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:33<00:05,  2.17it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.18it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:34<00:04,  2.18it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.17it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:35<00:03,  2.16it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:35<00:02,  2.18it/s]Progress: 100.00%
---- avg training fps: 7.54# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:35<00:02,  2.18it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:35<00:02,  2.27it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:36<00:01,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:36<00:01,  2.22it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:37<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:37<00:00,  2.20it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:38<00:00,  2.19it/s]Progress: 100.00%
---- avg training fps: 7.56# Trainer step: 294, epoch: 21: : 301it [02:38,  2.17it/s]                       Progress: 100.00%Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.25it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.93it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.70it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.61it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.56it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.48it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.47it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.46it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.45it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.44it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.43it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.42it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.42it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.41it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.41it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.41it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.41it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.40it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.40it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.39it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.37it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.36it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.93it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.80it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.55it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.31it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.28it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.30it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.28it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.28it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.28it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:01,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 04:21:36.294843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:21:36.385863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:21:36.385891: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:21:36.405130: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:21:36.806765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:21:36.806822: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:21:36.806831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_04-21-38-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723515698.6234007 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 16524.49it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.73it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  4.37it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.25it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_04-21-38-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.38it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.48it/s] 20%|██        | 2/10 [00:00<00:01,  4.38it/s] 30%|███       | 3/10 [00:00<00:01,  4.64it/s] 40%|████      | 4/10 [00:00<00:01,  4.78it/s] 50%|█████     | 5/10 [00:01<00:01,  4.74it/s] 60%|██████    | 6/10 [00:01<00:00,  4.74it/s] 70%|███████   | 7/10 [00:01<00:00,  4.94it/s] 80%|████████  | 8/10 [00:01<00:00,  5.02it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.02it/s]100%|██████████| 10/10 [00:02<00:00,  4.86it/s]100%|██████████| 10/10 [00:02<00:00,  4.77it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7365.54it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:10,  3.05s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:10,  3.46s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:20,  2.09s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:07,  1.44s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:21,  1.09s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:17,  1.14it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.64# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:36,  1.35it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:10,  1.54it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:52,  1.69it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:39,  1.81it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:39,  1.81it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:31,  1.91it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:25,  1.98it/s]Progress: 7.00%
---- avg training fps: 4.05# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:21,  2.03it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:17,  2.08it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:15,  2.09it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:14,  2.10it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:13,  2.11it/s]Progress: 9.00%
---- avg training fps: 4.91# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:12,  2.13it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:09,  2.14it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:09,  2.14it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:08,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.49# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:08,  2.14it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:07,  2.14it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:08,  2.13it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:07,  2.13it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:07,  2.13it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:06,  2.14it/s]Progress: 13.00%
---- avg training fps: 5.91# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:06,  2.14it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:06,  2.13it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:05,  2.13it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:20,  1.90it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:16,  1.96it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:12,  2.00it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:09,  2.04it/s]Progress: 15.00%
---- avg training fps: 6.18# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:07,  2.06it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:05,  2.08it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:04,  2.09it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:03,  2.11it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:03,  2.11it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:02,  2.11it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:01,  2.12it/s]Progress: 17.00%
---- avg training fps: 6.43# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:58,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:58,  2.13it/s]Progress: 19.00%
---- avg training fps: 6.63# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:57,  2.13it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<06:01,  1.46s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:46,  1.16s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:54,  1.05it/s]Progress: 21.00%
---- avg training fps: 6.16# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:18,  1.24it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:52,  1.42it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:34,  1.57it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:21,  1.71it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:13,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:06,  1.90it/s]Progress: 23.00%
---- avg training fps: 6.34# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:06,  1.90it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<02:02,  1.96it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<01:58,  2.00it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:55,  2.04it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<02:08,  1.83it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<02:02,  1.92it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:58,  1.98it/s]Progress: 25.00%
---- avg training fps: 6.45# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:55,  2.02it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:53,  2.05it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:51,  2.08it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:49,  2.09it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:49,  2.09it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:48,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:47,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.59# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.71# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:41,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.81# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:38,  2.13it/s]Progress: 33.00%
---- avg training fps: 6.90# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:38,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:36,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:36,  2.12it/s]Progress: 35.00%
---- avg training fps: 6.98# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:33,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:00<04:26,  1.35s/it]Progress: 37.00%
---- avg training fps: 6.72# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:00<03:33,  1.08s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:01<02:56,  1.11it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:01<02:30,  1.29it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:02<02:12,  1.46it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:02<01:59,  1.61it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:03<01:50,  1.74it/s]Progress: 39.00%
---- avg training fps: 6.78# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:03<01:55,  1.66it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:04<01:46,  1.78it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:04<01:46,  1.78it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:04<01:41,  1.87it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:05<01:37,  1.92it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:05<01:34,  1.97it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:06<01:32,  2.02it/s]Progress: 41.00%
---- avg training fps: 6.85# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:06<01:30,  2.05it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:07<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:07<01:27,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:08<01:26,  2.10it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:08<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:08<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 6.92# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:09<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:09<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:09<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:10<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:10<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:11<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:11<01:21,  2.12it/s]Progress: 45.00%
---- avg training fps: 6.98# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:12<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:12<01:20,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:13<01:20,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:13<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:14<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:14<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:14<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.04# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:15<01:18,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:15<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:15<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:16<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:16<01:16,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:17<01:16,  2.12it/s]Progress: 49.00%
---- avg training fps: 7.09# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:17<01:15,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:18<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:18<01:15,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:18<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:19<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:19<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:20<01:13,  2.11it/s]Progress: 51.00%
---- avg training fps: 7.14# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:20<01:13,  2.11it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:21<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:21<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:22<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:22<01:11,  2.11it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:23<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.18# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:23<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:23<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:27<03:56,  1.60s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:28<03:05,  1.26s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:28<02:29,  1.02s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:29<02:04,  1.17it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:29<01:46,  1.35it/s]Progress: 55.00%
---- avg training fps: 6.92# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:30<01:34,  1.51it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:30<01:25,  1.66it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:31<01:19,  1.78it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:31<01:15,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:32<01:15,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:32<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:32<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.97# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:32<01:07,  2.02it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:33<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:33<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:34<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:34<01:03,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:35<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.02# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:35<01:02,  2.11it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:36<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:36<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:36<01:01,  2.10it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:37<01:00,  2.10it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:37<01:00,  2.10it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:38<00:59,  2.10it/s]Progress: 61.00%
---- avg training fps: 7.06# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:38<00:59,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:39<00:58,  2.10it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:39<00:58,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:40<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:40<00:57,  2.11it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:41<00:57,  2.10it/s]Progress: 63.00%
---- avg training fps: 7.09# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:41<00:57,  2.10it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:41<00:56,  2.11it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:41<00:56,  2.10it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:42<00:55,  2.10it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:42<00:55,  2.10it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:43<00:54,  2.10it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:43<00:54,  2.10it/s]Progress: 65.00%
---- avg training fps: 7.13# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:44<00:53,  2.10it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:44<00:53,  2.10it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:45<00:52,  2.10it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:45<00:52,  2.10it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:46<00:52,  2.10it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:46<00:51,  2.10it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:46<00:51,  2.10it/s]Progress: 67.00%
---- avg training fps: 7.16# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:47<00:50,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:47<00:50,  2.11it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:48<00:49,  2.10it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:48<00:49,  2.10it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:49<00:49,  2.09it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:49<00:48,  2.09it/s]Progress: 69.00%
---- avg training fps: 7.20# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:50<00:48,  2.09it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:50<00:47,  2.10it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:51<00:47,  2.10it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:51<00:47,  2.10it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:55<02:34,  1.58s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:55<02:00,  1.24s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:56<01:37,  1.01s/it]Progress: 71.00%
---- avg training fps: 7.00# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:56<01:20,  1.18it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:57<01:09,  1.36it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:57<01:01,  1.52it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:57<00:55,  1.66it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:58<00:51,  1.78it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:58<00:48,  1.87it/s]Progress: 73.00%
---- avg training fps: 7.03# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:59<00:48,  1.87it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:59<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:59<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:00<00:43,  2.02it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:00<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:01<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:01<00:40,  2.09it/s]Progress: 75.00%
---- avg training fps: 7.07# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:02<00:39,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:02<00:39,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:03<00:38,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:03<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:04<00:38,  2.10it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:04<00:37,  2.10it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:04<00:37,  2.10it/s]Progress: 77.00%
---- avg training fps: 7.10# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:05<00:36,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:05<00:36,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:06<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:06<00:35,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:06<00:34,  2.11it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:07<00:34,  2.11it/s]Progress: 79.00%
---- avg training fps: 7.13# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:07<00:33,  2.12it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:08<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:08<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:08<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:09<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:09<00:31,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:10<00:31,  2.10it/s]Progress: 81.00%
---- avg training fps: 7.16# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:10<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:11<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:11<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:12<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:12<00:28,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:13<00:28,  2.11it/s]Progress: 83.00%
---- avg training fps: 7.18# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:13<00:28,  2.11it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:13<00:27,  2.11it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:14<00:27,  2.11it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:14<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:15<00:26,  2.11it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:15<00:26,  2.12it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:15<00:25,  2.11it/s]Progress: 85.00%
---- avg training fps: 7.21# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:16<00:25,  2.11it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:16<00:24,  2.12it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:17<00:24,  2.11it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:17<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:18<00:23,  2.11it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:18<00:23,  2.12it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:22<01:18,  1.63s/it]Progress: 87.00%
---- avg training fps: 7.04# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:23<01:00,  1.28s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:23<00:47,  1.04s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:24<00:38,  1.16it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:24<00:32,  1.34it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:25<00:28,  1.51it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:25<00:25,  1.65it/s]Progress: 89.00%
---- avg training fps: 7.07# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:25<00:23,  1.78it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:26<00:21,  1.87it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:26<00:21,  1.87it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:26<00:20,  1.94it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:27<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:27<00:18,  2.03it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:28<00:17,  2.05it/s]Progress: 91.00%
---- avg training fps: 7.10# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:28<00:16,  2.07it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:29<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:29<00:15,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:30<00:15,  2.10it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:30<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:31<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.13# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:31<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:31<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:32<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:32<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:32<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:33<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:33<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.15# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:34<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:34<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:35<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:35<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:36<00:09,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:36<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:36<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.18# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:37<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:37<00:07,  2.17it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:38<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:38<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:39<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:39<00:05,  2.17it/s]Progress: 99.00%
---- avg training fps: 7.20# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:39<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:40<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:41<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:41<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:42<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.23# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:42<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:43<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:43<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:44<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:44<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:45<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.25Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.29it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.33it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.32it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.31it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.30it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.29it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.29it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.29it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.29it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.28it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.28it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.28it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.28it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.28it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.28it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.28it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.28it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.28it/s][A100%|██████████| 30/30 [00:09<00:00,  3.32it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.39it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.35it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.27it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.27it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.27it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.45it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.38it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.34it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.32it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.29it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.29it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.28it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.28it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.27it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.27it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.27it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.27it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.27it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.27it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.27it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.27it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.27it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.31it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.81it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.53it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.42it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.30it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.28it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.27it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.27it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.93it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.44it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.27it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.26it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.23it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.24it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.25it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.25it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.43it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.37it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.33it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.31it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.29it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.28it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.28it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.27it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.27it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.27it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.26it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.26it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.26it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.26it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.26it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.26it/s][A
 67%|██████▋   | 20/30 [00:06<00:03,  3.26it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.26it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.26it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.26it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.26it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.26it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.26it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.26it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.26it/s][A100%|██████████| 30/30 [00:09<00:00,  3.30it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:05<00:00,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 04:26:15.007233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:26:15.103477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:26:15.103502: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:26:15.122497: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:26:15.528436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:26:15.528522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:26:15.528531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23126 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_04-26-17-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723515977.37286 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 85700.92it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.74it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.65it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.85it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.17it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_04-26-17-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_04-26-17-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 292625.86it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 714487.12it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a Tarsem Singh-like flair.
- In the style of TOK, a brigade of beavers resembles M. C. Escher's work.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen has been frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show has elephant seals as runway models and egrets in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above water.

--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and sea trash, is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun is depicted.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is embodied in a visual representation.
- In the style of TOK, two individuals decide to quit their boring corporation job together.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, trypophobia is visually represented.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is created with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is shown chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with a pattern like a Hawaiian shirt.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is designed in the style of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and sea trash is swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swims up through the sea to take a peek above the water.

--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal, intricate, and imaginatively whimsical.

- In the style of TOK, a mermaid made out of fishnets and sea trash swims underwater.
- In the style of TOK, Lilliputians are cramped inside a giant sea-sponge.
- In the style of TOK, a scenic view of Fort Kochi, Kerala.
- In the style of TOK, an abstract representation of the best and worst of times.
- In the style of TOK, a chain of bees linked together.
- In the style of TOK, a gorgon composed of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple hidden deep in the Amazon jungle.
- In the style of TOK, cats defy gravity while pooping.
- In the style of TOK, a mystical goblin goat.
- In the style of TOK, an allegory for the age of wisdom and foolishness.
- In the style of TOK, two people planning to leave their corporate jobs.
- In the style of TOK, ancient rock carvings known as petroglyphs.
- In the style of TOK, a room and space exchange based on connections.
- In the style of TOK, a visually unsettling pattern of holes resembling trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of beavers dance and sing.
- In the style of TOK, a beaver gnaws a rifle in half.
- In the style of TOK, beavers rapidly construct a dam.
- In the style of TOK, beavers rapidly construct a dam with vibrant patterns.
- In the style of TOK, beavers rapidly construct a dam in a detailed artistic style.
- In the style of TOK, a brigade of beavers depicted in intricate, impossible structures.
- In the style of TOK, a moving castle on grassy hills.
- In the style of TOK, a cute chorus line of beavers dancing.
- In the style of TOK, a frozen 1950s restaurant kitchen rediscovered in the space age.
- In the style of TOK, elephant seals model on a runway with egrets watching.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made from sea trash swims up to the water surface.
--------------------------
GPT-4 returned the wrong number of prompts 28 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 4...
----- GPT response: -----
Style Description: Surreal and fantastical imagery

- In the style of TOK, a mermaid constructed from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, a scenic view of Fort Kochi, Kerala, India.
- In the style of TOK, a depiction of the phrase "the best of times, the worst of times."
- In the style of TOK, a blockchain made up of bees.
- In the style of TOK, a gorgon composed of sharks eating each other, swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep within the Amazon jungle.
- In the style of TOK, cats are defecating in zero-gravity conditions.
- In the style of TOK, a depiction of a goblin goat.
- In the style of TOK, a visualization of the phrase "the age of wisdom, the age of foolishness."
- In the style of TOK, coworkers discuss quitting their boring corporate jobs together.
- In the style of TOK, ancient petroglyphs are depicted.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, an illustration that induces trypophobia.
- In the style of TOK, a six-pack of nightmare-inducing imagery.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a brigade of beavers builds a dam as seen in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers constructs a dam in a Tarsem Singh-inspired scene.
- In the style of TOK, a brigade of beavers is depicted in an M. C. Escher style.
- In the style of TOK, a castle moves along the ground on grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets in the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made from fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 28 instead of 54, retrying...
WARNING: no captioning text was given and we're not doing chatgpt cleanup...
Concept mode:  style
Using GPT concept name as CLIP-segmentation prompt: Surreal and fantastical imagery
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15224.33it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, they were the be...
4     in the style of <s0><s1><s2>, a blockchain of ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats pooping in ...
9             in the style of <s0><s1><s2>, goblin goat
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, let's quit our b...
12            in the style of <s0><s1><s2>, petroglyphs
13    in the style of <s0><s1><s2>, room and space e...
14            in the style of <s0><s1><s2>, trypophobia
15    in the style of <s0><s1><s2>, a 6-pack of nigh...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle that is...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi, kera...
30    in the style of <s0><s1><s2>, they were the be...
31    in the style of <s0><s1><s2>, a blockchain of ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats pooping in ...
36            in the style of <s0><s1><s2>, goblin goat
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, let's quit our b...
39            in the style of <s0><s1><s2>, petroglyphs
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:35,  2.93s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:41,  4.37s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:44,  2.57s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:32,  1.73s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:13,  1.27s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:50,  1.01it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.28# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:57,  1.23it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:22,  1.44it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<02:59,  1.62it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:32,  1.90it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:24,  1.99it/s]Progress: 7.00%
---- avg training fps: 3.64# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:19,  2.06it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:15,  2.11it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:15,  2.11it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:21,  2.01it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:17,  2.07it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:13,  2.12it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:11,  2.15it/s]Progress: 9.00%
---- avg training fps: 4.51# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:15<02:08,  2.18it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:07,  2.19it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:16<02:06,  2.20it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:05,  2.21it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:17<02:04,  2.22it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:04,  2.22it/s]Progress: 11.00%
---- avg training fps: 5.14# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:18<02:03,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:02,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:02,  2.23it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:01,  2.23it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:01,  2.23it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<01:57,  2.31it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:20<01:58,  2.28it/s]Progress: 13.00%
---- avg training fps: 5.63# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<01:58,  2.27it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:21<01:58,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<01:58,  2.25it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:22<01:58,  2.25it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<01:58,  2.24it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:23<01:57,  2.24it/s]Progress: 15.00%
---- avg training fps: 6.00# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:23<01:57,  2.24it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:24<01:57,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:24<01:56,  2.23it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<01:56,  2.23it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:25<01:56,  2.23it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:55,  2.23it/s]Progress: 17.00%
---- avg training fps: 6.31# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:26<01:55,  2.23it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:26<01:51,  2.31it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:51,  2.29it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:27<01:51,  2.28it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:27<01:52,  2.26it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:28<01:52,  2.25it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:28<01:52,  2.23it/s]Progress: 19.00%
---- avg training fps: 6.55# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:29<01:52,  2.23it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:29<01:52,  2.22it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:51,  2.23it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:33<05:14,  1.27s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:33<04:13,  1.02s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:34<03:29,  1.17it/s]Progress: 21.00%
---- avg training fps: 6.21# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:34<02:59,  1.37it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:35<02:38,  1.54it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:35<02:38,  1.54it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:35<02:19,  1.75it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:09,  1.86it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:36<02:02,  1.96it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:36<01:58,  2.02it/s]Progress: 23.00%
---- avg training fps: 6.41# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:37<01:55,  2.07it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:37<01:52,  2.11it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:38<01:51,  2.13it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:38<01:49,  2.16it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:39<01:49,  2.15it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:39<01:48,  2.16it/s]Progress: 25.00%
---- avg training fps: 6.57# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:40<01:47,  2.17it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:40<01:46,  2.18it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:45,  2.19it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:41<01:44,  2.19it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:41<01:44,  2.19it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:41<01:40,  2.28it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:42<01:41,  2.25it/s]Progress: 27.00%
---- avg training fps: 6.68# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<02:00,  1.89it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:43<01:54,  1.97it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:50,  2.03it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:44<01:47,  2.08it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:44<01:45,  2.11it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:45<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.80# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:45<01:42,  2.15it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:46<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:46<01:40,  2.18it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:47<01:39,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:47<01:39,  2.18it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:48<01:38,  2.19it/s]Progress: 31.00%
---- avg training fps: 6.92# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:48<01:38,  2.19it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:48<01:34,  2.28it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:48<01:35,  2.25it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:49<01:35,  2.24it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:49<01:35,  2.22it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:50<01:35,  2.21it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:50<01:35,  2.21it/s]Progress: 33.00%
---- avg training fps: 7.02# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:51<01:34,  2.21it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:51<01:34,  2.21it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:52<01:33,  2.21it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:52<01:33,  2.21it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:53<01:32,  2.21it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:53<01:32,  2.21it/s]Progress: 35.00%
---- avg training fps: 7.11# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:53<01:32,  2.20it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:54<01:31,  2.20it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:54<01:31,  2.20it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:54<01:27,  2.29it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:55<01:28,  2.26it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:55<01:28,  2.24it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:58<03:24,  1.03s/it]Progress: 37.00%
---- avg training fps: 6.96# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:58<02:49,  1.16it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [00:59<02:24,  1.35it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [00:59<02:07,  1.53it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [00:59<01:55,  1.68it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:00<01:46,  1.80it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:00<01:40,  1.91it/s]Progress: 39.00%
---- avg training fps: 7.04# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:01<01:36,  1.98it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:01<01:33,  2.04it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:02<01:30,  2.08it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:02<01:28,  2.11it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:03<01:28,  2.11it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:03<01:24,  2.22it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:03<01:23,  2.21it/s]Progress: 41.00%
---- avg training fps: 7.12# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:04<01:24,  2.20it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:04<01:23,  2.20it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:04<01:23,  2.19it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:05<01:23,  2.17it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:05<01:25,  2.13it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:06<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 7.18# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:06<01:23,  2.13it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:07<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:07<01:22,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:08<01:22,  2.13it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:08<01:22,  2.13it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:09<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 7.24# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:09<01:21,  2.13it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:09<01:17,  2.23it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:10<01:18,  2.19it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:10<01:18,  2.17it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:11<01:18,  2.16it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:11<01:18,  2.14it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:11<01:18,  2.14it/s]Progress: 47.00%
---- avg training fps: 7.29# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:12<01:18,  2.12it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:12<01:18,  2.12it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:13<01:17,  2.12it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:13<01:17,  2.13it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:14<01:17,  2.12it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:14<01:16,  2.12it/s]Progress: 49.00%
---- avg training fps: 7.34# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:15<01:15,  2.12it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:15<01:15,  2.12it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:16<01:15,  2.12it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:16<01:11,  2.23it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:16<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:17<01:11,  2.18it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:17<01:11,  2.17it/s]Progress: 51.00%
---- avg training fps: 7.37# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:18<01:19,  1.94it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:18<01:16,  2.00it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:19<01:14,  2.05it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:19<01:13,  2.08it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:20<01:11,  2.10it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:20<01:10,  2.12it/s]Progress: 53.00%
---- avg training fps: 7.41# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:20<01:09,  2.13it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:24<03:22,  1.37s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:24<02:41,  1.10s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:25<02:12,  1.10it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:25<02:12,  1.10it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:25<01:49,  1.33it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:26<01:36,  1.50it/s]Progress: 55.00%
---- avg training fps: 7.20# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:26<01:26,  1.65it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:27<01:20,  1.77it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:27<01:15,  1.87it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:28<01:11,  1.95it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:28<01:09,  2.01it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:28<01:07,  2.05it/s]Progress: 57.00%
---- avg training fps: 7.25# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:29<01:05,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:29<01:04,  2.11it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:30<01:03,  2.13it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:30<01:02,  2.14it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:31<01:02,  2.14it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:31<01:01,  2.15it/s]Progress: 59.00%
---- avg training fps: 7.29# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:32<01:01,  2.15it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:32<00:57,  2.26it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:32<00:58,  2.22it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:33<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:33<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:33<00:58,  2.18it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:34<00:57,  2.18it/s]Progress: 61.00%
---- avg training fps: 7.33# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:34<00:57,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:35<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:35<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:36<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:36<00:55,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:37<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.37# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:37<00:55,  2.16it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:38<01:01,  1.92it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:38<01:01,  1.92it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:38<00:56,  2.07it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:39<00:55,  2.09it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:39<00:54,  2.10it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:40<00:53,  2.11it/s]Progress: 65.00%
---- avg training fps: 7.39# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:40<00:53,  2.13it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:41<00:52,  2.14it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:41<00:51,  2.14it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:42<00:51,  2.14it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:42<00:50,  2.15it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:42<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.43# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:43<00:49,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:43<00:49,  2.14it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:44<00:48,  2.14it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:44<00:48,  2.14it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:45<00:48,  2.14it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:45<00:46,  2.23it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:45<00:46,  2.19it/s]Progress: 69.00%
---- avg training fps: 7.46# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:46<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:46<00:46,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:47<00:45,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:49<01:40,  1.03s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:49<01:23,  1.16it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:50<01:11,  1.35it/s]Progress: 71.00%
---- avg training fps: 7.36# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:50<01:02,  1.51it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:51<00:56,  1.66it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:51<00:52,  1.78it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:52<00:49,  1.88it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:52<00:46,  1.95it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:53<00:44,  2.00it/s]Progress: 73.00%
---- avg training fps: 7.40# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:53<00:44,  2.00it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:53<00:41,  2.13it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:54<00:41,  2.13it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:54<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:54<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:55<00:39,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:55<00:39,  2.14it/s]Progress: 75.00%
---- avg training fps: 7.42# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:56<00:38,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:56<00:38,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:57<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:57<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:58<00:36,  2.14it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:58<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.45# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [01:59<00:35,  2.14it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [01:59<00:35,  2.13it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:00<00:35,  2.13it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:00<00:33,  2.23it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:00<00:33,  2.20it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:01<00:33,  2.18it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:01<00:33,  2.17it/s]Progress: 79.00%
---- avg training fps: 7.48# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:01<00:32,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:02<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:02<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:03<00:31,  2.15it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:03<00:31,  2.14it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:04<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.50# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:04<00:30,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:05<00:29,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:05<00:29,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:06<00:29,  2.14it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:06<00:29,  2.14it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:06<00:26,  2.26it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:06<00:26,  2.23it/s]Progress: 83.00%
---- avg training fps: 7.53# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:07<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:07<00:26,  2.18it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:08<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:08<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:09<00:25,  2.15it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:09<00:25,  2.15it/s]Progress: 85.00%
---- avg training fps: 7.55# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:10<00:24,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:10<00:24,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:11<00:23,  2.14it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:11<00:23,  2.14it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:12<00:22,  2.14it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:15<01:05,  1.36s/it]Progress: 87.00%
---- avg training fps: 7.41# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:15<01:05,  1.36s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:15<00:50,  1.07s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:16<00:40,  1.12it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:16<00:34,  1.31it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:17<00:29,  1.48it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:17<00:26,  1.64it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:18<00:23,  1.76it/s]Progress: 89.00%
---- avg training fps: 7.44# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:18<00:22,  1.86it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:19<00:20,  1.94it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:19<00:19,  2.00it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:20<00:18,  2.04it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:20<00:17,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:17,  2.09it/s]Progress: 91.00%
---- avg training fps: 7.46# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:21<00:16,  2.10it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:22<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:22<00:14,  2.22it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:22<00:14,  2.20it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:23<00:14,  2.18it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:23<00:13,  2.17it/s]Progress: 93.00%
---- avg training fps: 7.48# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:24<00:13,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:24<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:25<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:25<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:26<00:11,  2.15it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:26<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.50# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:27<00:10,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.14it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:28<00:09,  2.14it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:28<00:09,  2.14it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:28<00:08,  2.24it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:29<00:08,  2.21it/s]Progress: 97.00%
---- avg training fps: 7.53# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:29<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:30<00:07,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:30<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:31<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:31<00:06,  2.15it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.55# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:32<00:05,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.14it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:33<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:34<00:03,  2.14it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:34<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.57# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:35<00:02,  2.14it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:35<00:02,  2.24it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:35<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:36<00:01,  2.19it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:36<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:37<00:00,  2.16it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:37<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.59# Trainer step: 294, epoch: 21: : 301it [02:38,  2.16it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.88it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.47it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.47it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.46it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.46it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.45it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.44it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.44it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.44it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.44it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.42it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.43it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.42it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.42it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.42it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.41it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.41it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.41it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.41it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.40it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.40it/s][A100%|██████████| 30/30 [00:08<00:00,  3.46it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.56it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.46it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.44it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.42it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.41it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.40it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.39it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.39it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.39it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.38it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.38it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.37it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.36it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.82it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [03:57,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 04:31:21.014305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:31:21.105627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:31:21.105656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:31:21.124411: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:31:21.522654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:31:21.522734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:31:21.522743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23134 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_04-31-23-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723516283.2955735 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 48904.78it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.71it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.01it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.20it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_04-31-23-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 195995.51it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.67it/s] 20%|██        | 2/10 [00:00<00:02,  3.52it/s] 30%|███       | 3/10 [00:00<00:01,  4.20it/s] 40%|████      | 4/10 [00:00<00:01,  4.42it/s] 50%|█████     | 5/10 [00:01<00:01,  4.51it/s] 60%|██████    | 6/10 [00:01<00:00,  4.71it/s] 70%|███████   | 7/10 [00:01<00:00,  4.69it/s] 80%|████████  | 8/10 [00:01<00:00,  4.84it/s] 90%|█████████ | 9/10 [00:02<00:00,  4.82it/s]100%|██████████| 10/10 [00:02<00:00,  4.97it/s]100%|██████████| 10/10 [00:02<00:00,  4.55it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and minimalist dreamscapes

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
GPT-4 returned the wrong number of prompts 8 instead of 10, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Dreamy, surreal landscape with vivid colors.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Dreamy, surreal landscape with vivid colors.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10900.67it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:03,  3.02s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:57,  4.02s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:51,  2.40s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<08:03,  1.63s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<05:58,  1.21s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:42,  1.04it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.38# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<03:54,  1.25it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:22,  1.44it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:01,  1.60it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:47,  1.73it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:37,  1.83it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:31,  1.91it/s]Progress: 7.00%
---- avg training fps: 3.66# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:13<02:42,  1.76it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:34,  1.85it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:14<02:27,  1.93it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:22,  1.99it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:19,  2.03it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:17,  2.05it/s]Progress: 9.00%
---- avg training fps: 4.52# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:15,  2.08it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:10,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:18<02:10,  2.12it/s]Progress: 11.00%
---- avg training fps: 5.12# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:09,  2.13it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:19<02:08,  2.13it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:08,  2.13it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:20<02:07,  2.13it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:07,  2.13it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:21<02:06,  2.14it/s]Progress: 13.00%
---- avg training fps: 5.57# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:06,  2.14it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:05,  2.14it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:22<02:05,  2.13it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:05,  2.13it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:04,  2.13it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:04,  2.13it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:03,  2.13it/s]Progress: 15.00%
---- avg training fps: 5.91# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:03,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:25<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:01,  2.14it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:26<02:01,  2.14it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:26<02:01,  2.13it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<02:00,  2.13it/s]Progress: 17.00%
---- avg training fps: 6.18# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:27<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:28<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:29<01:58,  2.13it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:58,  2.13it/s]Progress: 19.00%
---- avg training fps: 6.40# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:57,  2.13it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:57,  2.13it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:56,  2.14it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:35<06:32,  1.58s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:35<05:09,  1.25s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:36<04:10,  1.02s/it]Progress: 21.00%
---- avg training fps: 5.91# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:36<03:29,  1.17it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:37<03:00,  1.35it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:37<02:40,  1.52it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:25,  1.66it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:38<02:15,  1.78it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:08,  1.87it/s]Progress: 23.00%
---- avg training fps: 6.10# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:39<02:08,  1.87it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:39<02:03,  1.93it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:59,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:40<01:57,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:54,  2.06it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:41<01:53,  2.07it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:52,  2.09it/s]Progress: 25.00%
---- avg training fps: 6.26# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:42<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:42<01:50,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:43<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:43<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:44<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:44<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:44<01:47,  2.12it/s]Progress: 27.00%
---- avg training fps: 6.40# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:45<01:47,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:45<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:46,  2.11it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:46<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:47<01:44,  2.12it/s]Progress: 29.00%
---- avg training fps: 6.52# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.13it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:49<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:49<01:42,  2.13it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:50<01:41,  2.12it/s]Progress: 31.00%
---- avg training fps: 6.63# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:50<01:41,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:51<01:41,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:51<01:40,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:52<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:52<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:53<01:38,  2.12it/s]Progress: 33.00%
---- avg training fps: 6.73# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:53<01:38,  2.12it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:53<01:38,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:37,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:54<01:37,  2.13it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:55<01:36,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.82# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:56<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:56<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:57<01:34,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:57<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:58<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:58<01:33,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:02<05:37,  1.71s/it]Progress: 37.00%
---- avg training fps: 6.45# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:03<04:22,  1.33s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:03<03:30,  1.07s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:04<02:54,  1.12it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:04<02:29,  1.30it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:05<02:11,  1.47it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:05<01:58,  1.62it/s]Progress: 39.00%
---- avg training fps: 6.53# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:06<01:49,  1.74it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:06<01:43,  1.84it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:07<01:43,  1.84it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:07<01:38,  1.91it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:07<01:37,  1.94it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:08<01:33,  1.99it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:08<01:31,  2.03it/s]Progress: 41.00%
---- avg training fps: 6.61# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:08<01:30,  2.06it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:09<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:09<01:27,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:10<01:26,  2.10it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:10<01:25,  2.11it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:11<01:25,  2.11it/s]Progress: 43.00%
---- avg training fps: 6.69# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:11<01:25,  2.11it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:11<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:12<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:12<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:13<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:13<01:22,  2.11it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:14<01:22,  2.11it/s]Progress: 45.00%
---- avg training fps: 6.75# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:14<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:15<01:21,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:15<01:20,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:16<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:16<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:16<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:16<01:19,  2.11it/s]Progress: 47.00%
---- avg training fps: 6.82# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:17<01:19,  2.11it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:17<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:18<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:18<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:19<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:19<01:16,  2.11it/s]Progress: 49.00%
---- avg training fps: 6.87# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:20<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:20<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:21<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:21<01:15,  2.11it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:21<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:22<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:22<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 6.93# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:23<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:23<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:24<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:24<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:25<01:10,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:25<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 6.98# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:25<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:25<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:30<04:01,  1.63s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:31<03:20,  1.37s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:31<02:39,  1.10s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:31<02:11,  1.10it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:32<01:51,  1.29it/s]Progress: 55.00%
---- avg training fps: 6.72# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:32<01:37,  1.47it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:33<01:27,  1.62it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:33<01:20,  1.75it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:34<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:34<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:34<01:11,  1.94it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:35<01:08,  2.00it/s]Progress: 57.00%
---- avg training fps: 6.77# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:35<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:36<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:36<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:37<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:37<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:38<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 6.82# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:38<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:38<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:39<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:39<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:39<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:40<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:40<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 6.87# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:41<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:41<00:57,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:42<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:42<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:43<00:56,  2.15it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:43<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 6.92# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:44<00:55,  2.15it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:44<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:44<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:44<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:45<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:45<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:46<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 6.97# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:46<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:47<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:47<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:48<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:48<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:48<00:50,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:49<00:49,  2.16it/s]Progress: 67.00%
---- avg training fps: 7.01# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:49<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:50<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:50<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:50<00:48,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:51<00:47,  2.15it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:51<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.05# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:52<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:52<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:53<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:53<00:46,  2.15it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:57<02:48,  1.72s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:58<02:10,  1.34s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:58<01:43,  1.08s/it]Progress: 71.00%
---- avg training fps: 6.84# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:59<01:25,  1.12it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:59<01:12,  1.30it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [02:00<01:02,  1.48it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [02:00<00:56,  1.63it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:01<00:51,  1.76it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:01<00:48,  1.86it/s]Progress: 73.00%
---- avg training fps: 6.88# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:02<00:48,  1.86it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:02<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:02<00:44,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:03<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:03<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:04<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:04<00:39,  2.10it/s]Progress: 75.00%
---- avg training fps: 6.92# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:04<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:05<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:05<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:06<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:06<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:06<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:07<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 6.95# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:07<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:08<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:08<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:09<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:09<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:10<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 6.99# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:10<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:11<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:11<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:11<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:11<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:12<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:12<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.02# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:13<00:30,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:13<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:14<00:29,  2.15it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:14<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:15<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:15<00:27,  2.15it/s]Progress: 83.00%
---- avg training fps: 7.05# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:16<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:16<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:16<00:27,  2.15it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:17<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:17<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:18<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:18<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.08# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:18<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:19<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:19<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:20<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:20<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:20<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:25<01:21,  1.71s/it]Progress: 87.00%
---- avg training fps: 6.91# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:25<01:02,  1.33s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:26<00:49,  1.07s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:26<00:40,  1.12it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:27<00:33,  1.31it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:27<00:29,  1.48it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:28<00:25,  1.63it/s]Progress: 89.00%
---- avg training fps: 6.94# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:28<00:23,  1.76it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:29<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:29<00:20,  1.94it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:30<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:30<00:18,  2.04it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:31<00:17,  2.07it/s]Progress: 91.00%
---- avg training fps: 6.97# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:31<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:31<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:32<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:32<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:33<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:33<00:14,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.00# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:34<00:14,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:34<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:34<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:35<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:35<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:36<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:36<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.03# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:37<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:37<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:38<00:09,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:38<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:38<00:09,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:38<00:08,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:39<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.06# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:39<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:40<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:40<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:41<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:41<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:42<00:05,  2.14it/s]Progress: 99.00%
---- avg training fps: 7.08# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:42<00:05,  2.14it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:43<00:04,  2.14it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:44<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:44<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:44<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.11# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:45<00:02,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:45<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:46<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:46<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:47<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:47<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.13Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.91it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.49it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.48it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.47it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.47it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.47it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.46it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.46it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.46it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.46it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.45it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.45it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.44it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.44it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.44it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.43it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.43it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.43it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.43it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.42it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.41it/s][A100%|██████████| 30/30 [00:08<00:00,  3.47it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.50it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.47it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.45it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.43it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.42it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.41it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.40it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.40it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.39it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.38it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.81it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.29it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.29it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.29it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:06<00:00,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 04:35:58.102812: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:35:58.198016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:35:58.198062: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:35:58.217448: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:35:58.618664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:35:58.618744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:35:58.618753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_04-36-00-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723516560.4454093 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 10266.83it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 12.44it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  6.99it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.71it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.90it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_04-36-00-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.37it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.59it/s] 20%|██        | 2/10 [00:00<00:01,  4.50it/s] 30%|███       | 3/10 [00:00<00:01,  4.74it/s] 40%|████      | 4/10 [00:00<00:01,  4.85it/s] 50%|█████     | 5/10 [00:01<00:01,  4.78it/s] 60%|██████    | 6/10 [00:01<00:00,  4.80it/s] 70%|███████   | 7/10 [00:01<00:00,  4.98it/s] 80%|████████  | 8/10 [00:01<00:00,  5.06it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.05it/s]100%|██████████| 10/10 [00:02<00:00,  4.88it/s]100%|██████████| 10/10 [00:02<00:00,  4.82it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7037.13it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:50,  2.98s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:22,  3.30s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:55,  2.01s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:54,  1.40s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:14,  1.06s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:14,  1.16it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.71# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:36,  1.36it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:10,  1.53it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:54,  1.67it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:42,  1.79it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:42,  1.79it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:34,  1.87it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:29,  1.93it/s]Progress: 7.00%
---- avg training fps: 4.10# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:24,  1.98it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:21,  2.02it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:19,  2.04it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:16,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:15,  2.08it/s]Progress: 9.00%
---- avg training fps: 4.94# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:14,  2.09it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:14,  2.09it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:13,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:11,  2.10it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:10,  2.11it/s]Progress: 11.00%
---- avg training fps: 5.52# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:10,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:09,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:09,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:08,  2.11it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:08,  2.11it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:07,  2.11it/s]Progress: 13.00%
---- avg training fps: 5.93# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:06,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:05,  2.11it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:05,  2.11it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:04,  2.11it/s]Progress: 15.00%
---- avg training fps: 6.19# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:19,  1.89it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:14,  1.95it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:11,  1.99it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:08,  2.03it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:08,  2.03it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:06,  2.05it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:04,  2.07it/s]Progress: 17.00%
---- avg training fps: 6.43# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:03,  2.08it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:02,  2.09it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<02:01,  2.10it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<02:00,  2.10it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<02:00,  2.11it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:59,  2.11it/s]Progress: 19.00%
---- avg training fps: 6.63# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:59,  2.11it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:58,  2.11it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:58,  2.11it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:58,  2.10it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<05:47,  1.40s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:37,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:48,  1.08it/s]Progress: 21.00%
---- avg training fps: 6.19# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:14,  1.26it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:50,  1.43it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:33,  1.58it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:21,  1.71it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:12,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:07,  1.88it/s]Progress: 23.00%
---- avg training fps: 6.36# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:07,  1.88it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<02:03,  1.94it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<01:59,  1.99it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:57,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<01:54,  2.05it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:53,  2.07it/s]Progress: 25.00%
---- avg training fps: 6.50# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:52,  2.08it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:51,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:50,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:49,  2.10it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:48,  2.11it/s]Progress: 27.00%
---- avg training fps: 6.63# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:47,  2.10it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<02:00,  1.88it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:55,  1.94it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:52,  1.99it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:49,  2.03it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:48,  2.05it/s]Progress: 29.00%
---- avg training fps: 6.71# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:46,  2.07it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:45,  2.09it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:45,  2.09it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:44,  2.10it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:43,  2.11it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:41,  2.12it/s]Progress: 31.00%
---- avg training fps: 6.81# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:38,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.91# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:38,  2.14it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:35,  2.14it/s]Progress: 35.00%
---- avg training fps: 6.99# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:59<04:13,  1.28s/it]Progress: 37.00%
---- avg training fps: 6.75# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:00<03:24,  1.04s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:00<02:50,  1.15it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:01<02:26,  1.33it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:01<02:09,  1.50it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:02<01:57,  1.65it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:02<01:48,  1.77it/s]Progress: 39.00%
---- avg training fps: 6.83# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:03<01:42,  1.86it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:03<01:38,  1.93it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:04<01:38,  1.93it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:04<01:35,  1.98it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:04<01:32,  2.02it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:05<01:31,  2.05it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:05<01:30,  2.06it/s]Progress: 41.00%
---- avg training fps: 6.90# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:06<01:28,  2.08it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:06<01:27,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:07<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:07<01:26,  2.11it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:08<01:25,  2.11it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:08<01:35,  1.89it/s]Progress: 43.00%
---- avg training fps: 6.94# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:09<01:35,  1.89it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:09<01:31,  1.96it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:09<01:29,  2.00it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:10<01:27,  2.03it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:10<01:25,  2.06it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:11<01:23,  2.08it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:11<01:22,  2.10it/s]Progress: 45.00%
---- avg training fps: 7.00# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:11<01:22,  2.11it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:12<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:12<01:21,  2.10it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:13<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:13<01:20,  2.11it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:13<01:19,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:14<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.06# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:14<01:18,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:15<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:15<01:17,  2.13it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:16<01:16,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:16<01:16,  2.13it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:17<01:15,  2.14it/s]Progress: 49.00%
---- avg training fps: 7.11# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:17<01:15,  2.13it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:18<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:18<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:18<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:19<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:19<01:13,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:19<01:13,  2.13it/s]Progress: 51.00%
---- avg training fps: 7.16# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:20<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:20<01:12,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:21<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:21<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:22<01:10,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:22<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.21# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:23<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:23<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:27<03:42,  1.50s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:27<02:55,  1.19s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:28<02:22,  1.03it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:28<01:59,  1.22it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:29<01:43,  1.39it/s]Progress: 55.00%
---- avg training fps: 6.97# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:29<01:31,  1.56it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:29<01:23,  1.69it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:30<01:18,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:30<01:13,  1.89it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:31<01:13,  1.89it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:31<01:10,  1.96it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:31<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.02# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:32<01:07,  2.04it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:32<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:33<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:33<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:34<01:03,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:34<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.06# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:35<01:02,  2.11it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:35<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:36<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:36<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:36<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:37<00:59,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:37<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 7.11# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:37<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:38<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:38<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:39<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:39<00:56,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:40<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 7.15# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:40<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:40<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:41<00:55,  2.13it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:41<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:42<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:42<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:43<00:53,  2.13it/s]Progress: 65.00%
---- avg training fps: 7.18# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:43<00:53,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:44<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:44<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:45<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:45<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:45<00:51,  2.13it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:45<00:50,  2.13it/s]Progress: 67.00%
---- avg training fps: 7.22# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:46<00:50,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:46<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:47<00:49,  2.13it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:47<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:48<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:48<00:47,  2.13it/s]Progress: 69.00%
---- avg training fps: 7.25# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:49<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:49<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:50<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:50<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:53<02:19,  1.42s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:54<01:50,  1.14s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:54<01:29,  1.07it/s]Progress: 71.00%
---- avg training fps: 7.07# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:55<01:23,  1.14it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:55<01:11,  1.32it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:56<01:02,  1.50it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:56<00:55,  1.65it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:57<00:51,  1.77it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:57<00:48,  1.87it/s]Progress: 73.00%
---- avg training fps: 7.10# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:58<00:48,  1.87it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:58<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:58<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:59<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:59<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:00<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:00<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.14# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:01<00:39,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:01<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:02<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:02<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:02<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:02<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:03<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.17# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:03<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:04<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:04<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:05<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:05<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:06<00:33,  2.14it/s]Progress: 79.00%
---- avg training fps: 7.20# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:06<00:33,  2.14it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:07<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:07<00:32,  2.15it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:07<00:32,  2.14it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:08<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:08<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:09<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.23# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:09<00:30,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:09<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:10<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:10<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:11<00:28,  2.14it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:11<00:28,  2.14it/s]Progress: 83.00%
---- avg training fps: 7.26# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:12<00:28,  2.14it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:12<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:12<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:13<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:13<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:14<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:14<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.28# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:15<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:15<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:16<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:16<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:16<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:16<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:21<01:13,  1.54s/it]Progress: 87.00%
---- avg training fps: 7.12# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:21<00:57,  1.22s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:21<00:45,  1.01it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:22<00:37,  1.19it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:22<00:32,  1.37it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:23<00:27,  1.54it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:23<00:25,  1.68it/s]Progress: 89.00%
---- avg training fps: 7.15# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:24<00:22,  1.79it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:24<00:21,  1.88it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:25<00:21,  1.88it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:25<00:19,  1.95it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:25<00:18,  2.01it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:26<00:18,  2.04it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:26<00:17,  2.06it/s]Progress: 91.00%
---- avg training fps: 7.18# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:27<00:16,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:27<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:28<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:28<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:28<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:29<00:14,  2.12it/s]Progress: 93.00%
---- avg training fps: 7.20# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:29<00:14,  2.12it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:29<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:30<00:13,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:30<00:12,  2.12it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:31<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:31<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:32<00:11,  2.12it/s]Progress: 95.00%
---- avg training fps: 7.23# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:32<00:10,  2.12it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:33<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:33<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:34<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:34<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:34<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:35<00:08,  2.12it/s]Progress: 97.00%
---- avg training fps: 7.25# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:35<00:08,  2.12it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:36<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:36<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:36<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:37<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:37<00:05,  2.13it/s]Progress: 99.00%
---- avg training fps: 7.27# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:38<00:05,  2.13it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:38<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:39<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:39<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:39<00:03,  2.11it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:40<00:03,  2.11it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:40<00:02,  2.11it/s]Progress: 100.00%
---- avg training fps: 7.29# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:41<00:02,  2.11it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:41<00:01,  2.11it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:42<00:01,  2.11it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:42<00:00,  2.11it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:43<00:00,  2.12it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:43<00:00,  2.11it/s]Progress: 100.00%
---- avg training fps: 7.31Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.48it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.47it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.48it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.47it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.47it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.46it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.46it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.46it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.45it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.45it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.44it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.44it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.44it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.43it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.43it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.43it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.43it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.42it/s][A100%|██████████| 30/30 [00:08<00:00,  3.48it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.93it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.52it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.48it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.45it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.44it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.41it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.40it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.40it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.39it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.38it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.38it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.37it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.35it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.64it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:02<00:00,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 04:40:36.590835: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:40:36.694977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:40:36.695017: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:40:36.714290: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:40:37.117061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:40:37.117142: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:40:37.117151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23134 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_04-40-38-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723516838.9218578 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 11022.29it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.81it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.71it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.86it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.19it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_04-40-38-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 76260.07it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.68it/s] 20%|██        | 2/10 [00:00<00:02,  3.57it/s] 30%|███       | 3/10 [00:00<00:01,  4.26it/s] 40%|████      | 4/10 [00:00<00:01,  4.48it/s] 50%|█████     | 5/10 [00:01<00:01,  4.67it/s] 60%|██████    | 6/10 [00:01<00:00,  4.85it/s] 70%|███████   | 7/10 [00:01<00:00,  4.80it/s] 80%|████████  | 8/10 [00:01<00:00,  4.94it/s] 90%|█████████ | 9/10 [00:01<00:00,  4.83it/s]100%|██████████| 10/10 [00:02<00:00,  5.01it/s]100%|██████████| 10/10 [00:02<00:00,  4.62it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike scenes.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak standing in front of a building.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a camel in front of a mountain.
- In the style of TOK, a man standing on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress is walking through an archway.
- In the style of TOK, a person standing on top of a body of water.
- In the style of TOK, a person walking in the desert with a dog on a leash.
- In the style of TOK, a person walking on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike scenes.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10152.01it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person standin...
3     in the style of <s0><s1><s2>, a person walking...
4     in the style of <s0><s1><s2>, a man standing o...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person standin...
8     in the style of <s0><s1><s2>, a person walking...
9     in the style of <s0><s1><s2>, a person walking...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person standin...
13    in the style of <s0><s1><s2>, a person walking...
14    in the style of <s0><s1><s2>, a man standing o...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person standin...
18    in the style of <s0><s1><s2>, a person walking...
19    in the style of <s0><s1><s2>, a person walking...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person standin...
23    in the style of <s0><s1><s2>, a person walking...
24    in the style of <s0><s1><s2>, a man standing o...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person standin...
28    in the style of <s0><s1><s2>, a person walking...
29    in the style of <s0><s1><s2>, a person walking...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person standin...
33    in the style of <s0><s1><s2>, a person walking...
34    in the style of <s0><s1><s2>, a man standing o...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person standin...
38    in the style of <s0><s1><s2>, a person walking...
39    in the style of <s0><s1><s2>, a person walking...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:30,  2.91s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:18,  3.89s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<11:29,  2.32s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:49,  1.59s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:48,  1.18s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:35,  1.07it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.45# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:48,  1.28it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:18,  1.47it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:57,  1.64it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:33,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:27,  1.95it/s]Progress: 7.00%
---- avg training fps: 3.76# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:40,  1.79it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:31,  1.89it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:24,  1.97it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:16,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.64# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:12,  2.12it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:09,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:07,  2.16it/s]Progress: 11.00%
---- avg training fps: 5.25# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:07,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:06,  2.16it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.16it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:04,  2.16it/s]Progress: 13.00%
---- avg training fps: 5.70# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:04,  2.16it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:04,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:03,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:03,  2.17it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:02,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:01,  2.17it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:01,  2.17it/s]Progress: 15.00%
---- avg training fps: 6.04# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:01,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:00,  2.17it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:59,  2.17it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:58,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.32# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:58,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:57,  2.17it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.54# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:55,  2.17it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:55,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:54,  2.17it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:21,  1.54s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<05:00,  1.22s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:03,  1.01it/s]Progress: 21.00%
---- avg training fps: 6.05# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:24,  1.20it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:56,  1.39it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:36,  1.55it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:22,  1.69it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:13,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]Progress: 23.00%
---- avg training fps: 6.23# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:01,  1.97it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<01:57,  2.03it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:54,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:52,  2.09it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:51,  2.11it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:50,  2.13it/s]Progress: 25.00%
---- avg training fps: 6.39# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:48,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:47,  2.14it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:46,  2.15it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:45,  2.15it/s]Progress: 27.00%
---- avg training fps: 6.53# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:45,  2.15it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:44,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:44,  2.16it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:43,  2.16it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.15it/s]Progress: 29.00%
---- avg training fps: 6.66# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:42,  2.15it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:42,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:40,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:40,  2.16it/s]Progress: 31.00%
---- avg training fps: 6.77# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:39,  2.16it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:39,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:37,  2.16it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:37,  2.16it/s]Progress: 33.00%
---- avg training fps: 6.87# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:37,  2.16it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:36,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:36,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:35,  2.16it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:35,  2.16it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:34,  2.17it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.96# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:33,  2.16it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:32,  2.16it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:31,  2.16it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.04# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:57<01:31,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:30,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:58<01:30,  2.16it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:29,  2.16it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:59<01:29,  2.15it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:29,  2.15it/s]Progress: 39.00%
---- avg training fps: 7.11# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:28,  2.15it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:28,  2.15it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:28,  2.15it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:28,  2.14it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:27,  2.15it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:26,  2.15it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:26,  2.16it/s]Progress: 41.00%
---- avg training fps: 7.18# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:25,  2.16it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:25,  2.16it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:04<01:24,  2.15it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:23,  2.16it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:05<01:23,  2.16it/s]Progress: 43.00%
---- avg training fps: 7.24# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:23,  2.16it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:23,  2.16it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:06<01:22,  2.16it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:21,  2.16it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:07<01:21,  2.16it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:21,  2.16it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:20,  2.16it/s]Progress: 45.00%
---- avg training fps: 7.29# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:20,  2.16it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:19,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:19,  2.15it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:10<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:10<01:18,  2.16it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:11<01:17,  2.16it/s]Progress: 47.00%
---- avg training fps: 7.34# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:11<01:17,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:12<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:16,  2.16it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:13<01:15,  2.16it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:15,  2.16it/s]Progress: 49.00%
---- avg training fps: 7.39# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:14<01:14,  2.16it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:15<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:15<01:13,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:13,  2.16it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:16<01:12,  2.16it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:12,  2.16it/s]Progress: 51.00%
---- avg training fps: 7.44# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:11,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:17<01:11,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:18<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:09,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:19<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.48# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:09,  2.16it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:24<04:08,  1.68s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:25<03:13,  1.31s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:25<02:34,  1.06s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<02:07,  1.14it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:48,  1.32it/s]Progress: 55.00%
---- avg training fps: 7.17# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:35,  1.50it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:25,  1.65it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:19,  1.78it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:14,  1.88it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:28<01:14,  1.88it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:28<01:11,  1.95it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:08,  2.01it/s]Progress: 57.00%
---- avg training fps: 7.21# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:29<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:30<01:04,  2.10it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:31<01:03,  2.12it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:31<01:02,  2.13it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.25# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:01,  2.14it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:00,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<00:59,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:34<00:58,  2.15it/s]Progress: 61.00%
---- avg training fps: 7.29# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:58,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:35<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:57,  2.15it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:36<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:37<00:56,  2.16it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:37<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.33# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:38<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:38<00:55,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:39<00:54,  2.16it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:53,  2.16it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:52,  2.16it/s]Progress: 65.00%
---- avg training fps: 7.37# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:40<00:52,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:51,  2.15it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:41<00:51,  2.16it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:42<00:51,  2.16it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:42<00:51,  2.16it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:42<00:50,  2.15it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:43<00:50,  2.16it/s]Progress: 67.00%
---- avg training fps: 7.40# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:43<00:49,  2.15it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:44<00:49,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:44<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:45<00:48,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:45<00:47,  2.16it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:46<00:47,  2.15it/s]Progress: 69.00%
---- avg training fps: 7.43# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:46,  2.16it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:46,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:45,  2.16it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:48,  1.72s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:52<02:10,  1.35s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:43,  1.08s/it]Progress: 71.00%
---- avg training fps: 7.19# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:25,  1.12it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:53<01:11,  1.31it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<01:02,  1.48it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:54<00:56,  1.63it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:51,  1.76it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:55<00:48,  1.86it/s]Progress: 73.00%
---- avg training fps: 7.22# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:48,  1.86it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:56<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:57<00:41,  2.07it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:58<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:39,  2.12it/s]Progress: 75.00%
---- avg training fps: 7.25# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:38,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:37,  2.14it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:00<00:37,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:00<00:36,  2.15it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:01<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.29# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:01<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:02<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:02<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:34,  2.16it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:03<00:33,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:04<00:33,  2.16it/s]Progress: 79.00%
---- avg training fps: 7.32# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:31,  2.17it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:06<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:06<00:30,  2.17it/s]Progress: 81.00%
---- avg training fps: 7.34# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:07<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:07<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:08<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:08<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:09<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:09<00:27,  2.16it/s]Progress: 83.00%
---- avg training fps: 7.37# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:10<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:10<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:10<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:11<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:12<00:25,  2.17it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:12<00:24,  2.17it/s]Progress: 85.00%
---- avg training fps: 7.40# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:12<00:24,  2.17it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:13<00:23,  2.17it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:13<00:23,  2.17it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:14<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:14<00:23,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:14<00:22,  2.17it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:15<00:22,  2.17it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.43# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:15<00:21,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:16<00:21,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:16<00:20,  2.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:17<00:20,  2.17it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:17<00:19,  2.17it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:18<00:19,  2.17it/s]Progress: 89.00%
---- avg training fps: 7.45# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:18<00:18,  2.17it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:18<00:18,  2.17it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:19<00:18,  2.17it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:19<00:17,  2.17it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:19<00:17,  2.17it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:20<00:17,  2.16it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:20<00:16,  2.16it/s]Progress: 91.00%
---- avg training fps: 7.47# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:21<00:16,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:21<00:15,  2.16it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:22<00:15,  2.17it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:22<00:16,  1.91it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:23<00:15,  1.98it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:23<00:14,  2.03it/s]Progress: 93.00%
---- avg training fps: 7.49# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:24<00:14,  2.03it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:24<00:13,  2.07it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:24<00:13,  2.10it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:25<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:25<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:26<00:11,  2.16it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:26<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.51# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:27<00:10,  2.17it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:27<00:10,  2.17it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:27<00:09,  2.17it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:28<00:09,  2.17it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:28<00:08,  2.18it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:29<00:08,  2.18it/s]Progress: 97.00%
---- avg training fps: 7.53# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:29<00:07,  2.18it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:30<00:07,  2.18it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:30<00:06,  2.18it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:31<00:06,  2.18it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:31<00:05,  2.18it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:32<00:05,  2.18it/s]Progress: 99.00%
---- avg training fps: 7.55# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:32<00:05,  2.18it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:32<00:04,  2.19it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:33<00:04,  2.19it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:33<00:04,  2.19it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:33<00:03,  2.18it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:34<00:03,  2.18it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:34<00:02,  2.18it/s]Progress: 100.00%
---- avg training fps: 7.57# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:35<00:02,  2.18it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:35<00:01,  2.18it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:36<00:01,  2.18it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:36<00:00,  2.18it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:37<00:00,  2.18it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:37<00:00,  2.18it/s]Progress: 100.00%
---- avg training fps: 7.59Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.98it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.50it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.49it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.49it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.47it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.47it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.46it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.46it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.46it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.45it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.45it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.45it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.44it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.44it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.44it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.43it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.43it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.43it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.43it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.42it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.42it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.42it/s][A100%|██████████| 30/30 [00:08<00:00,  3.47it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.56it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.51it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.47it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.45it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.43it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.42it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.40it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.39it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.39it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.38it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.38it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.37it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.38it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.35it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.35it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.82it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:56<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 04:44:59.327115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:44:59.418338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:44:59.418363: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:44:59.436873: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:44:59.837186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:44:59.837264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:44:59.837273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/journey_small' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.5 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='journey_small' output_dir='lora_models/styles_final/journey_small_13_04-45-01-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723517101.6154902 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 54181.74it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.67it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.74it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.84it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.15it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/journey_small_13_04-45-01-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 0.812
New train_img_size: [448, 576]
Validation_img_size was set to: [896, 1152]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 199728.76it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:03,  2.65it/s] 20%|██        | 2/10 [00:00<00:02,  3.52it/s] 30%|███       | 3/10 [00:00<00:01,  4.13it/s] 40%|████      | 4/10 [00:00<00:01,  4.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.58it/s] 60%|██████    | 6/10 [00:01<00:00,  4.78it/s] 70%|███████   | 7/10 [00:01<00:00,  4.76it/s] 80%|████████  | 8/10 [00:01<00:00,  4.91it/s] 90%|█████████ | 9/10 [00:01<00:00,  4.89it/s]100%|██████████| 10/10 [00:02<00:00,  5.04it/s]100%|██████████| 10/10 [00:02<00:00,  4.59it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red cloak standing in front of a building.
- A person standing on top of a body of water.
- A person walking in the desert with a camel in front of a mountain.
- A man standing on top of a sandy beach next to the ocean.
- A sunset over a desert landscape with a mountain in the background.
- A woman in a red dress is walking through an archway.
- A person standing on top of a body of water.
- A person walking in the desert with a dog on a leash.
- A person walking on a beach next to a body of water.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal and dreamlike, focus on vastness.

- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red cloak stands in front of a building.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a camel in front of a mountain.
- In the style of TOK, a man stands on top of a sandy beach next to the ocean.
- In the style of TOK, a sunset over a desert landscape with a mountain in the background.
- In the style of TOK, a woman in a red dress walks through an archway.
- In the style of TOK, a person stands on top of a body of water.
- In the style of TOK, a person walks in the desert with a dog on a leash.
- In the style of TOK, a person walks on a beach next to a body of water.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal and dreamlike, focus on vastness.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 10123.83it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a sunset over a ...
1     in the style of <s0><s1><s2>, a woman in a red...
2     in the style of <s0><s1><s2>, a person stands ...
3     in the style of <s0><s1><s2>, a person walks i...
4     in the style of <s0><s1><s2>, a man stands on ...
5     in the style of <s0><s1><s2>, a sunset over a ...
6     in the style of <s0><s1><s2>, a woman in a red...
7     in the style of <s0><s1><s2>, a person stands ...
8     in the style of <s0><s1><s2>, a person walks i...
9     in the style of <s0><s1><s2>, a person walks o...
10    in the style of <s0><s1><s2>, a sunset over a ...
11    in the style of <s0><s1><s2>, a woman in a red...
12    in the style of <s0><s1><s2>, a person stands ...
13    in the style of <s0><s1><s2>, a person walks i...
14    in the style of <s0><s1><s2>, a man stands on ...
15    in the style of <s0><s1><s2>, a sunset over a ...
16    in the style of <s0><s1><s2>, a woman in a red...
17    in the style of <s0><s1><s2>, a person stands ...
18    in the style of <s0><s1><s2>, a person walks i...
19    in the style of <s0><s1><s2>, a person walks o...
20    in the style of <s0><s1><s2>, a sunset over a ...
21    in the style of <s0><s1><s2>, a woman in a red...
22    in the style of <s0><s1><s2>, a person stands ...
23    in the style of <s0><s1><s2>, a person walks i...
24    in the style of <s0><s1><s2>, a man stands on ...
25    in the style of <s0><s1><s2>, a sunset over a ...
26    in the style of <s0><s1><s2>, a woman in a red...
27    in the style of <s0><s1><s2>, a person stands ...
28    in the style of <s0><s1><s2>, a person walks i...
29    in the style of <s0><s1><s2>, a person walks o...
30    in the style of <s0><s1><s2>, a sunset over a ...
31    in the style of <s0><s1><s2>, a woman in a red...
32    in the style of <s0><s1><s2>, a person stands ...
33    in the style of <s0><s1><s2>, a person walks i...
34    in the style of <s0><s1><s2>, a man stands on ...
35    in the style of <s0><s1><s2>, a sunset over a ...
36    in the style of <s0><s1><s2>, a woman in a red...
37    in the style of <s0><s1><s2>, a person stands ...
38    in the style of <s0><s1><s2>, a person walks i...
39    in the style of <s0><s1><s2>, a person walks o...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:37,  2.94s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:07<19:28,  3.92s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<11:35,  2.34s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:08<07:53,  1.60s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:50,  1.19s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:09<04:37,  1.06it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.43# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:50,  1.27it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:10<03:19,  1.46it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:59,  1.63it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:11<02:44,  1.76it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:44,  1.76it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:35,  1.86it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:12<02:29,  1.93it/s]Progress: 7.00%
---- avg training fps: 3.73# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:41,  1.78it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:13<02:32,  1.88it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:13<02:25,  1.95it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:14<02:21,  2.01it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:14<02:17,  2.05it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:15<02:15,  2.08it/s]Progress: 9.00%
---- avg training fps: 4.60# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:15<02:13,  2.10it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:16<02:12,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:16<02:12,  2.12it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:16<02:11,  2.13it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:17<02:10,  2.13it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:17<02:09,  2.13it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:08,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.21# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:18<02:08,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:19<02:07,  2.15it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:06,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:20<02:05,  2.15it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:05,  2.15it/s]Progress: 13.00%
---- avg training fps: 5.66# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:21<02:05,  2.15it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:21<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:04,  2.16it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:23<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 6.00# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:24<02:02,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:01,  2.15it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:00,  2.16it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:26<01:59,  2.16it/s]Progress: 17.00%
---- avg training fps: 6.27# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:27<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:28<01:58,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:57,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:29<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.49# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:56,  2.16it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.16it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:34<06:20,  1.53s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:59,  1.21s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:35<04:03,  1.01it/s]Progress: 21.00%
---- avg training fps: 6.01# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:23,  1.20it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:36<02:56,  1.39it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:36,  1.55it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:37<02:23,  1.69it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:13,  1.81it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]Progress: 23.00%
---- avg training fps: 6.20# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:06,  1.90it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:01,  1.96it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:39<01:58,  2.02it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<01:55,  2.05it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:40<01:53,  2.08it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:41<01:50,  2.11it/s]Progress: 25.00%
---- avg training fps: 6.36# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:47,  2.14it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:46,  2.14it/s]Progress: 27.00%
---- avg training fps: 6.50# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:44<01:46,  2.13it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:45<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:45,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:46<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.62# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:47<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:48<01:43,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:48<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:40,  2.14it/s]Progress: 31.00%
---- avg training fps: 6.73# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:39,  2.14it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:38,  2.14it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:52<01:37,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.83# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:55<01:34,  2.15it/s]Progress: 35.00%
---- avg training fps: 6.92# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:34,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:33,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:33,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:33,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:32,  2.14it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:01<05:32,  1.68s/it]Progress: 37.00%
---- avg training fps: 6.54# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:02<04:19,  1.32s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:02<03:28,  1.06s/it]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:03<02:52,  1.13it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:03<02:27,  1.32it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:04<02:09,  1.49it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:04<01:56,  1.64it/s]Progress: 39.00%
---- avg training fps: 6.63# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:05<01:48,  1.76it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:05<01:41,  1.87it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:06<01:41,  1.87it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:06<01:37,  1.94it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:06<01:34,  2.00it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:07<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:07<01:30,  2.07it/s]Progress: 41.00%
---- avg training fps: 6.71# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:07<01:28,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:08<01:27,  2.10it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:08<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:09<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:09<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:10<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 6.78# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:10<01:24,  2.13it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:10<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:11<01:23,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:11<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:12<01:22,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:12<01:21,  2.14it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:13<01:21,  2.14it/s]Progress: 45.00%
---- avg training fps: 6.85# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:13<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:14<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:14<01:19,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:14<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:15<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:15<01:18,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:15<01:18,  2.15it/s]Progress: 47.00%
---- avg training fps: 6.91# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:16<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:16<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:17<01:17,  2.14it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:17<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:18<01:16,  2.14it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:18<01:15,  2.15it/s]Progress: 49.00%
---- avg training fps: 6.97# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:19<01:15,  2.14it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:19<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:20<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:20<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:20<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:21<01:13,  2.14it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:21<01:12,  2.14it/s]Progress: 51.00%
---- avg training fps: 7.03# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:21<01:12,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:22<01:11,  2.14it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:22<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:23<01:11,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:23<01:10,  2.14it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:24<01:10,  2.14it/s]Progress: 53.00%
---- avg training fps: 7.08# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:24<01:10,  2.14it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:24<01:09,  2.14it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:29<04:09,  1.69s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:29<03:14,  1.32s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:30<02:35,  1.06s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:30<02:08,  1.13it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:31<01:49,  1.31it/s]Progress: 55.00%
---- avg training fps: 6.81# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:31<01:36,  1.49it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:32<01:26,  1.64it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:32<01:20,  1.76it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:33<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:33<01:15,  1.86it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:33<01:11,  1.93it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:34<01:09,  1.98it/s]Progress: 57.00%
---- avg training fps: 6.86# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:34<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:34<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:35<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:35<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:36<01:02,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:36<01:02,  2.12it/s]Progress: 59.00%
---- avg training fps: 6.91# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:37<01:01,  2.12it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:37<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:38<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:38<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:38<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:39<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:39<00:59,  2.13it/s]Progress: 61.00%
---- avg training fps: 6.95# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:40<00:58,  2.13it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:40<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:41<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:41<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:41<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:42<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.00# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:42<00:56,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:42<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:43<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:43<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:44<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:44<00:53,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:45<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.04# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:45<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:46<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:46<00:51,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:47<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:47<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:47<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:48<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.08# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:48<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:48<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:49<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:49<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:50<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:50<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.12# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:51<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:51<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:52<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:52<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:56<02:50,  1.74s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:57<02:11,  1.36s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:57<01:44,  1.09s/it]Progress: 71.00%
---- avg training fps: 6.90# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:58<01:25,  1.11it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:58<01:12,  1.30it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:59<01:03,  1.47it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:59<00:56,  1.63it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [02:00<00:51,  1.75it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [02:00<00:48,  1.86it/s]Progress: 73.00%
---- avg training fps: 6.94# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [02:01<00:48,  1.86it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [02:01<00:45,  1.94it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [02:01<00:44,  1.99it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:02<00:42,  2.03it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:02<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:02<00:40,  2.09it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:03<00:39,  2.10it/s]Progress: 75.00%
---- avg training fps: 6.97# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:03<00:39,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:04<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:04<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:05<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:05<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:05<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:06<00:36,  2.14it/s]Progress: 77.00%
---- avg training fps: 7.01# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:06<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:07<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:07<00:35,  2.14it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:08<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:08<00:34,  2.14it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:09<00:33,  2.12it/s]Progress: 79.00%
---- avg training fps: 7.04# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:09<00:33,  2.13it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:10<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:10<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:10<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:10<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:11<00:31,  2.14it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:11<00:30,  2.14it/s]Progress: 81.00%
---- avg training fps: 7.07# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:12<00:30,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:12<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:13<00:29,  2.14it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:13<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:14<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:14<00:28,  2.14it/s]Progress: 83.00%
---- avg training fps: 7.10# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:15<00:28,  2.14it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:15<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:15<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:16<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:16<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:17<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:17<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.13# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:17<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:18<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:18<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:19<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:19<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:19<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:24<01:17,  1.61s/it]Progress: 87.00%
---- avg training fps: 6.97# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:24<00:59,  1.26s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:25<00:47,  1.02s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:25<00:42,  1.06it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:26<00:35,  1.25it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:26<00:30,  1.43it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:27<00:26,  1.59it/s]Progress: 89.00%
---- avg training fps: 6.99# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:27<00:23,  1.73it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:28<00:21,  1.84it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:28<00:21,  1.84it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:28<00:20,  1.92it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:29<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:29<00:18,  2.04it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:29<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 7.02# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:30<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:30<00:16,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:31<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:31<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:32<00:14,  2.14it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:32<00:13,  2.15it/s]Progress: 93.00%
---- avg training fps: 7.05# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:33<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:33<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:33<00:13,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:34<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:34<00:12,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:35<00:11,  2.15it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:35<00:11,  2.16it/s]Progress: 95.00%
---- avg training fps: 7.08# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:35<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:36<00:10,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:36<00:09,  2.16it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:37<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:37<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:37<00:08,  2.16it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:38<00:08,  2.16it/s]Progress: 97.00%
---- avg training fps: 7.10# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:38<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:39<00:07,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:39<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:40<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:40<00:06,  2.16it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:41<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.13# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:41<00:05,  2.16it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:42<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:42<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:42<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:42<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:43<00:03,  2.16it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:43<00:02,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.16# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:44<00:02,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:44<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:45<00:01,  2.16it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:45<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:46<00:00,  2.16it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:46<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.18Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.96it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.56it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.53it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.47it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.47it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.47it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.47it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.47it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.47it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.47it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.47it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.47it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.47it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.47it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.47it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.47it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.47it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.46it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.46it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.46it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.45it/s][A100%|██████████| 30/30 [00:08<00:00,  3.49it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.70it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.53it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.50it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.48it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.46it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.45it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.44it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.44it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.42it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.42it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.42it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.42it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.42it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.41it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.41it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.41it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.41it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.41it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.40it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.40it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.40it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.40it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.40it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.40it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.40it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.39it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.39it/s][A100%|██████████| 30/30 [00:08<00:00,  3.45it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.49it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.45it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.41it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.40it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.40it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.39it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.38it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.38it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.37it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.36it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.41it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.84it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:04<00:00,  1.22it/s]
------------------------------------------
Training done :)
2024-08-13 04:49:31.563496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:49:31.655472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:49:31.655499: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:49:31.674981: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:49:32.076168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:49:32.076249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:49:32.076258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23135 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_04-49-33-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723517373.9091036 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 16714.29it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 18.68it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.77it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.85it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.18it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_04-49-33-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_04-49-33-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 437244.05it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1083695.77it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, the scene is Fort Kochi, Kerala, India.
- In the style of TOK, the phrase describes the best and worst of times.
- In the style of TOK, a blockchain is depicted using bees.
- In the style of TOK, a gorgon made of sharks is eating each other while swimming underwater.
- In the style of TOK, a hillside at sunset shows Venus and Earth circling the sun.
- In the style of TOK, there is an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is portrayed.
- In the style of TOK, the phrase exemplifies the age of wisdom and the age of foolishness.
- In the style of TOK, two people discuss quitting their boring corporation jobs together.
- In the style of TOK, petroglyphs are presented.
- In the style of TOK, a room and space exchange based on first and second-degree connections is depicted.
- In the style of TOK, the fear known as trypophobia is illustrated.
- In the style of TOK, there is a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing and singing beavers is highlighted.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam with patterns akin to Hawaiian shirts.
- In the style of TOK, a brigade of beavers is quickly building a dam with a Tarsem Singh-like flair.
- In the style of TOK, a brigade of beavers resembles M. C. Escher's artwork.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, there is a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to take a peek above water.

--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, Venus and Earth are circling the sun over a hillside at sunset.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness" is depicted visually.
- In the style of TOK, two characters are planning to quit their boring corporation job together.
- In the style of TOK, ancient petroglyphs are featured.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, the concept of trypophobia is illustrated.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is featured in an intricate pattern inspired by M.C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
- In the style of TOK, a mermaid made out of fishnets and other sea trash is swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi in Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is embodied in a visual representation.
- In the style of TOK, a blockchain is composed of bees.
- In the style of TOK, a gorgon made out of sharks is eating each other while swimming underwater.
- In the style of TOK, Venus and Earth are circling the sun over a hillside at sunset.
- In the style of TOK, an ancient temple is located deep in the Amazon jungle.
- In the style of TOK, cats are pooping in zero-gravity.
- In the style of TOK, a goblin goat is presented.
- In the style of TOK, the phrase "it was the age of wisdom, it was the age of foolishness" is depicted visually.
- In the style of TOK, two characters are planning to quit their boring corporation job together.
- In the style of TOK, ancient petroglyphs are featured.
- In the style of TOK, a room and space exchange is based on first and second-degree connections.
- In the style of TOK, the concept of trypophobia is illustrated.
- In the style of TOK, a six-pack of nightmare fuel is shown.
- In the style of TOK, a band of dancing and singing beavers is featured with a nod to Jim Henson's Muppets.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam, inspired by Tarsem Singh.
- In the style of TOK, a brigade of beavers is featured in an intricate pattern inspired by M.C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, is rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting showcases lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash is swimming up through the sea to take a peak above the water.
--------------------------
Making sure TOK is added to every training prompt...
Using GPT concept name as CLIP-segmentation prompt: Surrealistic, intricate, and fantastical scenes
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15518.49it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi in ke...
3     in the style of <s0><s1><s2>, the phrase "they...
4     in the style of <s0><s1><s2>, a blockchain is ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, venus and earth ...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats are pooping...
9     in the style of <s0><s1><s2>, a goblin goat is...
10    in the style of <s0><s1><s2>, the phrase "it w...
11    in the style of <s0><s1><s2>, two characters a...
12    in the style of <s0><s1><s2>, ancient petrogly...
13    in the style of <s0><s1><s2>, a room and space...
14    in the style of <s0><s1><s2>, the concept of t...
15    in the style of <s0><s1><s2>, a six-pack of ni...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver is chew...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle is movi...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show f...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi in ke...
30    in the style of <s0><s1><s2>, the phrase "they...
31    in the style of <s0><s1><s2>, a blockchain is ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, venus and earth ...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats are pooping...
36    in the style of <s0><s1><s2>, a goblin goat is...
37    in the style of <s0><s1><s2>, the phrase "it w...
38    in the style of <s0><s1><s2>, two characters a...
39    in the style of <s0><s1><s2>, ancient petrogly...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<14:58,  3.00s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<22:12,  4.47s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<13:04,  2.64s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:48,  1.78s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:26,  1.31s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<05:00,  1.02s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.22# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:06,  1.19it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:30,  1.39it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:07,  1.56it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:50,  1.70it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:39,  1.82it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:13<02:31,  1.90it/s]Progress: 7.00%
---- avg training fps: 3.52# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:25,  1.97it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:14<02:21,  2.02it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:21,  2.02it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:26,  1.95it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:15<02:22,  1.99it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:18,  2.04it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:16<02:16,  2.07it/s]Progress: 9.00%
---- avg training fps: 4.36# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:14,  2.09it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:12,  2.11it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:11,  2.12it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:10,  2.12it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:09,  2.13it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:09,  2.13it/s]Progress: 11.00%
---- avg training fps: 4.97# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:08,  2.14it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:07,  2.14it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:20<02:07,  2.14it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:07,  2.14it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:21<02:07,  2.14it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:21<02:01,  2.24it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:02,  2.21it/s]Progress: 13.00%
---- avg training fps: 5.44# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:22<02:03,  2.17it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:04,  2.16it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:23<02:03,  2.15it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:03,  2.16it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:03,  2.15it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:24<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 5.79# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:02,  2.15it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:25<02:02,  2.14it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:01,  2.15it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:26<02:01,  2.15it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<02:00,  2.15it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:27<01:59,  2.15it/s]Progress: 17.00%
---- avg training fps: 6.09# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:59,  2.15it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:54,  2.25it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:28<01:55,  2.21it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:56,  2.20it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:56,  2.17it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:29<01:56,  2.17it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.32# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:30<01:56,  2.15it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:56,  2.14it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:31<01:56,  2.14it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:35<05:57,  1.44s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:35<04:43,  1.15s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:52,  1.06it/s]Progress: 21.00%
---- avg training fps: 5.93# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:36<03:16,  1.25it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:51,  1.42it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:37<02:51,  1.42it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:37<02:28,  1.64it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:37<02:17,  1.76it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:38<02:09,  1.86it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:39<02:24,  1.66it/s]Progress: 23.00%
---- avg training fps: 6.08# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:39<02:14,  1.78it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:39<02:07,  1.87it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:40<02:01,  1.95it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:40<01:57,  2.01it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:41<01:54,  2.05it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:41<01:52,  2.09it/s]Progress: 25.00%
---- avg training fps: 6.25# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:42<01:50,  2.11it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:42<01:49,  2.12it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:43<01:48,  2.13it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:43<01:47,  2.13it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:44<01:47,  2.13it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:44<01:42,  2.24it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:44<01:43,  2.21it/s]Progress: 27.00%
---- avg training fps: 6.40# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:44<01:43,  2.19it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:45<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:45<01:43,  2.17it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:46<01:43,  2.16it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:46<01:43,  2.16it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:47<01:42,  2.16it/s]Progress: 29.00%
---- avg training fps: 6.53# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:47<01:42,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:48<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:48<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:49<01:41,  2.16it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:49<01:40,  2.15it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:50<01:40,  2.16it/s]Progress: 31.00%
---- avg training fps: 6.66# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:50<01:40,  2.16it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:50<01:35,  2.26it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:50<01:36,  2.23it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:51<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:51<01:36,  2.20it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:52<01:36,  2.19it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:52<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.76# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:53<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:53<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:54<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:54<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:55<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:55<01:34,  2.16it/s]Progress: 35.00%
---- avg training fps: 6.85# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:56<01:33,  2.16it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:56<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:56<01:33,  2.16it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:56<01:28,  2.26it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:57<01:29,  2.24it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:57<01:30,  2.21it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [01:00<03:58,  1.21s/it]Progress: 37.00%
---- avg training fps: 6.66# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [01:01<03:14,  1.02it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:01<02:42,  1.21it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:02<02:20,  1.39it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:02<02:04,  1.56it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:03<01:53,  1.70it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:03<01:46,  1.81it/s]Progress: 39.00%
---- avg training fps: 6.75# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:04<01:40,  1.90it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:04<01:36,  1.97it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:04<01:33,  2.02it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:05<01:31,  2.05it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:05<01:31,  2.05it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:05<01:25,  2.17it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:06<01:36,  1.93it/s]Progress: 41.00%
---- avg training fps: 6.81# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:06<01:33,  1.99it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:07<01:30,  2.03it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:07<01:28,  2.07it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:08<01:27,  2.09it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:08<01:25,  2.11it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:09<01:24,  2.13it/s]Progress: 43.00%
---- avg training fps: 6.88# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:09<01:23,  2.13it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:10<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:10<01:22,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:11<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:11<01:21,  2.15it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:12<01:20,  2.15it/s]Progress: 45.00%
---- avg training fps: 6.96# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:12<01:20,  2.15it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:12<01:16,  2.25it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:12<01:17,  2.21it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:13<01:17,  2.20it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:13<01:17,  2.19it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:14<01:17,  2.17it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:14<01:17,  2.17it/s]Progress: 47.00%
---- avg training fps: 7.02# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:15<01:17,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:15<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:16<01:16,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:16<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:17<01:15,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:17<01:14,  2.16it/s]Progress: 49.00%
---- avg training fps: 7.07# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:18<01:14,  2.16it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:18<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:18<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:18<01:10,  2.25it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:19<01:11,  2.22it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:19<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:20<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.13# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:20<01:11,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:21<01:11,  2.16it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:21<01:10,  2.16it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:22<01:10,  2.17it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:22<01:09,  2.16it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:23<01:09,  2.16it/s]Progress: 53.00%
---- avg training fps: 7.18# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:23<01:09,  2.15it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:28<04:27,  1.81s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:28<03:26,  1.41s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:29<02:43,  1.12s/it]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:29<02:43,  1.12s/it]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:29<02:11,  1.11it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:30<01:51,  1.29it/s]Progress: 55.00%
---- avg training fps: 6.88# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:30<01:37,  1.46it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:31<01:27,  1.62it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:31<01:20,  1.75it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:32<01:15,  1.86it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:32<01:11,  1.94it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:33<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.93# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:33<01:06,  2.05it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:34<01:05,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:34<01:04,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:34<01:03,  2.11it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:35<01:02,  2.12it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:35<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 6.98# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:36<01:01,  2.14it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:36<00:58,  2.25it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:36<00:58,  2.22it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:37<00:58,  2.20it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:37<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:38<00:58,  2.18it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:38<00:57,  2.18it/s]Progress: 61.00%
---- avg training fps: 7.03# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:39<00:57,  2.17it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:39<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:39<00:57,  2.16it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:40<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:40<00:56,  2.16it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:41<00:55,  2.16it/s]Progress: 63.00%
---- avg training fps: 7.07# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:41<00:55,  2.16it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:42<00:54,  2.16it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:42<00:54,  2.16it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:42<00:51,  2.27it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:43<00:51,  2.23it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:43<00:51,  2.21it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:44<00:51,  2.19it/s]Progress: 65.00%
---- avg training fps: 7.12# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:44<00:51,  2.19it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:44<00:51,  2.18it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:45<00:51,  2.17it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:45<00:50,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:46<00:50,  2.16it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:46<00:50,  2.16it/s]Progress: 67.00%
---- avg training fps: 7.16# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:47<00:49,  2.16it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:47<00:49,  2.16it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:48<00:48,  2.15it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:48<00:48,  2.16it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:49<00:48,  2.16it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:49<00:45,  2.26it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:49<00:46,  2.22it/s]Progress: 69.00%
---- avg training fps: 7.20# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:50<00:46,  2.19it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:50<00:45,  2.18it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:50<00:45,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:54<02:13,  1.36s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:54<01:46,  1.09s/it]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:55<01:26,  1.11it/s]Progress: 71.00%
---- avg training fps: 7.05# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:55<01:13,  1.29it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:56<01:04,  1.46it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:56<00:57,  1.63it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:57<00:52,  1.76it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:57<00:48,  1.86it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:58<00:46,  1.94it/s]Progress: 73.00%
---- avg training fps: 7.09# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:58<00:46,  1.94it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:58<00:42,  2.09it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:59<00:41,  2.10it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:59<00:40,  2.13it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:59<00:40,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [02:00<00:39,  2.14it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [02:00<00:39,  2.15it/s]Progress: 75.00%
---- avg training fps: 7.12# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [02:01<00:38,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [02:01<00:38,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [02:02<00:37,  2.15it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [02:02<00:37,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [02:03<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [02:03<00:36,  2.16it/s]Progress: 77.00%
---- avg training fps: 7.16# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:04<00:35,  2.15it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:04<00:35,  2.14it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:04<00:35,  2.14it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:04<00:33,  2.25it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:05<00:33,  2.21it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:05<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:06<00:32,  2.19it/s]Progress: 79.00%
---- avg training fps: 7.19# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:06<00:32,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:07<00:32,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:07<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:08<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:08<00:31,  2.16it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:09<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.22# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:09<00:30,  2.16it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:10<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:10<00:29,  2.15it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:11<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:11<00:28,  2.15it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:11<00:26,  2.29it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:11<00:26,  2.24it/s]Progress: 83.00%
---- avg training fps: 7.26# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:12<00:26,  2.21it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:12<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:13<00:26,  2.18it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:13<00:25,  2.18it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:14<00:25,  2.17it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:14<00:24,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.28# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:15<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:15<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:16<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:16<00:23,  2.16it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:16<00:22,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:20<01:11,  1.49s/it]Progress: 87.00%
---- avg training fps: 7.14# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:21<01:11,  1.49s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:21<00:54,  1.16s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:21<00:43,  1.05it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:22<00:36,  1.24it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:22<00:30,  1.42it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:23<00:27,  1.58it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:23<00:24,  1.73it/s]Progress: 89.00%
---- avg training fps: 7.17# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:24<00:22,  1.83it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:24<00:20,  1.91it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:24<00:19,  1.98it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:25<00:18,  2.03it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:25<00:17,  2.07it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:26<00:17,  2.08it/s]Progress: 91.00%
---- avg training fps: 7.19# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:26<00:16,  2.11it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:27<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:27<00:16,  2.12it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:27<00:14,  2.23it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:28<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:28<00:14,  2.18it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:29<00:13,  2.16it/s]Progress: 93.00%
---- avg training fps: 7.22# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:29<00:13,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:30<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:30<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:30<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:31<00:11,  2.16it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:31<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.25# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:32<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:32<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:33<00:09,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:33<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:34<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:34<00:08,  2.24it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:34<00:08,  2.20it/s]Progress: 97.00%
---- avg training fps: 7.27# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:35<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:35<00:07,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:36<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:36<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:36<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:37<00:05,  2.16it/s]Progress: 99.00%
---- avg training fps: 7.30# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:37<00:05,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:38<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:38<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:39<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:39<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:40<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.32# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:40<00:02,  2.14it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:40<00:02,  2.25it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:41<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:41<00:01,  2.20it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:41<00:00,  2.19it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:42<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:42<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.34# Trainer step: 294, epoch: 21: : 301it [02:43,  2.16it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.99it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.48it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.48it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.48it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.48it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.47it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.47it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.47it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.46it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.46it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.45it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.45it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.45it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.45it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.45it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.44it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.44it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.44it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.43it/s][A100%|██████████| 30/30 [00:08<00:00,  3.48it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.58it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.52it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.49it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.46it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.43it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.42it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.41it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.41it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.40it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.40it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.39it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.39it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.38it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.43it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.66it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.39it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.38it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.38it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.38it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.37it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.36it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.40it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.36it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.40it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [04:01,  1.24it/s]
------------------------------------------
Training done :)
2024-08-13 04:54:19.652070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:54:19.744774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:54:19.744800: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:54:19.763730: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:54:20.167274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:54:20.167330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:54:20.174189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23118 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.0 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_04-54-21-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723517661.9522135 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 31860.22it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.32it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.49it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.84it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_04-54-21-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.37it/s] 80%|████████  | 4/5 [00:02<00:00,  1.57it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.53it/s] 20%|██        | 2/10 [00:00<00:01,  4.44it/s] 30%|███       | 3/10 [00:00<00:01,  4.70it/s] 40%|████      | 4/10 [00:00<00:01,  4.81it/s] 50%|█████     | 5/10 [00:01<00:01,  4.75it/s] 60%|██████    | 6/10 [00:01<00:00,  4.77it/s] 70%|███████   | 7/10 [00:01<00:00,  4.97it/s] 80%|████████  | 8/10 [00:01<00:00,  5.03it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.03it/s]100%|██████████| 10/10 [00:02<00:00,  4.85it/s]100%|██████████| 10/10 [00:02<00:00,  4.79it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal blending of nature and technology

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is set against a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is situated on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is set against a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is shown in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Surreal blending of nature and technology
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 6925.58it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:01,  3.02s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:00,  3.42s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:16,  2.08s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:07,  1.44s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:22,  1.09s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:19,  1.13it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.64# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:38,  1.34it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:12,  1.52it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:54,  1.67it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:42,  1.78it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:33,  1.88it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:28,  1.94it/s]Progress: 7.00%
---- avg training fps: 4.03# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:24,  1.99it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:21,  2.02it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:19,  2.04it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:17,  2.06it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:16,  2.08it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:14,  2.10it/s]Progress: 9.00%
---- avg training fps: 4.88# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:13,  2.10it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:12,  2.11it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:11,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:10,  2.12it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:10,  2.12it/s]Progress: 11.00%
---- avg training fps: 5.46# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:09,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:08,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:07,  2.12it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:07,  2.12it/s]Progress: 13.00%
---- avg training fps: 5.88# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:07,  2.12it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:06,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:21,  1.89it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:15,  1.96it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:12,  2.00it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:09,  2.04it/s]Progress: 15.00%
---- avg training fps: 6.15# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:07,  2.06it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:05,  2.08it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:04,  2.09it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:03,  2.10it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:03,  2.10it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:02,  2.11it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:01,  2.12it/s]Progress: 17.00%
---- avg training fps: 6.40# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:01,  2.11it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<02:00,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:59,  2.12it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:59,  2.12it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:58,  2.12it/s]Progress: 19.00%
---- avg training fps: 6.60# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:58,  2.12it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:57,  2.12it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:57,  2.12it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:57,  2.12it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<06:08,  1.48s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:51,  1.18s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:58,  1.03it/s]Progress: 21.00%
---- avg training fps: 6.12# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:20,  1.22it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:54,  1.40it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:36,  1.56it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:23,  1.69it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:13,  1.80it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:07,  1.89it/s]Progress: 23.00%
---- avg training fps: 6.26# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:07,  1.89it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:16,  1.75it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<02:08,  1.85it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<02:02,  1.93it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<01:59,  1.98it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:56,  2.03it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:54,  2.05it/s]Progress: 25.00%
---- avg training fps: 6.42# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:52,  2.07it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:51,  2.09it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:42<01:50,  2.10it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:43<01:49,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:43<01:48,  2.11it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:47,  2.12it/s]Progress: 27.00%
---- avg training fps: 6.55# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:47,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:46,  2.12it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:44,  2.12it/s]Progress: 29.00%
---- avg training fps: 6.67# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:44,  2.12it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:43,  2.12it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:42,  2.12it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:49<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.77# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:51<01:39,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:38,  2.13it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:38,  2.14it/s]Progress: 33.00%
---- avg training fps: 6.87# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:38,  2.14it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:37,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:36,  2.14it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:36,  2.13it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:35,  2.14it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:35,  2.13it/s]Progress: 35.00%
---- avg training fps: 6.95# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:34,  2.14it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.13it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:34,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:33,  2.13it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:57<01:32,  2.13it/s]Progress: 37.00%Failed to plot token attention loss

---- avg training fps: 7.03# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:58<01:32,  2.13it/s]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [00:58<01:32,  2.13it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [00:58<01:31,  2.13it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [00:59<01:31,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [00:59<01:30,  2.12it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:00<01:30,  2.12it/s]Progress: 39.00%
---- avg training fps: 7.10# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:00<01:29,  2.12it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:01<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:01<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:01<01:29,  2.12it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:02<01:28,  2.12it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:02<01:28,  2.12it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:03<01:27,  2.12it/s]Progress: 41.00%
---- avg training fps: 7.16# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:03<01:26,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:04<01:26,  2.13it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:04<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:05<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:05<01:25,  2.12it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:06<01:24,  2.12it/s]Progress: 43.00%
---- avg training fps: 7.22# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:06<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:06<01:24,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:07<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:07<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:07<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:08<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:08<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 7.27# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:09<01:21,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:09<01:20,  2.13it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:10<01:20,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:10<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:11<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:11<01:19,  2.13it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:11<01:18,  2.13it/s]Progress: 47.00%
---- avg training fps: 7.32# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:12<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:12<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:13<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:13<01:17,  2.11it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:14<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:14<01:16,  2.12it/s]Progress: 49.00%
---- avg training fps: 7.36# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:15<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:15<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:15<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:15<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:16<01:14,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:16<01:13,  2.13it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:17<01:13,  2.13it/s]Progress: 51.00%
---- avg training fps: 7.40# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:17<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:18<01:12,  2.13it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:18<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:19<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:19<01:10,  2.13it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:20<01:10,  2.13it/s]Progress: 53.00%
---- avg training fps: 7.44# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:20<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:20<01:10,  2.13it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:24<03:52,  1.57s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:25<03:02,  1.24s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:25<02:27,  1.01s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:26<02:03,  1.18it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:26<01:45,  1.36it/s]Progress: 55.00%
---- avg training fps: 7.16# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:27<01:33,  1.52it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:27<01:25,  1.67it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:28<01:19,  1.78it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:28<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:29<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:29<01:11,  1.94it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:29<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 7.20# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:29<01:07,  2.03it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:30<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:30<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:31<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:31<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:32<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.24# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:32<01:02,  2.10it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:33<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:33<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:33<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:34<01:00,  2.11it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:34<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:35<00:59,  2.12it/s]Progress: 61.00%
---- avg training fps: 7.28# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:35<00:59,  2.11it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:36<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:36<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:37<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:37<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:38<00:56,  2.13it/s]Progress: 63.00%
---- avg training fps: 7.31# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:38<00:56,  2.13it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:38<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:38<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:39<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:39<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:40<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:40<00:53,  2.12it/s]Progress: 65.00%
---- avg training fps: 7.34# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:41<00:53,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:41<00:53,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:42<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:42<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:43<00:52,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:43<00:51,  2.11it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:43<00:50,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.37# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:44<00:50,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:44<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:45<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:45<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:46<00:48,  2.12it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:46<00:48,  2.12it/s]Progress: 69.00%
---- avg training fps: 7.40# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:46<00:47,  2.12it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:47<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:47<00:47,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:47<00:46,  2.12it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:36,  1.59s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:52<02:02,  1.26s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:37,  1.02s/it]Progress: 71.00%
---- avg training fps: 7.19# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:53<01:21,  1.17it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:09,  1.35it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:54<01:01,  1.51it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:54<00:55,  1.65it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:55<00:51,  1.78it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:55<00:48,  1.86it/s]Progress: 73.00%
---- avg training fps: 7.22# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:56<00:48,  1.86it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:56<00:46,  1.93it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:56<00:44,  1.98it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:57<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:57<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:58<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:58<00:40,  2.07it/s]Progress: 75.00%
---- avg training fps: 7.25# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [01:59<00:39,  2.08it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [01:59<00:39,  2.09it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:38,  2.10it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:00<00:37,  2.11it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:37,  2.11it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:37,  2.11it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:01<00:36,  2.11it/s]Progress: 77.00%
---- avg training fps: 7.27# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:36,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:02<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:03<00:34,  2.12it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:03<00:34,  2.12it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:04<00:34,  2.11it/s]Progress: 79.00%
---- avg training fps: 7.30# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:04<00:33,  2.11it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:05<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:05<00:33,  2.11it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:05<00:32,  2.12it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:32,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:06<00:31,  2.11it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:31,  2.11it/s]Progress: 81.00%
---- avg training fps: 7.33# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:07<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:30,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:08<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:29,  2.11it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:09<00:28,  2.12it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:10<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:10<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:27,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:11<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:11<00:26,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:12<00:25,  2.14it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:12<00:25,  2.14it/s]Progress: 85.00%
---- avg training fps: 7.38# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:13<00:24,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:23,  2.14it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:14<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:22,  2.14it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:15<00:22,  2.15it/s]Progress: 87.00%Failed to plot token attention loss

---- avg training fps: 7.40# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:16<00:21,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:16<00:21,  2.15it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:17<00:21,  2.14it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:17<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:18<00:20,  2.14it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:18<00:19,  2.14it/s]Progress: 89.00%
---- avg training fps: 7.43# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:18<00:19,  2.14it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:19<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:19<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:19<00:18,  2.14it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:20<00:17,  2.14it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:21<00:19,  1.89it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:21<00:18,  1.96it/s]Progress: 91.00%
---- avg training fps: 7.44# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:21<00:17,  2.01it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:22<00:16,  2.05it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:22<00:15,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:23<00:15,  2.10it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:23<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:24<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.46# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:24<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:24<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:25<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:25<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:26<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:26<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:27<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.48# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:27<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:28<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:28<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:28<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:29<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:29<00:08,  2.14it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:29<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.50# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:30<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:30<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:31<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:31<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:32<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:32<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.52# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:33<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:33<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:34<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:34<00:04,  2.16it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:34<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:35<00:03,  2.15it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:35<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.54# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:35<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:36<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:36<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:37<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:37<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:38<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.56Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.89it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.54it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.49it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.48it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.47it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.47it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.47it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.46it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.45it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.45it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.45it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.44it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.44it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.44it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.43it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.43it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.43it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.43it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.42it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.42it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.42it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.41it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.41it/s][A100%|██████████| 30/30 [00:08<00:00,  3.47it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.91it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.56it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.51it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.47it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.45it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.43it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.42it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.41it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.40it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.40it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.39it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.39it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.39it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.38it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.38it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.38it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.38it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.37it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.37it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.37it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.42it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.35it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.34it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [03:56<00:00,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 04:58:48.216437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 04:58:48.316150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 04:58:48.316179: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 04:58:48.334878: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 04:58:48.734572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:58:48.734625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 04:58:48.734634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23123 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.2 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=1.0 freeze_unet_before_completion_f=0.25 token_attention_loss_w=2e-07 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='clipx.zip' output_dir='lora_models/styles_final/clipx.zip_13_04-58-50-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723517930.531857 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 17268.87it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  7.73it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.02it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.40it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Downloading training data...
Downloading https://edenartlab-lfs.s3.amazonaws.com/datasets/clipx.zip to lora_models/styles_final/clipx.zip_13_04-58-50-style_512_florence_300/images_in/clipx.zip...
Succesfully prepped 54 .jpg images in lora_models/styles_final/clipx.zip_13_04-58-50-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.314
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 27 images, 27 of which have captions.
upscaling imgs..
  0%|          | 0/27 [00:00<?, ?it/s]100%|██████████| 27/27 [00:00<00:00, 355003.79it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 27 to 54)
Generating 54 captions using mode: style...
  0%|          | 0/54 [00:00<?, ?it/s]100%|██████████| 54/54 [00:00<00:00, 1617802.97it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Surreal, whimsical, detailed, and quirky scenes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater in the ocean.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, an image of Fort Kochi, Kerala, India.
- In the style of TOK, a scene that suggests both the best and worst of times.
- In the style of TOK, bees form a blockchain.
- In the style of TOK, a gorgon made of sharks swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple is deep in the Amazon jungle.
- In the style of TOK, cats poop in zero-gravity.
- In the style of TOK, a creature described as a goblin goat.
- In the style of TOK, a scene comparing wisdom and foolishness.
- In the style of TOK, colleagues decide to quit their boring corporation jobs together.
- In the style of TOK, ancient petroglyphs are depicted.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, a depiction relating to trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly builds a dam.
- In the style of TOK, a castle moves along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a 1950s restaurant kitchen is frozen solid and rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting depicts lemon-lime architecture.
- In the style of TOK, a mermaid made of fishnets, dead fish, packing peanuts, and other sea trash swims up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 1...
----- GPT response: -----
Style Description: Surrealistic, intricate, and fantastical scenes

- In the style of TOK, a mermaid swims underwater in the ocean, crafted from fishnets and sea trash.
- In the style of TOK, a throng of Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India is depicted.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times" is illustrated.
- In the style of TOK, a blockchain of bees is depicted.
- In the style of TOK, a gorgon made out of sharks is depicted swimming underwater, the sharks eating each other.
- In the style of TOK, a hillside at sunset is shown with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle is depicted.
- In the style of TOK, cats are shown pooping in zero-gravity.
- In the style of TOK, a goblin goat is depicted.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness" is illustrated.
- In the style of TOK, the phrase "Let's quit our boring corporation job together" is illustrated.
- In the style of TOK, petroglyphs are depicted.
- In the style of TOK, room and space exchange based on first and second-degree connection is depicted.
- In the style of TOK, trypophobia is illustrated.
- In the style of TOK, a six-pack of nightmare fuel is depicted.
- In the style of TOK, a band of dancing, singing beavers is shown.
- In the style of TOK, a beaver is chewing a rifle in half.
- In the style of TOK, a brigade of beavers is quickly building a dam in a Hawaiian-shirt pattern.
- In the style of TOK, a brigade of beavers is quickly building a dam as depicted by Tarsem Singh.
- In the style of TOK, a brigade of beavers is depicted in the manner of M. C. Escher.
- In the style of TOK, a castle is moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers is dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen is shown, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show features elephant seals as runway models with egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture is depicted.
- In the style of TOK, a mermaid made out of fishnets, dead fish, and packing peanuts is swimming up through the sea to peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 2...
----- GPT response: -----
Style Description: Surreal, eclectic, and whimsical themes

- In the style of TOK, a mermaid made out of fishnets and other sea trash swims underwater.
- In the style of TOK, a throng of Lilliputians is cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain of bees.
- In the style of TOK, a gorgon made out of sharks eating each other swims underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, “Let's quit our boring corporation job together.”
- In the style of TOK, petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam.
- In the style of TOK, a castle moving along the grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets as the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swims up through the sea to take a peek above the water.

--------------------------
GPT-4 returned the wrong number of prompts 25 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 3...
----- GPT response: -----
Style Description: Surreal and intricate marine or forest scenes

- In the style of TOK, a mermaid crafted from fishnets and sea trash swims underwater in the ocean.
- In the style of TOK, Lilliputians are cramped inside the pores of a giant sea-sponge.
- In the style of TOK, Fort Kochi, Kerala, India.
- In the style of TOK, narrating the best and worst of times.
- In the style of TOK, a blockchain composed of bees.
- In the style of TOK, a gorgon formed from sharks cannibalizing each other, swimming underwater.
- In the style of TOK, a sunset over a hillside with Venus and Earth orbiting the sun.
- In the style of TOK, an ancient temple nestled in the Amazon jungle.
- In the style of TOK, cats defecating in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, it was the age of wisdom and foolishness.
- In the style of TOK, two people planning to leave their corporate jobs together.
- In the style of TOK, ancient rock carvings.
- In the style of TOK, room and space exchange based on connections.
- In the style of TOK, a pattern inducing trypophobia.
- In the style of TOK, a six-pack of nightmare fuel.
- In the style of TOK, dancing and singing beavers perform.
- In the style of TOK, a beaver chews a rifle in half.
- In the style of TOK, a brigade of beavers quickly constructs a dam in a Hawaiian shirt pattern.
- In the style of TOK, a brigade of beavers quickly constructs a dam in a Tarsem Singh-like manner.
- In the style of TOK, beavers designed in M. C. Escher's style.
- In the style of TOK, a castle moves along grassy hills.
- In the style of TOK, a chorus line of adorable beavers dances in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen frozen and preserved in the space age.
- In the style of TOK, elephant seals parade as runway models with egrets in the audience.
- In the style of TOK, a hyper-realistic painting featuring lemon-lime architecture.
- In the style of TOK, a mermaid constructed out of fishnets, dead fish, packing peanuts, and sea trash swims to the surface for a peek.

Note: A few descriptions have small repetitions in the list since asked in the question description.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water
- A mermaid made out of fishnets and other sea trash, swimming underwater in the ocean
- A throng of Lilliputians cramped inside the pores of a giant sea-sponge | C. G. Jung - "Liber Novus"
- Fort Kochi, Kerala, India
- They were the best of times, they were the worst of times
- a blockchain of bees
- a gorgon made out of sharks eating each other swimming underwater
- a hillside at sunset, Venus and earth circling the sun
- an ancient temple deep in the amazon jungle
- cats pooping in zero-gravity
- goblin goat
- it was the age of wisdom, it was the age of foolishness
- let's quit our boring corporation job together.
- petroglyphs
- room and space exchange based on first and second degree connection
- trypophobia
- A 6-pack of nightmare fuel
- A band of dancing, singing beavers | Jim Henson's Muppets
- A beaver chewing a rifle in half
- A brigade of beavers quickly building a dam | Hawaiian-shirt pattern
- A brigade of beavers quickly building a dam | Tarsem Singh
- A brigade of beavers | M. C. Escher
- A castle that is moving along the ground in grassy hills
- A chorus line of adorable beavers dancing in unison
- A dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age
- A fashion show with elephant seals as the runway models and egrets seated in the audience
- A hyper-realistic painting of lemon-lime architecture
- A mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peak above the water

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 4...
----- GPT response: -----
Style Description: Surreal and fantastical imagery

- In the style of TOK, a mermaid made out of fishnets, swimming underwater in the ocean.
- In the style of TOK, a throng of Lilliputians cramped inside the pores of a giant sea-sponge.
- In the style of TOK, a scene of Fort Kochi, Kerala, India.
- In the style of TOK, the phrase "They were the best of times, they were the worst of times."
- In the style of TOK, a blockchain composed of bees.
- In the style of TOK, a gorgon made out of sharks eating each other, swimming underwater.
- In the style of TOK, a hillside at sunset with Venus and Earth circling the sun.
- In the style of TOK, an ancient temple located deep in the Amazon jungle.
- In the style of TOK, cats pooping in zero-gravity.
- In the style of TOK, a goblin goat.
- In the style of TOK, the phrase "It was the age of wisdom, it was the age of foolishness."
- In the style of TOK, the phrase "Let's quit our boring corporation job together."
- In the style of TOK, various petroglyphs.
- In the style of TOK, a room and space exchange based on first and second-degree connections.
- In the style of TOK, an image invoking trypophobia.
- In the style of TOK, a 6-pack of nightmare fuel.
- In the style of TOK, a band of dancing, singing beavers.
- In the style of TOK, a beaver chewing a rifle in half.
- In the style of TOK, a brigade of beavers quickly building a dam (Hawaiian-shirt pattern).
- In the style of TOK, a brigade of beavers quickly building a dam (Tarsem Singh).
- In the style of TOK, a brigade of beavers (M. C. Escher).
- In the style of TOK, a castle moving along the ground in grassy hills.
- In the style of TOK, a chorus line of adorable beavers dancing in unison.
- In the style of TOK, a dirty 1950s restaurant kitchen, frozen solid and preserved, rediscovered in the space age.
- In the style of TOK, a fashion show with elephant seals as runway models and egrets seated in the audience.
- In the style of TOK, a hyper-realistic painting of lemon-lime architecture.
- In the style of TOK, a mermaid made out of fishnets, dead fish, packing peanuts, and other sea trash, swimming up through the sea to take a peek above the water.
--------------------------
GPT-4 returned the wrong number of prompts 27 instead of 54, retrying...
WARNING: no captioning text was given and we're not doing chatgpt cleanup...
Concept mode:  style
Using GPT concept name as CLIP-segmentation prompt: Surreal and fantastical imagery
Generating 54 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]54it [00:00, 15809.89it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 54 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a mermaid made o...
1     in the style of <s0><s1><s2>, a throng of lill...
2     in the style of <s0><s1><s2>, fort kochi, kera...
3     in the style of <s0><s1><s2>, they were the be...
4     in the style of <s0><s1><s2>, a blockchain of ...
5     in the style of <s0><s1><s2>, a gorgon made ou...
6     in the style of <s0><s1><s2>, a hillside at su...
7     in the style of <s0><s1><s2>, an ancient templ...
8     in the style of <s0><s1><s2>, cats pooping in ...
9             in the style of <s0><s1><s2>, goblin goat
10    in the style of <s0><s1><s2>, it was the age o...
11    in the style of <s0><s1><s2>, let's quit our b...
12            in the style of <s0><s1><s2>, petroglyphs
13    in the style of <s0><s1><s2>, room and space e...
14            in the style of <s0><s1><s2>, trypophobia
15    in the style of <s0><s1><s2>, a 6-pack of nigh...
16    in the style of <s0><s1><s2>, a band of dancin...
17    in the style of <s0><s1><s2>, a beaver chewing...
18    in the style of <s0><s1><s2>, a brigade of bea...
19    in the style of <s0><s1><s2>, a brigade of bea...
20    in the style of <s0><s1><s2>, a brigade of bea...
21    in the style of <s0><s1><s2>, a castle that is...
22    in the style of <s0><s1><s2>, a chorus line of...
23    in the style of <s0><s1><s2>, a dirty 1950s re...
24    in the style of <s0><s1><s2>, a fashion show w...
25    in the style of <s0><s1><s2>, a hyper-realisti...
26    in the style of <s0><s1><s2>, a mermaid made o...
27    in the style of <s0><s1><s2>, a mermaid made o...
28    in the style of <s0><s1><s2>, a throng of lill...
29    in the style of <s0><s1><s2>, fort kochi, kera...
30    in the style of <s0><s1><s2>, they were the be...
31    in the style of <s0><s1><s2>, a blockchain of ...
32    in the style of <s0><s1><s2>, a gorgon made ou...
33    in the style of <s0><s1><s2>, a hillside at su...
34    in the style of <s0><s1><s2>, an ancient templ...
35    in the style of <s0><s1><s2>, cats pooping in ...
36            in the style of <s0><s1><s2>, goblin goat
37    in the style of <s0><s1><s2>, it was the age o...
38    in the style of <s0><s1><s2>, let's quit our b...
39            in the style of <s0><s1><s2>, petroglyphs
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 54
--- Num batches each epoch = 14
--- Num Epochs = 22
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:42,  2.95s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:08<21:42,  4.37s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:08<12:47,  2.59s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:09<08:37,  1.75s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:09<06:18,  1.28s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:10<04:56,  1.01s/it]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.26# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:10<04:03,  1.20it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:11<03:28,  1.40it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:11<03:05,  1.57it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:12<02:48,  1.72it/s]# Trainer step: 0, epoch: 0:   4%|▎         | 11/300 [00:12<02:37,  1.83it/s]# Trainer step: 0, epoch: 0:   4%|▍         | 12/300 [00:12<02:30,  1.92it/s]Progress: 7.00%
---- avg training fps: 3.58# Trainer step: 0, epoch: 0:   4%|▍         | 13/300 [00:13<02:24,  1.99it/s]# Trainer step: 0, epoch: 0:   5%|▍         | 14/300 [00:13<02:20,  2.03it/s]# Trainer step: 14, epoch: 1:   5%|▍         | 14/300 [00:14<02:20,  2.03it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 15/300 [00:14<02:25,  1.96it/s]# Trainer step: 14, epoch: 1:   5%|▌         | 16/300 [00:14<02:20,  2.02it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 17/300 [00:15<02:17,  2.06it/s]# Trainer step: 14, epoch: 1:   6%|▌         | 18/300 [00:15<02:14,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.42# Trainer step: 14, epoch: 1:   6%|▋         | 19/300 [00:16<02:12,  2.11it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 20/300 [00:16<02:11,  2.12it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 21/300 [00:17<02:10,  2.13it/s]# Trainer step: 14, epoch: 1:   7%|▋         | 22/300 [00:17<02:10,  2.14it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 23/300 [00:18<02:09,  2.14it/s]# Trainer step: 14, epoch: 1:   8%|▊         | 24/300 [00:18<02:08,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.04# Trainer step: 14, epoch: 1:   8%|▊         | 25/300 [00:19<02:07,  2.15it/s]# Trainer step: 14, epoch: 1:   9%|▊         | 26/300 [00:19<02:07,  2.15it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 27/300 [00:19<02:06,  2.15it/s]# Trainer step: 14, epoch: 1:   9%|▉         | 28/300 [00:20<02:06,  2.15it/s]# Trainer step: 28, epoch: 2:   9%|▉         | 28/300 [00:20<02:06,  2.15it/s]# Trainer step: 28, epoch: 2:  10%|▉         | 29/300 [00:20<02:00,  2.26it/s]# Trainer step: 28, epoch: 2:  10%|█         | 30/300 [00:21<02:01,  2.22it/s]Progress: 13.00%
---- avg training fps: 5.51# Trainer step: 28, epoch: 2:  10%|█         | 31/300 [00:21<02:02,  2.19it/s]# Trainer step: 28, epoch: 2:  11%|█         | 32/300 [00:22<02:02,  2.18it/s]# Trainer step: 28, epoch: 2:  11%|█         | 33/300 [00:22<02:02,  2.17it/s]# Trainer step: 28, epoch: 2:  11%|█▏        | 34/300 [00:23<02:02,  2.17it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 35/300 [00:23<02:02,  2.17it/s]# Trainer step: 28, epoch: 2:  12%|█▏        | 36/300 [00:24<02:01,  2.17it/s]Progress: 15.00%
---- avg training fps: 5.86# Trainer step: 28, epoch: 2:  12%|█▏        | 37/300 [00:24<02:01,  2.16it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 38/300 [00:25<02:01,  2.16it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 39/300 [00:25<02:00,  2.16it/s]# Trainer step: 28, epoch: 2:  13%|█▎        | 40/300 [00:25<02:00,  2.16it/s]# Trainer step: 28, epoch: 2:  14%|█▎        | 41/300 [00:26<01:59,  2.16it/s]# Trainer step: 28, epoch: 2:  14%|█▍        | 42/300 [00:26<01:59,  2.17it/s]Progress: 17.00%
---- avg training fps: 6.16# Trainer step: 42, epoch: 3:  14%|█▍        | 42/300 [00:27<01:59,  2.17it/s]# Trainer step: 42, epoch: 3:  14%|█▍        | 43/300 [00:27<01:53,  2.27it/s]# Trainer step: 42, epoch: 3:  15%|█▍        | 44/300 [00:27<01:54,  2.23it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 45/300 [00:28<01:55,  2.21it/s]# Trainer step: 42, epoch: 3:  15%|█▌        | 46/300 [00:28<01:55,  2.19it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 47/300 [00:29<01:56,  2.18it/s]# Trainer step: 42, epoch: 3:  16%|█▌        | 48/300 [00:29<01:56,  2.17it/s]Progress: 19.00%
---- avg training fps: 6.39# Trainer step: 42, epoch: 3:  16%|█▋        | 49/300 [00:30<01:56,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 50/300 [00:30<01:55,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 51/300 [00:30<01:55,  2.16it/s]# Trainer step: 42, epoch: 3:  17%|█▋        | 52/300 [00:34<05:15,  1.27s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 53/300 [00:34<04:14,  1.03s/it]# Trainer step: 42, epoch: 3:  18%|█▊        | 54/300 [00:35<03:31,  1.16it/s]Progress: 21.00%
---- avg training fps: 6.08# Trainer step: 42, epoch: 3:  18%|█▊        | 55/300 [00:35<03:01,  1.35it/s]# Trainer step: 42, epoch: 3:  19%|█▊        | 56/300 [00:36<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▊        | 56/300 [00:36<02:40,  1.52it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 57/300 [00:36<02:20,  1.73it/s]# Trainer step: 56, epoch: 4:  19%|█▉        | 58/300 [00:36<02:11,  1.84it/s]# Trainer step: 56, epoch: 4:  20%|█▉        | 59/300 [00:37<02:05,  1.92it/s]# Trainer step: 56, epoch: 4:  20%|██        | 60/300 [00:37<02:01,  1.98it/s]Progress: 23.00%
---- avg training fps: 6.27# Trainer step: 56, epoch: 4:  20%|██        | 61/300 [00:38<01:57,  2.03it/s]# Trainer step: 56, epoch: 4:  21%|██        | 62/300 [00:38<01:55,  2.07it/s]# Trainer step: 56, epoch: 4:  21%|██        | 63/300 [00:39<01:53,  2.09it/s]# Trainer step: 56, epoch: 4:  21%|██▏       | 64/300 [00:39<01:51,  2.11it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 65/300 [00:40<01:50,  2.12it/s]# Trainer step: 56, epoch: 4:  22%|██▏       | 66/300 [00:40<01:49,  2.14it/s]Progress: 25.00%
---- avg training fps: 6.43# Trainer step: 56, epoch: 4:  22%|██▏       | 67/300 [00:41<01:48,  2.14it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 68/300 [00:41<01:47,  2.15it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 69/300 [00:41<01:47,  2.14it/s]# Trainer step: 56, epoch: 4:  23%|██▎       | 70/300 [00:42<01:47,  2.14it/s]# Trainer step: 70, epoch: 5:  23%|██▎       | 70/300 [00:42<01:47,  2.14it/s]# Trainer step: 70, epoch: 5:  24%|██▎       | 71/300 [00:42<01:42,  2.24it/s]# Trainer step: 70, epoch: 5:  24%|██▍       | 72/300 [00:43<01:43,  2.21it/s]Progress: 27.00%
---- avg training fps: 6.58# Trainer step: 70, epoch: 5:  24%|██▍       | 73/300 [00:43<01:43,  2.19it/s]# Trainer step: 70, epoch: 5:  25%|██▍       | 74/300 [00:44<01:43,  2.18it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 75/300 [00:44<01:43,  2.17it/s]# Trainer step: 70, epoch: 5:  25%|██▌       | 76/300 [00:45<02:01,  1.84it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 77/300 [00:45<01:56,  1.92it/s]# Trainer step: 70, epoch: 5:  26%|██▌       | 78/300 [00:46<01:51,  1.98it/s]Progress: 29.00%
---- avg training fps: 6.66# Trainer step: 70, epoch: 5:  26%|██▋       | 79/300 [00:46<01:48,  2.03it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 80/300 [00:47<01:46,  2.07it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 81/300 [00:47<01:45,  2.08it/s]# Trainer step: 70, epoch: 5:  27%|██▋       | 82/300 [00:48<01:43,  2.11it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 83/300 [00:48<01:42,  2.12it/s]# Trainer step: 70, epoch: 5:  28%|██▊       | 84/300 [00:49<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.78# Trainer step: 84, epoch: 6:  28%|██▊       | 84/300 [00:49<01:41,  2.13it/s]# Trainer step: 84, epoch: 6:  28%|██▊       | 85/300 [00:49<01:35,  2.24it/s]# Trainer step: 84, epoch: 6:  29%|██▊       | 86/300 [00:50<01:36,  2.22it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 87/300 [00:50<01:36,  2.21it/s]# Trainer step: 84, epoch: 6:  29%|██▉       | 88/300 [00:50<01:36,  2.20it/s]# Trainer step: 84, epoch: 6:  30%|██▉       | 89/300 [00:51<01:36,  2.18it/s]# Trainer step: 84, epoch: 6:  30%|███       | 90/300 [00:51<01:36,  2.18it/s]Progress: 33.00%
---- avg training fps: 6.88# Trainer step: 84, epoch: 6:  30%|███       | 91/300 [00:52<01:36,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 92/300 [00:52<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███       | 93/300 [00:53<01:35,  2.17it/s]# Trainer step: 84, epoch: 6:  31%|███▏      | 94/300 [00:53<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 95/300 [00:54<01:34,  2.17it/s]# Trainer step: 84, epoch: 6:  32%|███▏      | 96/300 [00:54<01:34,  2.17it/s]Progress: 35.00%
---- avg training fps: 6.97# Trainer step: 84, epoch: 6:  32%|███▏      | 97/300 [00:55<01:33,  2.16it/s]# Trainer step: 84, epoch: 6:  33%|███▎      | 98/300 [00:55<01:33,  2.15it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 98/300 [00:55<01:33,  2.15it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 99/300 [00:55<01:29,  2.26it/s]# Trainer step: 98, epoch: 7:  33%|███▎      | 100/300 [00:56<01:29,  2.23it/s]# Trainer step: 98, epoch: 7:  34%|███▎      | 101/300 [00:56<01:30,  2.20it/s]# Trainer step: 98, epoch: 7:  34%|███▍      | 102/300 [00:59<03:27,  1.05s/it]Progress: 37.00%
---- avg training fps: 6.82# Trainer step: 98, epoch: 7:  34%|███▍      | 103/300 [00:59<02:51,  1.15it/s]# Trainer step: 98, epoch: 7:  35%|███▍      | 104/300 [01:00<02:27,  1.33it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 105/300 [01:00<02:09,  1.51it/s]# Trainer step: 98, epoch: 7:  35%|███▌      | 106/300 [01:01<01:57,  1.65it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 107/300 [01:01<01:48,  1.77it/s]# Trainer step: 98, epoch: 7:  36%|███▌      | 108/300 [01:02<01:42,  1.87it/s]Progress: 39.00%
---- avg training fps: 6.90# Trainer step: 98, epoch: 7:  36%|███▋      | 109/300 [01:02<01:38,  1.94it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 110/300 [01:03<01:34,  2.00it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 111/300 [01:03<01:32,  2.04it/s]# Trainer step: 98, epoch: 7:  37%|███▋      | 112/300 [01:03<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  37%|███▋      | 112/300 [01:04<01:30,  2.07it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 113/300 [01:04<01:25,  2.19it/s]# Trainer step: 112, epoch: 8:  38%|███▊      | 114/300 [01:04<01:25,  2.17it/s]Progress: 41.00%
---- avg training fps: 6.98# Trainer step: 112, epoch: 8:  38%|███▊      | 115/300 [01:05<01:25,  2.16it/s]# Trainer step: 112, epoch: 8:  39%|███▊      | 116/300 [01:05<01:25,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 117/300 [01:06<01:24,  2.15it/s]# Trainer step: 112, epoch: 8:  39%|███▉      | 118/300 [01:06<01:24,  2.15it/s]# Trainer step: 112, epoch: 8:  40%|███▉      | 119/300 [01:07<01:23,  2.15it/s]# Trainer step: 112, epoch: 8:  40%|████      | 120/300 [01:07<01:23,  2.15it/s]Progress: 43.00%
---- avg training fps: 7.05# Trainer step: 112, epoch: 8:  40%|████      | 121/300 [01:08<01:23,  2.15it/s]# Trainer step: 112, epoch: 8:  41%|████      | 122/300 [01:08<01:23,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████      | 123/300 [01:09<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  41%|████▏     | 124/300 [01:09<01:22,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 125/300 [01:09<01:21,  2.14it/s]# Trainer step: 112, epoch: 8:  42%|████▏     | 126/300 [01:10<01:20,  2.15it/s]Progress: 45.00%
---- avg training fps: 7.12# Trainer step: 126, epoch: 9:  42%|████▏     | 126/300 [01:10<01:20,  2.15it/s]# Trainer step: 126, epoch: 9:  42%|████▏     | 127/300 [01:10<01:16,  2.25it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 128/300 [01:11<01:17,  2.22it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 129/300 [01:11<01:17,  2.20it/s]# Trainer step: 126, epoch: 9:  43%|████▎     | 130/300 [01:12<01:17,  2.18it/s]# Trainer step: 126, epoch: 9:  44%|████▎     | 131/300 [01:12<01:17,  2.18it/s]# Trainer step: 126, epoch: 9:  44%|████▍     | 132/300 [01:13<01:17,  2.17it/s]Progress: 47.00%
---- avg training fps: 7.17# Trainer step: 126, epoch: 9:  44%|████▍     | 133/300 [01:13<01:17,  2.16it/s]# Trainer step: 126, epoch: 9:  45%|████▍     | 134/300 [01:14<01:17,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 135/300 [01:14<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  45%|████▌     | 136/300 [01:15<01:16,  2.15it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 137/300 [01:15<01:15,  2.16it/s]# Trainer step: 126, epoch: 9:  46%|████▌     | 138/300 [01:15<01:15,  2.16it/s]Progress: 49.00%
---- avg training fps: 7.22# Trainer step: 126, epoch: 9:  46%|████▋     | 139/300 [01:16<01:14,  2.15it/s]# Trainer step: 126, epoch: 9:  47%|████▋     | 140/300 [01:16<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 140/300 [01:17<01:14,  2.15it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 141/300 [01:17<01:10,  2.26it/s]# Trainer step: 140, epoch: 10:  47%|████▋     | 142/300 [01:17<01:10,  2.23it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 143/300 [01:18<01:11,  2.20it/s]# Trainer step: 140, epoch: 10:  48%|████▊     | 144/300 [01:18<01:11,  2.18it/s]Progress: 51.00%
---- avg training fps: 7.28# Trainer step: 140, epoch: 10:  48%|████▊     | 145/300 [01:19<01:11,  2.17it/s]# Trainer step: 140, epoch: 10:  49%|████▊     | 146/300 [01:19<01:11,  2.16it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 147/300 [01:20<01:10,  2.16it/s]# Trainer step: 140, epoch: 10:  49%|████▉     | 148/300 [01:20<01:10,  2.16it/s]# Trainer step: 140, epoch: 10:  50%|████▉     | 149/300 [01:21<01:10,  2.15it/s]# Trainer step: 140, epoch: 10:  50%|█████     | 150/300 [01:21<01:09,  2.15it/s]Progress: 53.00%
---- avg training fps: 7.31# Trainer step: 140, epoch: 10:  50%|█████     | 151/300 [01:22<01:17,  1.93it/s]# Trainer step: 140, epoch: 10:  51%|█████     | 152/300 [01:25<03:26,  1.40s/it]# Trainer step: 140, epoch: 10:  51%|█████     | 153/300 [01:26<02:44,  1.12s/it]# Trainer step: 140, epoch: 10:  51%|█████▏    | 154/300 [01:26<02:14,  1.09it/s]# Trainer step: 154, epoch: 11:  51%|█████▏    | 154/300 [01:26<02:14,  1.09it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 155/300 [01:26<01:50,  1.31it/s]# Trainer step: 154, epoch: 11:  52%|█████▏    | 156/300 [01:27<01:36,  1.49it/s]Progress: 55.00%
---- avg training fps: 7.11# Trainer step: 154, epoch: 11:  52%|█████▏    | 157/300 [01:27<01:27,  1.63it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 158/300 [01:28<01:20,  1.76it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 159/300 [01:28<01:16,  1.85it/s]# Trainer step: 154, epoch: 11:  53%|█████▎    | 160/300 [01:29<01:12,  1.93it/s]# Trainer step: 154, epoch: 11:  54%|█████▎    | 161/300 [01:29<01:09,  1.99it/s]# Trainer step: 154, epoch: 11:  54%|█████▍    | 162/300 [01:30<01:07,  2.03it/s]Progress: 57.00%
---- avg training fps: 7.15# Trainer step: 154, epoch: 11:  54%|█████▍    | 163/300 [01:30<01:06,  2.07it/s]# Trainer step: 154, epoch: 11:  55%|█████▍    | 164/300 [01:31<01:04,  2.09it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 165/300 [01:31<01:04,  2.10it/s]# Trainer step: 154, epoch: 11:  55%|█████▌    | 166/300 [01:32<01:03,  2.12it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 167/300 [01:32<01:02,  2.13it/s]# Trainer step: 154, epoch: 11:  56%|█████▌    | 168/300 [01:32<01:01,  2.14it/s]Progress: 59.00%
---- avg training fps: 7.20# Trainer step: 168, epoch: 12:  56%|█████▌    | 168/300 [01:33<01:01,  2.14it/s]# Trainer step: 168, epoch: 12:  56%|█████▋    | 169/300 [01:33<00:58,  2.25it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 170/300 [01:33<00:58,  2.21it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 171/300 [01:34<00:58,  2.19it/s]# Trainer step: 168, epoch: 12:  57%|█████▋    | 172/300 [01:34<00:58,  2.18it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 173/300 [01:35<00:58,  2.17it/s]# Trainer step: 168, epoch: 12:  58%|█████▊    | 174/300 [01:35<00:58,  2.16it/s]Progress: 61.00%
---- avg training fps: 7.24# Trainer step: 168, epoch: 12:  58%|█████▊    | 175/300 [01:36<00:58,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▊    | 176/300 [01:36<00:57,  2.15it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 177/300 [01:37<00:57,  2.14it/s]# Trainer step: 168, epoch: 12:  59%|█████▉    | 178/300 [01:37<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|█████▉    | 179/300 [01:38<00:56,  2.15it/s]# Trainer step: 168, epoch: 12:  60%|██████    | 180/300 [01:38<00:55,  2.15it/s]Progress: 63.00%
---- avg training fps: 7.28# Trainer step: 168, epoch: 12:  60%|██████    | 181/300 [01:38<00:55,  2.13it/s]# Trainer step: 168, epoch: 12:  61%|██████    | 182/300 [01:39<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 182/300 [01:39<00:55,  2.14it/s]# Trainer step: 182, epoch: 13:  61%|██████    | 183/300 [01:39<00:52,  2.24it/s]# Trainer step: 182, epoch: 13:  61%|██████▏   | 184/300 [01:40<00:52,  2.22it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 185/300 [01:40<00:52,  2.20it/s]# Trainer step: 182, epoch: 13:  62%|██████▏   | 186/300 [01:41<00:52,  2.18it/s]Progress: 65.00%
---- avg training fps: 7.32# Trainer step: 182, epoch: 13:  62%|██████▏   | 187/300 [01:41<00:51,  2.17it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 188/300 [01:42<00:51,  2.17it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 189/300 [01:42<00:51,  2.16it/s]# Trainer step: 182, epoch: 13:  63%|██████▎   | 190/300 [01:43<00:57,  1.91it/s]# Trainer step: 182, epoch: 13:  64%|██████▎   | 191/300 [01:43<00:55,  1.98it/s]# Trainer step: 182, epoch: 13:  64%|██████▍   | 192/300 [01:44<00:53,  2.03it/s]Progress: 67.00%
---- avg training fps: 7.34# Trainer step: 182, epoch: 13:  64%|██████▍   | 193/300 [01:44<00:51,  2.06it/s]# Trainer step: 182, epoch: 13:  65%|██████▍   | 194/300 [01:45<00:50,  2.08it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 195/300 [01:45<00:49,  2.10it/s]# Trainer step: 182, epoch: 13:  65%|██████▌   | 196/300 [01:46<00:49,  2.12it/s]# Trainer step: 196, epoch: 14:  65%|██████▌   | 196/300 [01:46<00:49,  2.12it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 197/300 [01:46<00:46,  2.23it/s]# Trainer step: 196, epoch: 14:  66%|██████▌   | 198/300 [01:46<00:46,  2.20it/s]Progress: 69.00%
---- avg training fps: 7.38# Trainer step: 196, epoch: 14:  66%|██████▋   | 199/300 [01:47<00:46,  2.19it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 200/300 [01:47<00:46,  2.17it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 201/300 [01:48<00:45,  2.16it/s]# Trainer step: 196, epoch: 14:  67%|██████▋   | 202/300 [01:50<01:37,  1.00it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 203/300 [01:51<01:21,  1.20it/s]# Trainer step: 196, epoch: 14:  68%|██████▊   | 204/300 [01:51<01:09,  1.38it/s]Progress: 71.00%
---- avg training fps: 7.29# Trainer step: 196, epoch: 14:  68%|██████▊   | 205/300 [01:51<01:01,  1.54it/s]# Trainer step: 196, epoch: 14:  69%|██████▊   | 206/300 [01:52<00:55,  1.69it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 207/300 [01:52<00:51,  1.81it/s]# Trainer step: 196, epoch: 14:  69%|██████▉   | 208/300 [01:53<00:48,  1.90it/s]# Trainer step: 196, epoch: 14:  70%|██████▉   | 209/300 [01:53<00:46,  1.97it/s]# Trainer step: 196, epoch: 14:  70%|███████   | 210/300 [01:54<00:44,  2.02it/s]Progress: 73.00%
---- avg training fps: 7.33# Trainer step: 210, epoch: 15:  70%|███████   | 210/300 [01:54<00:44,  2.02it/s]# Trainer step: 210, epoch: 15:  70%|███████   | 211/300 [01:54<00:41,  2.15it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 212/300 [01:55<00:40,  2.15it/s]# Trainer step: 210, epoch: 15:  71%|███████   | 213/300 [01:55<00:40,  2.16it/s]# Trainer step: 210, epoch: 15:  71%|███████▏  | 214/300 [01:56<00:39,  2.16it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 215/300 [01:56<00:39,  2.16it/s]# Trainer step: 210, epoch: 15:  72%|███████▏  | 216/300 [01:56<00:38,  2.16it/s]Progress: 75.00%
---- avg training fps: 7.36# Trainer step: 210, epoch: 15:  72%|███████▏  | 217/300 [01:57<00:38,  2.17it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 218/300 [01:57<00:38,  2.16it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 219/300 [01:58<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  73%|███████▎  | 220/300 [01:58<00:37,  2.14it/s]# Trainer step: 210, epoch: 15:  74%|███████▎  | 221/300 [01:59<00:36,  2.15it/s]# Trainer step: 210, epoch: 15:  74%|███████▍  | 222/300 [01:59<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.39# Trainer step: 210, epoch: 15:  74%|███████▍  | 223/300 [02:00<00:35,  2.15it/s]# Trainer step: 210, epoch: 15:  75%|███████▍  | 224/300 [02:00<00:35,  2.15it/s]# Trainer step: 224, epoch: 16:  75%|███████▍  | 224/300 [02:01<00:35,  2.15it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 225/300 [02:01<00:33,  2.25it/s]# Trainer step: 224, epoch: 16:  75%|███████▌  | 226/300 [02:01<00:33,  2.21it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 227/300 [02:02<00:33,  2.19it/s]# Trainer step: 224, epoch: 16:  76%|███████▌  | 228/300 [02:02<00:33,  2.18it/s]Progress: 79.00%
---- avg training fps: 7.42# Trainer step: 224, epoch: 16:  76%|███████▋  | 229/300 [02:02<00:32,  2.17it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 230/300 [02:03<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 231/300 [02:03<00:32,  2.15it/s]# Trainer step: 224, epoch: 16:  77%|███████▋  | 232/300 [02:04<00:31,  2.15it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 233/300 [02:04<00:31,  2.14it/s]# Trainer step: 224, epoch: 16:  78%|███████▊  | 234/300 [02:05<00:30,  2.15it/s]Progress: 81.00%
---- avg training fps: 7.44# Trainer step: 224, epoch: 16:  78%|███████▊  | 235/300 [02:05<00:30,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▊  | 236/300 [02:06<00:29,  2.14it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 237/300 [02:06<00:29,  2.13it/s]# Trainer step: 224, epoch: 16:  79%|███████▉  | 238/300 [02:07<00:28,  2.14it/s]# Trainer step: 238, epoch: 17:  79%|███████▉  | 238/300 [02:07<00:28,  2.14it/s]# Trainer step: 238, epoch: 17:  80%|███████▉  | 239/300 [02:07<00:26,  2.28it/s]# Trainer step: 238, epoch: 17:  80%|████████  | 240/300 [02:08<00:26,  2.23it/s]Progress: 83.00%
---- avg training fps: 7.47# Trainer step: 238, epoch: 17:  80%|████████  | 241/300 [02:08<00:26,  2.20it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 242/300 [02:08<00:26,  2.19it/s]# Trainer step: 238, epoch: 17:  81%|████████  | 243/300 [02:09<00:26,  2.17it/s]# Trainer step: 238, epoch: 17:  81%|████████▏ | 244/300 [02:09<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 245/300 [02:10<00:25,  2.16it/s]# Trainer step: 238, epoch: 17:  82%|████████▏ | 246/300 [02:10<00:25,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.50# Trainer step: 238, epoch: 17:  82%|████████▏ | 247/300 [02:11<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 248/300 [02:11<00:24,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 249/300 [02:12<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  83%|████████▎ | 250/300 [02:12<00:23,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▎ | 251/300 [02:13<00:22,  2.15it/s]# Trainer step: 238, epoch: 17:  84%|████████▍ | 252/300 [02:16<01:03,  1.32s/it]Progress: 87.00%
---- avg training fps: 7.37# Trainer step: 252, epoch: 18:  84%|████████▍ | 252/300 [02:16<01:03,  1.32s/it]# Trainer step: 252, epoch: 18:  84%|████████▍ | 253/300 [02:16<00:49,  1.04s/it]# Trainer step: 252, epoch: 18:  85%|████████▍ | 254/300 [02:17<00:40,  1.15it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 255/300 [02:17<00:33,  1.33it/s]# Trainer step: 252, epoch: 18:  85%|████████▌ | 256/300 [02:18<00:29,  1.50it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 257/300 [02:18<00:25,  1.66it/s]# Trainer step: 252, epoch: 18:  86%|████████▌ | 258/300 [02:19<00:23,  1.78it/s]Progress: 89.00%
---- avg training fps: 7.39# Trainer step: 252, epoch: 18:  86%|████████▋ | 259/300 [02:19<00:21,  1.87it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 260/300 [02:20<00:20,  1.95it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 261/300 [02:20<00:19,  2.01it/s]# Trainer step: 252, epoch: 18:  87%|████████▋ | 262/300 [02:21<00:18,  2.05it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 263/300 [02:21<00:17,  2.08it/s]# Trainer step: 252, epoch: 18:  88%|████████▊ | 264/300 [02:21<00:17,  2.10it/s]Progress: 91.00%
---- avg training fps: 7.41# Trainer step: 252, epoch: 18:  88%|████████▊ | 265/300 [02:22<00:16,  2.12it/s]# Trainer step: 252, epoch: 18:  89%|████████▊ | 266/300 [02:22<00:15,  2.13it/s]# Trainer step: 266, epoch: 19:  89%|████████▊ | 266/300 [02:23<00:15,  2.13it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 267/300 [02:23<00:14,  2.24it/s]# Trainer step: 266, epoch: 19:  89%|████████▉ | 268/300 [02:23<00:14,  2.21it/s]# Trainer step: 266, epoch: 19:  90%|████████▉ | 269/300 [02:24<00:14,  2.19it/s]# Trainer step: 266, epoch: 19:  90%|█████████ | 270/300 [02:24<00:13,  2.18it/s]Progress: 93.00%
---- avg training fps: 7.44# Trainer step: 266, epoch: 19:  90%|█████████ | 271/300 [02:25<00:13,  2.17it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 272/300 [02:25<00:12,  2.17it/s]# Trainer step: 266, epoch: 19:  91%|█████████ | 273/300 [02:26<00:12,  2.15it/s]# Trainer step: 266, epoch: 19:  91%|█████████▏| 274/300 [02:26<00:12,  2.16it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 275/300 [02:27<00:11,  2.16it/s]# Trainer step: 266, epoch: 19:  92%|█████████▏| 276/300 [02:27<00:11,  2.15it/s]Progress: 95.00%
---- avg training fps: 7.46# Trainer step: 266, epoch: 19:  92%|█████████▏| 277/300 [02:27<00:10,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 278/300 [02:28<00:10,  2.16it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 279/300 [02:28<00:09,  2.15it/s]# Trainer step: 266, epoch: 19:  93%|█████████▎| 280/300 [02:29<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  93%|█████████▎| 280/300 [02:29<00:09,  2.15it/s]# Trainer step: 280, epoch: 20:  94%|█████████▎| 281/300 [02:29<00:08,  2.25it/s]# Trainer step: 280, epoch: 20:  94%|█████████▍| 282/300 [02:30<00:08,  2.22it/s]Progress: 97.00%
---- avg training fps: 7.49# Trainer step: 280, epoch: 20:  94%|█████████▍| 283/300 [02:30<00:07,  2.19it/s]# Trainer step: 280, epoch: 20:  95%|█████████▍| 284/300 [02:31<00:07,  2.18it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 285/300 [02:31<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  95%|█████████▌| 286/300 [02:32<00:06,  2.17it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 287/300 [02:32<00:06,  2.16it/s]# Trainer step: 280, epoch: 20:  96%|█████████▌| 288/300 [02:32<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.51# Trainer step: 280, epoch: 20:  96%|█████████▋| 289/300 [02:33<00:05,  2.16it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 290/300 [02:33<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 291/300 [02:34<00:04,  2.15it/s]# Trainer step: 280, epoch: 20:  97%|█████████▋| 292/300 [02:34<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 293/300 [02:35<00:03,  2.15it/s]# Trainer step: 280, epoch: 20:  98%|█████████▊| 294/300 [02:35<00:02,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.53# Trainer step: 294, epoch: 21:  98%|█████████▊| 294/300 [02:36<00:02,  2.15it/s]# Trainer step: 294, epoch: 21:  98%|█████████▊| 295/300 [02:36<00:02,  2.25it/s]# Trainer step: 294, epoch: 21:  99%|█████████▊| 296/300 [02:36<00:01,  2.21it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 297/300 [02:37<00:01,  2.20it/s]# Trainer step: 294, epoch: 21:  99%|█████████▉| 298/300 [02:37<00:00,  2.18it/s]# Trainer step: 294, epoch: 21: 100%|█████████▉| 299/300 [02:38<00:00,  2.17it/s]# Trainer step: 294, epoch: 21: 100%|██████████| 300/300 [02:38<00:00,  2.16it/s]Progress: 100.00%
---- avg training fps: 7.55# Trainer step: 294, epoch: 21: : 301it [02:38,  2.15it/s]                       Progress: 100.00%Failed to plot token attention loss
Reached max steps, stopping training!
Saving checkpoint at step.. 301
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.87it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.70it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.61it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.56it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.53it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.49it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.48it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.48it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.48it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.47it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.47it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.47it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.47it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.47it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.46it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.46it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.46it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.45it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.45it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.45it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.44it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.44it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.44it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.43it/s][A100%|██████████| 30/30 [00:08<00:00,  3.49it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.58it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.52it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.49it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.46it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.42it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.42it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.41it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.40it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.40it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.40it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.40it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.43it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.48it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.40it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.40it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.39it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.38it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.38it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.38it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.37it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.36it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.37it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.37it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.36it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.36it/s][A100%|██████████| 30/30 [00:08<00:00,  3.40it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.89it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.52it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.46it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.42it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.34it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.34it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.34it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.62it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.34it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.32it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.32it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.32it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 294, epoch: 21: : 301it [03:57,  1.27it/s]
------------------------------------------
Training done :)
2024-08-13 05:03:51.548421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 05:03:51.639288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 05:03:51.639314: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 05:03:51.659197: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 05:03:52.061682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 05:03:52.061770: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 05:03:52.061780: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23130 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.001 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.75 freeze_unet_before_completion_f=0.25 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_05-03-53-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723518233.8534348 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 4722.06it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 17.36it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.43it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.81it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.10it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_05-03-53-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.39it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.40it/s] 20%|██        | 2/10 [00:00<00:01,  4.40it/s] 30%|███       | 3/10 [00:00<00:01,  4.70it/s] 40%|████      | 4/10 [00:00<00:01,  4.70it/s] 50%|█████     | 5/10 [00:01<00:01,  4.73it/s] 60%|██████    | 6/10 [00:01<00:00,  4.79it/s] 70%|███████   | 7/10 [00:01<00:00,  5.02it/s] 80%|████████  | 8/10 [00:01<00:00,  5.11it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.11it/s]100%|██████████| 10/10 [00:02<00:00,  4.96it/s]100%|██████████| 10/10 [00:02<00:00,  4.82it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology.

- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants on a black background.
- In the style of TOK, a potted plant sitting on top of a table next to a lamp.
- In the style of TOK, a futuristic city in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves on a dark blue background.
- In the style of TOK, a plant growing out of a circuit board.
- In the style of TOK, a group of green and red plants in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 7166.38it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant growing ...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant growing ...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant growing ...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant growing ...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant growing ...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant growing ...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant growing ...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant growing ...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:02<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:02<14:45,  2.96s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<16:14,  3.27s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:06<09:50,  1.99s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<06:50,  1.39s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:07<05:10,  1.05s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:10,  1.17it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.74# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:08<03:33,  1.38it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:08,  1.55it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:09<02:51,  1.69it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:40,  1.81it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:10<02:40,  1.81it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:10<02:32,  1.90it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:26,  1.97it/s]Progress: 7.00%
---- avg training fps: 4.15# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:11<02:22,  2.02it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:17,  2.08it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:12<02:15,  2.10it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:13,  2.11it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:13<02:12,  2.13it/s]Progress: 9.00%
---- avg training fps: 5.01# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:11,  2.13it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:14<02:11,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:11,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:10,  2.14it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:15<02:09,  2.14it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:09,  2.14it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:16<02:08,  2.14it/s]Progress: 11.00%
---- avg training fps: 5.59# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:08,  2.14it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:17<02:08,  2.14it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:07,  2.14it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:18<02:07,  2.14it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:06,  2.14it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:19<02:06,  2.14it/s]Progress: 13.00%
---- avg training fps: 6.01# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:19<02:06,  2.14it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:19<02:05,  2.14it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:20<02:05,  2.14it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:20<02:04,  2.15it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:21<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:21<02:03,  2.15it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:22<02:02,  2.15it/s]Progress: 15.00%
---- avg training fps: 6.28# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:22<02:17,  1.92it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:23<02:12,  1.98it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:23<02:08,  2.03it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:06,  2.06it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:24<02:06,  2.06it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:24<02:04,  2.09it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<02:02,  2.11it/s]Progress: 17.00%
---- avg training fps: 6.53# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:25<02:01,  2.12it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<02:00,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:26<01:59,  2.13it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:27<01:58,  2.14it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:57,  2.15it/s]Progress: 19.00%
---- avg training fps: 6.73# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:28<01:56,  2.15it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:29<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:29<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<05:45,  1.39s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:33<04:35,  1.12s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:33<03:46,  1.09it/s]Progress: 21.00%
---- avg training fps: 6.27# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:34<03:12,  1.27it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:34<02:48,  1.45it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:35<02:31,  1.60it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:35<02:19,  1.74it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:36<02:10,  1.84it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:36<02:04,  1.92it/s]Progress: 23.00%
---- avg training fps: 6.45# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:37<02:04,  1.92it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:37<02:00,  1.98it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:37<01:57,  2.03it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:38<01:54,  2.06it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:38<01:53,  2.08it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:39<01:51,  2.10it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:39<01:50,  2.11it/s]Progress: 25.00%
---- avg training fps: 6.59# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:40<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:40<01:49,  2.12it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:40<01:48,  2.13it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:41<02:01,  1.90it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<02:01,  1.90it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:56,  1.97it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:42<01:52,  2.02it/s]Progress: 27.00%
---- avg training fps: 6.69# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:50,  2.06it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:43<01:48,  2.08it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:43<01:46,  2.10it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:44<01:45,  2.12it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:44<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:45<01:44,  2.13it/s]Progress: 29.00%
---- avg training fps: 6.81# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:45<01:43,  2.14it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:46<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:46<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:46<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:47<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:47<01:40,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:40,  2.15it/s]Progress: 31.00%
---- avg training fps: 6.91# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:48<01:40,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:39,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:49<01:39,  2.15it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:50<01:38,  2.15it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:50<01:37,  2.15it/s]Progress: 33.00%
---- avg training fps: 7.01# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:51<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:51<01:37,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:51<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:52<01:36,  2.15it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:52<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:53<01:35,  2.15it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:53<01:34,  2.15it/s]Progress: 35.00%
---- avg training fps: 7.09# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:54<01:34,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:54<01:33,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:55<01:33,  2.15it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:55<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:56<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:56<01:32,  2.15it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [00:59<04:15,  1.29s/it]Progress: 37.00%
---- avg training fps: 6.83# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [00:59<03:25,  1.04s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:00<02:50,  1.15it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:00<02:26,  1.33it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:01<02:09,  1.50it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:01<01:56,  1.65it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:02<01:48,  1.77it/s]Progress: 39.00%
---- avg training fps: 6.91# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:02<01:42,  1.87it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:02<01:37,  1.94it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:03<01:37,  1.94it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:03<01:34,  2.00it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:03<01:32,  2.04it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:04<01:30,  2.07it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:04<01:28,  2.09it/s]Progress: 41.00%
---- avg training fps: 6.98# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:05<01:28,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:05<01:27,  2.11it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:06<01:26,  2.12it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:06<01:25,  2.13it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:07<01:35,  1.90it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:07<01:31,  1.97it/s]Progress: 43.00%
---- avg training fps: 7.03# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:08<01:31,  1.97it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:08<01:28,  2.02it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:08<01:26,  2.06it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:09<01:24,  2.09it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:09<01:23,  2.11it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:10<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:10<01:21,  2.13it/s]Progress: 45.00%
---- avg training fps: 7.09# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:11<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:11<01:20,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:12<01:19,  2.14it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:12<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:12<01:19,  2.14it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:12<01:18,  2.15it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:13<01:18,  2.15it/s]Progress: 47.00%
---- avg training fps: 7.15# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:13<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:14<01:17,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:14<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:15<01:16,  2.15it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:15<01:15,  2.15it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:16<01:15,  2.15it/s]Progress: 49.00%
---- avg training fps: 7.20# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:16<01:14,  2.15it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:17<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:17<01:14,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:17<01:13,  2.15it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:18<01:13,  2.15it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:18<01:12,  2.15it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:19<01:12,  2.15it/s]Progress: 51.00%
---- avg training fps: 7.25# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:19<01:11,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:19<01:11,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:20<01:11,  2.15it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:20<01:10,  2.16it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:21<01:10,  2.15it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:21<01:09,  2.15it/s]Progress: 53.00%
---- avg training fps: 7.29# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:22<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:22<01:09,  2.15it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:26<03:41,  1.50s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:26<02:54,  1.19s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:27<02:21,  1.03it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:27<01:59,  1.22it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:28<01:42,  1.40it/s]Progress: 55.00%
---- avg training fps: 7.05# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:28<01:31,  1.56it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:28<01:23,  1.70it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:29<01:17,  1.81it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:29<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:30<01:13,  1.90it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:30<01:10,  1.97it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:30<01:08,  2.02it/s]Progress: 57.00%
---- avg training fps: 7.10# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:31<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:31<01:05,  2.08it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:32<01:04,  2.09it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:32<01:03,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:33<01:02,  2.11it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:33<01:02,  2.12it/s]Progress: 59.00%
---- avg training fps: 7.14# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:34<01:01,  2.13it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:34<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:35<01:01,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:35<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:35<01:00,  2.13it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:35<00:59,  2.14it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:36<00:58,  2.14it/s]Progress: 61.00%
---- avg training fps: 7.18# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:36<00:58,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:37<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:37<00:57,  2.14it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:38<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:38<00:56,  2.14it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:39<00:56,  2.14it/s]Progress: 63.00%
---- avg training fps: 7.22# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:39<00:56,  2.14it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:39<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:40<00:55,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:40<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:41<00:54,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:41<00:53,  2.14it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:42<00:53,  2.14it/s]Progress: 65.00%
---- avg training fps: 7.26# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:42<00:52,  2.14it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:43<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:43<00:52,  2.13it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:43<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:44<00:51,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:44<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:44<00:50,  2.14it/s]Progress: 67.00%
---- avg training fps: 7.29# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:45<00:50,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:45<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:46<00:49,  2.14it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:46<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:47<00:48,  2.14it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:47<00:47,  2.14it/s]Progress: 69.00%
---- avg training fps: 7.32# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:48<00:47,  2.14it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:48<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:49<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:49<00:46,  2.14it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:52<02:20,  1.44s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:53<01:51,  1.15s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:53<01:38,  1.02s/it]Progress: 71.00%
---- avg training fps: 7.13# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:54<01:21,  1.17it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:54<01:09,  1.35it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:55<01:01,  1.52it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:55<00:55,  1.67it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:56<00:50,  1.79it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:56<00:47,  1.89it/s]Progress: 73.00%
---- avg training fps: 7.17# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:57<00:47,  1.89it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:57<00:45,  1.96it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:57<00:43,  2.01it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [01:58<00:42,  2.05it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [01:58<00:41,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [01:59<00:40,  2.10it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [01:59<00:39,  2.11it/s]Progress: 75.00%
---- avg training fps: 7.20# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:00<00:39,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:00<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:00<00:37,  2.13it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:01<00:37,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:01<00:36,  2.14it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:02<00:36,  2.15it/s]Progress: 77.00%
---- avg training fps: 7.23# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:02<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:03<00:35,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:03<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:04<00:34,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:04<00:33,  2.15it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:05<00:33,  2.15it/s]Progress: 79.00%
---- avg training fps: 7.26# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:05<00:32,  2.16it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:06<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:06<00:32,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:06<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:06<00:31,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:07<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:07<00:30,  2.16it/s]Progress: 81.00%
---- avg training fps: 7.29# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:08<00:30,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:08<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:09<00:29,  2.16it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:09<00:28,  2.15it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:10<00:28,  2.16it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:10<00:27,  2.16it/s]Progress: 83.00%
---- avg training fps: 7.32# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:11<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:11<00:27,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:11<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:12<00:26,  2.16it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:12<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:13<00:25,  2.16it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:13<00:25,  2.16it/s]Progress: 85.00%
---- avg training fps: 7.35# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:13<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:14<00:24,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:14<00:23,  2.16it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:15<00:23,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:15<00:22,  2.16it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:19<01:12,  1.52s/it]Progress: 87.00%
---- avg training fps: 7.19# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:20<00:56,  1.20s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:20<00:45,  1.02it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:21<00:37,  1.21it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:21<00:31,  1.39it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:22<00:27,  1.56it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:22<00:24,  1.70it/s]Progress: 89.00%
---- avg training fps: 7.22# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:23<00:22,  1.81it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:23<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:23<00:21,  1.90it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:23<00:19,  1.97it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:24<00:18,  2.02it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:24<00:18,  2.03it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:25<00:17,  2.07it/s]Progress: 91.00%
---- avg training fps: 7.24# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:25<00:16,  2.09it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:26<00:16,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:26<00:15,  2.12it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:27<00:15,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:27<00:14,  2.13it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:28<00:14,  2.14it/s]Progress: 93.00%
---- avg training fps: 7.27# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:28<00:14,  2.14it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:28<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:29<00:13,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:29<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:30<00:12,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:30<00:11,  2.14it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:30<00:11,  2.14it/s]Progress: 95.00%
---- avg training fps: 7.29# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:31<00:10,  2.14it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:31<00:10,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:32<00:09,  2.15it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:32<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:33<00:09,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:33<00:08,  2.15it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:33<00:08,  2.15it/s]Progress: 97.00%
---- avg training fps: 7.31# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:34<00:07,  2.15it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:34<00:07,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:35<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:35<00:06,  2.14it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:36<00:06,  2.15it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:36<00:05,  2.15it/s]Progress: 99.00%
---- avg training fps: 7.34# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:37<00:05,  2.15it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:37<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:37<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:37<00:04,  2.15it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:38<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:38<00:03,  2.14it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:39<00:02,  2.14it/s]Progress: 100.00%
---- avg training fps: 7.36# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:39<00:02,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:40<00:01,  2.14it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:40<00:01,  2.15it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:41<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:41<00:00,  2.15it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:42<00:00,  2.15it/s]Progress: 100.00%
---- avg training fps: 7.38Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.90it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.60it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.53it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.49it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.48it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.48it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.47it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.48it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.48it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.47it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.47it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.47it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.47it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.46it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.46it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.46it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.45it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.45it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.45it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.45it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.44it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.44it/s][A100%|██████████| 30/30 [00:08<00:00,  3.49it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.69it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.53it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.49it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.47it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.45it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.44it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.44it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.42it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.42it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.42it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.41it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.41it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.41it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.41it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.41it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.40it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.39it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.39it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.39it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.39it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.39it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.38it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.38it/s][A100%|██████████| 30/30 [00:08<00:00,  3.44it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.65it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.54it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.48it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.44it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.42it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.41it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.39it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.39it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.38it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.38it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.37it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.37it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.37it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.37it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.36it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.36it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.36it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.36it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.36it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.35it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.35it/s][A100%|██████████| 30/30 [00:08<00:00,  3.40it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.88it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.51it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.45it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.40it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.38it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.37it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.36it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.35it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.35it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.35it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.35it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.35it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.34it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.34it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.34it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.34it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.33it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.33it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.33it/s][A100%|██████████| 30/30 [00:08<00:00,  3.38it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.87it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.38it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.36it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.35it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.33it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.32it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.32it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.32it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.32it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.36it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.33it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.28it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.29it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.31it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.36it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.84it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.32it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.31it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.30it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:00<00:00,  1.25it/s]
------------------------------------------
Training done :)
2024-08-13 05:08:24.157116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-13 05:08:24.255915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-08-13 05:08:24.255941: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-13 05:08:24.274593: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-13 05:08:24.675596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-08-13 05:08:24.675679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-08-13 05:08:24.675688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
OpenAI API key loaded
# of visible GPUs: 1
GPU 0: 23122 MB free
Using GPU 0
Starting new LoRa training run with config:
lora_training_urls='/home/rednax/Documents/datasets/good_styles/eden_crystals' concept_mode='style' caption_prefix='' caption_model='florence' caption_dropout=0.0 sd_model_version='sdxl' ckpt_path=None pretrained_model={'path': './models/zavychromaxl_v90.safetensors', 'url': 'https://edenartlab-lfs.s3.amazonaws.com/comfyui/models2/checkpoints/zavychromaxl_v90.safetensors', 'version': 'sdxl'} seed=0 resolution=512 validation_img_size=None train_img_size=None train_aspect_ratio=None train_batch_size=4 max_train_steps=300 num_train_epochs=None checkpointing_steps=300 gradient_accumulation_steps=1 is_lora=True unet_optimizer_type='adamw' unet_lr_warmup_steps=300 unet_lr=0.0003 prodigy_d_coef=1.0 unet_prodigy_growth_factor=1.05 lora_weight_decay=0.001 ti_lr=0.001 token_warmup_steps=0 ti_weight_decay=0.0 ti_optimizer='adamw' freeze_ti_after_completion_f=0.5 freeze_unet_before_completion_f=0.0 token_attention_loss_w=0.0 cond_reg_w=0.0 tok_cond_reg_w=0.0 tok_cov_reg_w=500.0 l1_penalty=0.0 noise_offset=0.02 snr_gamma=5.0 lora_alpha_multiplier=1.0 lora_rank=16 use_dora=False left_right_flip_augmentation=True augment_imgs_up_to_n=40 mask_target_prompts=None crop_based_on_salience=True use_face_detection_instead=False clipseg_temperature=0.5 n_sample_imgs=8 name='eden_crystals' output_dir='lora_models/styles_final/eden_crystals_13_05-08-26-style_512_florence_300' debug=True allow_tf32=True disable_ti=False skip_gpt_cleanup=False weight_type='bf16' n_tokens=3 inserting_list_tokens=['<s0>', '<s1>', '<s2>'] token_dict={'TOK': '<s0><s1><s2>'} device='cuda:0' do_cache=True sample_imgs_lora_scale=0.8 dataloader_num_workers=0 training_attributes={} aspect_ratio_bucketing=False start_time=1723518506.4959981 job_time=0.0 text_encoder_lora_optimizer=None text_encoder_lora_lr=0.0 txt_encoders_lr_warmup_steps=200 text_encoder_lora_weight_decay=1e-05 text_encoder_lora_rank=16
------------------------------------------
Loading model weights from /home/rednax/SSD2TB/Github_repos/diffusion_trainer/models/zavychromaxl_v90.safetensors with dtype: torch.bfloat16...
Loading as SDXL model...
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]Fetching 17 files: 100%|██████████| 17/17 [00:00<00:00, 2585.13it/s]
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Some weights of the model checkpoint were not used when initializing CLIPTextModel: 
 ['text_model.embeddings.position_ids']
Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 16.65it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00,  7.63it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:01<00:00,  3.83it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loaded sdxl model!
Found: 60 modules
Local path detected, skipping download.
Succesfully prepped 5 .jpg images in lora_models/styles_final/eden_crystals_13_05-08-26-style_512_florence_300/images_in!
Average aspect ratio of images (width / height): 1.242
New train_img_size: [576, 448]
Validation_img_size was set to: [1152, 896]
Loaded 5 images, 0 of which have captions.
upscaling imgs..
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00,  3.38it/s] 80%|████████  | 4/5 [00:02<00:00,  1.58it/s]100%|██████████| 5/5 [00:03<00:00,  1.07it/s]100%|██████████| 5/5 [00:03<00:00,  1.31it/s]
/home/rednax/SSD2TB/miniconda3/envs/sdxl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Adding LR flips... (doubling the number of images from 5 to 10)
Generating 10 captions using mode: style...
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:02,  3.64it/s] 20%|██        | 2/10 [00:00<00:01,  4.54it/s] 30%|███       | 3/10 [00:00<00:01,  4.79it/s] 40%|████      | 4/10 [00:00<00:01,  4.91it/s] 50%|█████     | 5/10 [00:01<00:01,  4.86it/s] 60%|██████    | 6/10 [00:01<00:00,  4.88it/s] 70%|███████   | 7/10 [00:01<00:00,  4.88it/s] 80%|████████  | 8/10 [00:01<00:00,  4.99it/s] 90%|█████████ | 9/10 [00:01<00:00,  5.00it/s]100%|██████████| 10/10 [00:02<00:00,  4.86it/s]100%|██████████| 10/10 [00:02<00:00,  4.82it/s]
Final chatgpt prompt:

Analyze a set of (poor) image descriptions, each featuring an example of a common aesthetic style named TOK.
Tasks:
1. Deduce a concise (max 7 words) visual description of the aesthetic style (Style Description).
2. Rewrite each description to focus solely on the non-stylistic contents of the image like characters, objects, colors, scene, context etc but not the stylistic elements captured by TOK.
3. Integrate "in the style of TOK" naturally into each description, typically at the beginning while summarizing each description to its core elements, ensuring clarity and mandatory inclusion of "TOK".
The descriptions are:
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants on a black background.
- A potted plant sitting on top of a table next to a lamp.
- a futuristic city in the middle of a space filled with stars
- A flower with green leaves on a dark blue background.
- A plant growing out of a circuit board.
- A group of green and red plants in the dark.

Respond with "Style Description: ..." followed by a list (using "-") of all the revised descriptions, each mentioning "in the style of TOK".

--------------------------
Calling chatgpt with seed 0...
----- GPT response: -----
Style Description: Futuristic natural elements blending with technology.

- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is on a black background.
- In the style of TOK, a potted plant sits on a table next to a lamp.
- In the style of TOK, a futuristic city is in the middle of a space filled with stars.
- In the style of TOK, a flower with green leaves is on a dark blue background.
- In the style of TOK, a plant is growing out of a circuit board.
- In the style of TOK, a group of green and red plants is in the dark.
--------------------------
Making sure TOK is added to every training prompt...
Adding augmented version of each training img...
Adding augmented version of each training img...
Adding augmented version of each training img...
Using GPT concept name as CLIP-segmentation prompt: Futuristic natural elements blending with technology.
Generating 40 masks...
Using "" as CLIP-segmentation prompt for all images.
0it [00:00, ?it/s]40it [00:00, 6995.17it/s]
Masks generated! Cropping images to center of mass...
Cropping and resizing images...
Expanding masks...
Done!
Saving final training dataset...
---> Training data 100% ready to go!
Initializing new tokens: ['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-0:
['<s0>', '<s1>', '<s2>']
Inserting new tokens into tokenizer-1:
['<s0>', '<s1>', '<s2>']
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Initialized a new DistributionLoss with shape: torch.Size([49411, 768])
Initialized a new DistributionLoss with shape: torch.Size([49411, 1280])
Skipping token embedding warmup.
All embeddings in text_encoder_0 are now set to be trainable.
All embeddings in text_encoder_1 are now set to be trainable.
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 768]) to the trainable parameters
Added text_model.embeddings.token_embedding.weight with shape torch.Size([49411, 1280]) to the trainable parameters
Created adamw optimizer for textual inversion!
Created adamw optimizer for unet!
################################################################################
Trainable unet params: 25.4M || All params: 2592.9M || trainable = 0.98%
################################################################################
################################################################################
Trainable text_encoder_0 params: 0.0M || All params: 123.1M || trainable = 0.00%
################################################################################
################################################################################
Trainable text_encoder_1 params: 0.0M || All params: 694.7M || trainable = 0.00%
################################################################################
Caching latents, masks and captions...


Cached latents, masks and captions for 40 images.
Not using aspect ratio bucketing.
Final training captions:
0     in the style of <s0><s1><s2>, a potted plant s...
1     in the style of <s0><s1><s2>, a futuristic cit...
2     in the style of <s0><s1><s2>, a flower with gr...
3     in the style of <s0><s1><s2>, a plant is growi...
4     in the style of <s0><s1><s2>, a group of green...
5     in the style of <s0><s1><s2>, a potted plant s...
6     in the style of <s0><s1><s2>, a futuristic cit...
7     in the style of <s0><s1><s2>, a flower with gr...
8     in the style of <s0><s1><s2>, a plant is growi...
9     in the style of <s0><s1><s2>, a group of green...
10    in the style of <s0><s1><s2>, a potted plant s...
11    in the style of <s0><s1><s2>, a futuristic cit...
12    in the style of <s0><s1><s2>, a flower with gr...
13    in the style of <s0><s1><s2>, a plant is growi...
14    in the style of <s0><s1><s2>, a group of green...
15    in the style of <s0><s1><s2>, a potted plant s...
16    in the style of <s0><s1><s2>, a futuristic cit...
17    in the style of <s0><s1><s2>, a flower with gr...
18    in the style of <s0><s1><s2>, a plant is growi...
19    in the style of <s0><s1><s2>, a group of green...
20    in the style of <s0><s1><s2>, a potted plant s...
21    in the style of <s0><s1><s2>, a futuristic cit...
22    in the style of <s0><s1><s2>, a flower with gr...
23    in the style of <s0><s1><s2>, a plant is growi...
24    in the style of <s0><s1><s2>, a group of green...
25    in the style of <s0><s1><s2>, a potted plant s...
26    in the style of <s0><s1><s2>, a futuristic cit...
27    in the style of <s0><s1><s2>, a flower with gr...
28    in the style of <s0><s1><s2>, a plant is growi...
29    in the style of <s0><s1><s2>, a group of green...
30    in the style of <s0><s1><s2>, a potted plant s...
31    in the style of <s0><s1><s2>, a futuristic cit...
32    in the style of <s0><s1><s2>, a flower with gr...
33    in the style of <s0><s1><s2>, a plant is growi...
34    in the style of <s0><s1><s2>, a group of green...
35    in the style of <s0><s1><s2>, a potted plant s...
36    in the style of <s0><s1><s2>, a futuristic cit...
37    in the style of <s0><s1><s2>, a flower with gr...
38    in the style of <s0><s1><s2>, a plant is growi...
39    in the style of <s0><s1><s2>, a group of green...
Name: caption, dtype: object
# Trainer : Loaded dataset, do_cache: True
--- Num samples = 40
--- Num batches each epoch = 10
--- Num Epochs = 30
--- Instantaneous batch size per device = 4
--- Total batch_size (distributed + accumulation) = 4
--- Gradient Accumulation steps = 1
--- Total optimization steps = 300

  0%|          | 0/300 [00:00<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 0/300 [00:03<?, ?it/s]# Trainer step: 0, epoch: 0:   0%|          | 1/300 [00:03<15:20,  3.08s/it]# Trainer step: 0, epoch: 0:   1%|          | 2/300 [00:06<17:15,  3.47s/it]# Trainer step: 0, epoch: 0:   1%|          | 3/300 [00:07<10:24,  2.10s/it]# Trainer step: 0, epoch: 0:   1%|▏         | 4/300 [00:07<07:11,  1.46s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 5/300 [00:08<05:25,  1.10s/it]# Trainer step: 0, epoch: 0:   2%|▏         | 6/300 [00:08<04:20,  1.13it/s]--> Initialized optimizers for:
textual_inversion
unet

---- avg training fps: 2.62# Trainer step: 0, epoch: 0:   2%|▏         | 7/300 [00:09<03:40,  1.33it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 8/300 [00:09<03:13,  1.51it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 9/300 [00:10<02:55,  1.65it/s]# Trainer step: 0, epoch: 0:   3%|▎         | 10/300 [00:10<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   3%|▎         | 10/300 [00:11<02:43,  1.77it/s]# Trainer step: 10, epoch: 1:   4%|▎         | 11/300 [00:11<02:35,  1.86it/s]# Trainer step: 10, epoch: 1:   4%|▍         | 12/300 [00:11<02:29,  1.93it/s]Progress: 7.00%
---- avg training fps: 3.99# Trainer step: 10, epoch: 1:   4%|▍         | 13/300 [00:12<02:24,  1.98it/s]# Trainer step: 10, epoch: 1:   5%|▍         | 14/300 [00:12<02:21,  2.02it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 15/300 [00:12<02:19,  2.05it/s]# Trainer step: 10, epoch: 1:   5%|▌         | 16/300 [00:13<02:17,  2.07it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 17/300 [00:13<02:16,  2.08it/s]# Trainer step: 10, epoch: 1:   6%|▌         | 18/300 [00:14<02:14,  2.09it/s]Progress: 9.00%
---- avg training fps: 4.84# Trainer step: 10, epoch: 1:   6%|▋         | 19/300 [00:14<02:14,  2.09it/s]# Trainer step: 10, epoch: 1:   7%|▋         | 20/300 [00:15<02:13,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 20/300 [00:15<02:13,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 21/300 [00:15<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   7%|▋         | 22/300 [00:16<02:12,  2.10it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 23/300 [00:16<02:11,  2.11it/s]# Trainer step: 20, epoch: 2:   8%|▊         | 24/300 [00:17<02:10,  2.11it/s]Progress: 11.00%
---- avg training fps: 5.42# Trainer step: 20, epoch: 2:   8%|▊         | 25/300 [00:17<02:10,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▊         | 26/300 [00:18<02:09,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 27/300 [00:18<02:09,  2.11it/s]# Trainer step: 20, epoch: 2:   9%|▉         | 28/300 [00:19<02:08,  2.11it/s]# Trainer step: 20, epoch: 2:  10%|▉         | 29/300 [00:19<02:08,  2.11it/s]# Trainer step: 20, epoch: 2:  10%|█         | 30/300 [00:20<02:07,  2.11it/s]Progress: 13.00%
---- avg training fps: 5.84# Trainer step: 30, epoch: 3:  10%|█         | 30/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  10%|█         | 31/300 [00:20<02:07,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 32/300 [00:21<02:06,  2.11it/s]# Trainer step: 30, epoch: 3:  11%|█         | 33/300 [00:21<02:21,  1.88it/s]# Trainer step: 30, epoch: 3:  11%|█▏        | 34/300 [00:22<02:17,  1.94it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 35/300 [00:22<02:12,  2.00it/s]# Trainer step: 30, epoch: 3:  12%|█▏        | 36/300 [00:23<02:08,  2.05it/s]Progress: 15.00%
---- avg training fps: 6.11# Trainer step: 30, epoch: 3:  12%|█▏        | 37/300 [00:23<02:06,  2.08it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 38/300 [00:24<02:04,  2.11it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 39/300 [00:24<02:02,  2.13it/s]# Trainer step: 30, epoch: 3:  13%|█▎        | 40/300 [00:24<02:01,  2.14it/s]# Trainer step: 40, epoch: 4:  13%|█▎        | 40/300 [00:25<02:01,  2.14it/s]# Trainer step: 40, epoch: 4:  14%|█▎        | 41/300 [00:25<02:00,  2.15it/s]# Trainer step: 40, epoch: 4:  14%|█▍        | 42/300 [00:25<01:59,  2.15it/s]Progress: 17.00%
---- avg training fps: 6.38# Trainer step: 40, epoch: 4:  14%|█▍        | 43/300 [00:26<01:59,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▍        | 44/300 [00:26<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 45/300 [00:27<01:58,  2.16it/s]# Trainer step: 40, epoch: 4:  15%|█▌        | 46/300 [00:27<01:57,  2.15it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 47/300 [00:28<01:57,  2.16it/s]# Trainer step: 40, epoch: 4:  16%|█▌        | 48/300 [00:28<01:56,  2.16it/s]Progress: 19.00%
---- avg training fps: 6.60# Trainer step: 40, epoch: 4:  16%|█▋        | 49/300 [00:29<01:56,  2.15it/s]# Trainer step: 40, epoch: 4:  17%|█▋        | 50/300 [00:29<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 50/300 [00:30<01:56,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 51/300 [00:30<01:55,  2.15it/s]# Trainer step: 50, epoch: 5:  17%|█▋        | 52/300 [00:33<06:04,  1.47s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 53/300 [00:34<04:48,  1.17s/it]# Trainer step: 50, epoch: 5:  18%|█▊        | 54/300 [00:34<03:54,  1.05it/s]Progress: 21.00%
---- avg training fps: 6.13# Trainer step: 50, epoch: 5:  18%|█▊        | 55/300 [00:35<03:18,  1.24it/s]# Trainer step: 50, epoch: 5:  19%|█▊        | 56/300 [00:35<02:52,  1.41it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 57/300 [00:36<02:33,  1.58it/s]# Trainer step: 50, epoch: 5:  19%|█▉        | 58/300 [00:36<02:20,  1.72it/s]# Trainer step: 50, epoch: 5:  20%|█▉        | 59/300 [00:37<02:11,  1.83it/s]# Trainer step: 50, epoch: 5:  20%|██        | 60/300 [00:37<02:05,  1.91it/s]Progress: 23.00%
---- avg training fps: 6.31# Trainer step: 60, epoch: 6:  20%|██        | 60/300 [00:38<02:05,  1.91it/s]# Trainer step: 60, epoch: 6:  20%|██        | 61/300 [00:38<02:01,  1.97it/s]# Trainer step: 60, epoch: 6:  21%|██        | 62/300 [00:38<02:12,  1.80it/s]# Trainer step: 60, epoch: 6:  21%|██        | 63/300 [00:39<02:05,  1.89it/s]# Trainer step: 60, epoch: 6:  21%|██▏       | 64/300 [00:39<02:00,  1.96it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 65/300 [00:40<01:56,  2.02it/s]# Trainer step: 60, epoch: 6:  22%|██▏       | 66/300 [00:40<01:53,  2.05it/s]Progress: 25.00%
---- avg training fps: 6.44# Trainer step: 60, epoch: 6:  22%|██▏       | 67/300 [00:41<01:51,  2.08it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 68/300 [00:41<01:50,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 69/300 [00:41<01:49,  2.11it/s]# Trainer step: 60, epoch: 6:  23%|██▎       | 70/300 [00:42<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  23%|██▎       | 70/300 [00:42<01:48,  2.12it/s]# Trainer step: 70, epoch: 7:  24%|██▎       | 71/300 [00:42<01:47,  2.13it/s]# Trainer step: 70, epoch: 7:  24%|██▍       | 72/300 [00:43<01:46,  2.13it/s]Progress: 27.00%
---- avg training fps: 6.57# Trainer step: 70, epoch: 7:  24%|██▍       | 73/300 [00:43<01:46,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▍       | 74/300 [00:44<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 75/300 [00:44<01:45,  2.14it/s]# Trainer step: 70, epoch: 7:  25%|██▌       | 76/300 [00:45<01:44,  2.13it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 77/300 [00:45<01:44,  2.14it/s]# Trainer step: 70, epoch: 7:  26%|██▌       | 78/300 [00:46<01:43,  2.14it/s]Progress: 29.00%
---- avg training fps: 6.69# Trainer step: 70, epoch: 7:  26%|██▋       | 79/300 [00:46<01:43,  2.15it/s]# Trainer step: 70, epoch: 7:  27%|██▋       | 80/300 [00:47<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 80/300 [00:47<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 81/300 [00:47<01:42,  2.14it/s]# Trainer step: 80, epoch: 8:  27%|██▋       | 82/300 [00:48<01:41,  2.15it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 83/300 [00:48<01:41,  2.14it/s]# Trainer step: 80, epoch: 8:  28%|██▊       | 84/300 [00:48<01:41,  2.13it/s]Progress: 31.00%
---- avg training fps: 6.80# Trainer step: 80, epoch: 8:  28%|██▊       | 85/300 [00:49<01:41,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▊       | 86/300 [00:49<01:40,  2.13it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 87/300 [00:50<01:40,  2.12it/s]# Trainer step: 80, epoch: 8:  29%|██▉       | 88/300 [00:50<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|██▉       | 89/300 [00:51<01:39,  2.12it/s]# Trainer step: 80, epoch: 8:  30%|███       | 90/300 [00:51<01:38,  2.12it/s]Progress: 33.00%
---- avg training fps: 6.89# Trainer step: 90, epoch: 9:  30%|███       | 90/300 [00:52<01:38,  2.12it/s]# Trainer step: 90, epoch: 9:  30%|███       | 91/300 [00:52<01:38,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███       | 92/300 [00:52<01:38,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███       | 93/300 [00:53<01:37,  2.12it/s]# Trainer step: 90, epoch: 9:  31%|███▏      | 94/300 [00:53<01:37,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 95/300 [00:54<01:36,  2.12it/s]# Trainer step: 90, epoch: 9:  32%|███▏      | 96/300 [00:54<01:36,  2.12it/s]Progress: 35.00%
---- avg training fps: 6.97# Trainer step: 90, epoch: 9:  32%|███▏      | 97/300 [00:55<01:35,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 98/300 [00:55<01:35,  2.11it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 99/300 [00:56<01:34,  2.12it/s]# Trainer step: 90, epoch: 9:  33%|███▎      | 100/300 [00:56<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  33%|███▎      | 100/300 [00:57<01:34,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▎      | 101/300 [00:57<01:33,  2.12it/s]# Trainer step: 100, epoch: 10:  34%|███▍      | 102/300 [01:00<04:32,  1.37s/it]Progress: 37.00%
---- avg training fps: 6.67# Trainer step: 100, epoch: 10:  34%|███▍      | 103/300 [01:01<03:49,  1.16s/it]# Trainer step: 100, epoch: 10:  35%|███▍      | 104/300 [01:01<03:07,  1.05it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 105/300 [01:02<02:37,  1.24it/s]# Trainer step: 100, epoch: 10:  35%|███▌      | 106/300 [01:02<02:17,  1.41it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 107/300 [01:03<02:02,  1.57it/s]# Trainer step: 100, epoch: 10:  36%|███▌      | 108/300 [01:03<01:53,  1.69it/s]Progress: 39.00%
---- avg training fps: 6.75# Trainer step: 100, epoch: 10:  36%|███▋      | 109/300 [01:03<01:45,  1.80it/s]# Trainer step: 100, epoch: 10:  37%|███▋      | 110/300 [01:04<01:40,  1.89it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 110/300 [01:04<01:40,  1.89it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 111/300 [01:04<01:36,  1.95it/s]# Trainer step: 110, epoch: 11:  37%|███▋      | 112/300 [01:05<01:34,  1.99it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 113/300 [01:05<01:32,  2.03it/s]# Trainer step: 110, epoch: 11:  38%|███▊      | 114/300 [01:06<01:30,  2.05it/s]Progress: 41.00%
---- avg training fps: 6.82# Trainer step: 110, epoch: 11:  38%|███▊      | 115/300 [01:06<01:29,  2.07it/s]# Trainer step: 110, epoch: 11:  39%|███▊      | 116/300 [01:07<01:28,  2.09it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 117/300 [01:07<01:27,  2.10it/s]# Trainer step: 110, epoch: 11:  39%|███▉      | 118/300 [01:08<01:26,  2.10it/s]# Trainer step: 110, epoch: 11:  40%|███▉      | 119/300 [01:08<01:25,  2.11it/s]# Trainer step: 110, epoch: 11:  40%|████      | 120/300 [01:09<01:25,  2.11it/s]Progress: 43.00%
---- avg training fps: 6.89# Trainer step: 120, epoch: 12:  40%|████      | 120/300 [01:09<01:25,  2.11it/s]# Trainer step: 120, epoch: 12:  40%|████      | 121/300 [01:09<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 122/300 [01:10<01:24,  2.11it/s]# Trainer step: 120, epoch: 12:  41%|████      | 123/300 [01:10<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  41%|████▏     | 124/300 [01:11<01:23,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 125/300 [01:11<01:22,  2.12it/s]# Trainer step: 120, epoch: 12:  42%|████▏     | 126/300 [01:12<01:22,  2.12it/s]Progress: 45.00%
---- avg training fps: 6.95# Trainer step: 120, epoch: 12:  42%|████▏     | 127/300 [01:12<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 128/300 [01:12<01:21,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 129/300 [01:13<01:20,  2.12it/s]# Trainer step: 120, epoch: 12:  43%|████▎     | 130/300 [01:13<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  43%|████▎     | 130/300 [01:14<01:20,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▎     | 131/300 [01:14<01:19,  2.12it/s]# Trainer step: 130, epoch: 13:  44%|████▍     | 132/300 [01:14<01:19,  2.12it/s]Progress: 47.00%
---- avg training fps: 7.01# Trainer step: 130, epoch: 13:  44%|████▍     | 133/300 [01:15<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▍     | 134/300 [01:15<01:18,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 135/300 [01:16<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  45%|████▌     | 136/300 [01:16<01:17,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 137/300 [01:17<01:16,  2.12it/s]# Trainer step: 130, epoch: 13:  46%|████▌     | 138/300 [01:17<01:16,  2.12it/s]Progress: 49.00%
---- avg training fps: 7.06# Trainer step: 130, epoch: 13:  46%|████▋     | 139/300 [01:18<01:15,  2.12it/s]# Trainer step: 130, epoch: 13:  47%|████▋     | 140/300 [01:18<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 140/300 [01:19<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 141/300 [01:19<01:15,  2.12it/s]# Trainer step: 140, epoch: 14:  47%|████▋     | 142/300 [01:19<01:14,  2.11it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 143/300 [01:20<01:14,  2.12it/s]# Trainer step: 140, epoch: 14:  48%|████▊     | 144/300 [01:20<01:13,  2.12it/s]Progress: 51.00%
---- avg training fps: 7.11# Trainer step: 140, epoch: 14:  48%|████▊     | 145/300 [01:20<01:13,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▊     | 146/300 [01:21<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 147/300 [01:21<01:12,  2.12it/s]# Trainer step: 140, epoch: 14:  49%|████▉     | 148/300 [01:22<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|████▉     | 149/300 [01:22<01:11,  2.12it/s]# Trainer step: 140, epoch: 14:  50%|█████     | 150/300 [01:23<01:10,  2.12it/s]Progress: 53.00%
---- avg training fps: 7.16# Trainer step: 150, epoch: 15:  50%|█████     | 150/300 [01:23<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  50%|█████     | 151/300 [01:23<01:10,  2.12it/s]# Trainer step: 150, epoch: 15:  51%|█████     | 152/300 [01:27<03:53,  1.58s/it]# Trainer step: 150, epoch: 15:  51%|█████     | 153/300 [01:28<03:02,  1.24s/it]# Trainer step: 150, epoch: 15:  51%|█████▏    | 154/300 [01:28<02:27,  1.01s/it]# Trainer step: 150, epoch: 15:  52%|█████▏    | 155/300 [01:29<02:03,  1.18it/s]# Trainer step: 150, epoch: 15:  52%|█████▏    | 156/300 [01:29<01:46,  1.36it/s]Progress: 55.00%
---- avg training fps: 6.91# Trainer step: 150, epoch: 15:  52%|█████▏    | 157/300 [01:30<01:33,  1.52it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 158/300 [01:30<01:25,  1.66it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 159/300 [01:31<01:19,  1.78it/s]# Trainer step: 150, epoch: 15:  53%|█████▎    | 160/300 [01:31<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  53%|█████▎    | 160/300 [01:32<01:14,  1.87it/s]# Trainer step: 160, epoch: 16:  54%|█████▎    | 161/300 [01:32<01:11,  1.94it/s]# Trainer step: 160, epoch: 16:  54%|█████▍    | 162/300 [01:32<01:09,  1.99it/s]Progress: 57.00%
---- avg training fps: 6.96# Trainer step: 160, epoch: 16:  54%|█████▍    | 163/300 [01:33<01:07,  2.02it/s]# Trainer step: 160, epoch: 16:  55%|█████▍    | 164/300 [01:33<01:06,  2.05it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 165/300 [01:34<01:05,  2.07it/s]# Trainer step: 160, epoch: 16:  55%|█████▌    | 166/300 [01:34<01:04,  2.08it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 167/300 [01:35<01:03,  2.10it/s]# Trainer step: 160, epoch: 16:  56%|█████▌    | 168/300 [01:35<01:02,  2.10it/s]Progress: 59.00%
---- avg training fps: 7.00# Trainer step: 160, epoch: 16:  56%|█████▋    | 169/300 [01:35<01:02,  2.10it/s]# Trainer step: 160, epoch: 16:  57%|█████▋    | 170/300 [01:36<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 170/300 [01:36<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 171/300 [01:36<01:01,  2.11it/s]# Trainer step: 170, epoch: 17:  57%|█████▋    | 172/300 [01:37<01:00,  2.11it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 173/300 [01:37<01:00,  2.12it/s]# Trainer step: 170, epoch: 17:  58%|█████▊    | 174/300 [01:38<00:59,  2.12it/s]Progress: 61.00%
---- avg training fps: 7.04# Trainer step: 170, epoch: 17:  58%|█████▊    | 175/300 [01:38<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▊    | 176/300 [01:39<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 177/300 [01:39<00:58,  2.12it/s]# Trainer step: 170, epoch: 17:  59%|█████▉    | 178/300 [01:40<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|█████▉    | 179/300 [01:40<00:57,  2.12it/s]# Trainer step: 170, epoch: 17:  60%|██████    | 180/300 [01:41<00:56,  2.12it/s]Progress: 63.00%
---- avg training fps: 7.08# Trainer step: 180, epoch: 18:  60%|██████    | 180/300 [01:41<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  60%|██████    | 181/300 [01:41<00:56,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 182/300 [01:42<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████    | 183/300 [01:42<00:55,  2.12it/s]# Trainer step: 180, epoch: 18:  61%|██████▏   | 184/300 [01:43<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 185/300 [01:43<00:54,  2.12it/s]# Trainer step: 180, epoch: 18:  62%|██████▏   | 186/300 [01:44<00:53,  2.12it/s]Progress: 65.00%
---- avg training fps: 7.12# Trainer step: 180, epoch: 18:  62%|██████▏   | 187/300 [01:44<00:53,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 188/300 [01:44<00:52,  2.12it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 189/300 [01:45<00:52,  2.11it/s]# Trainer step: 180, epoch: 18:  63%|██████▎   | 190/300 [01:45<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  63%|██████▎   | 190/300 [01:46<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  64%|██████▎   | 191/300 [01:46<00:51,  2.12it/s]# Trainer step: 190, epoch: 19:  64%|██████▍   | 192/300 [01:46<00:50,  2.12it/s]Progress: 67.00%
---- avg training fps: 7.16# Trainer step: 190, epoch: 19:  64%|██████▍   | 193/300 [01:47<00:50,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▍   | 194/300 [01:47<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 195/300 [01:48<00:49,  2.12it/s]# Trainer step: 190, epoch: 19:  65%|██████▌   | 196/300 [01:48<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 197/300 [01:49<00:48,  2.13it/s]# Trainer step: 190, epoch: 19:  66%|██████▌   | 198/300 [01:49<00:47,  2.13it/s]Progress: 69.00%
---- avg training fps: 7.19# Trainer step: 190, epoch: 19:  66%|██████▋   | 199/300 [01:50<00:47,  2.13it/s]# Trainer step: 190, epoch: 19:  67%|██████▋   | 200/300 [01:50<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 200/300 [01:51<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 201/300 [01:51<00:46,  2.13it/s]# Trainer step: 200, epoch: 20:  67%|██████▋   | 202/300 [01:55<02:33,  1.57s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 203/300 [01:55<02:00,  1.24s/it]# Trainer step: 200, epoch: 20:  68%|██████▊   | 204/300 [01:56<01:36,  1.01s/it]Progress: 71.00%
---- avg training fps: 7.00# Trainer step: 200, epoch: 20:  68%|██████▊   | 205/300 [01:56<01:20,  1.18it/s]# Trainer step: 200, epoch: 20:  69%|██████▊   | 206/300 [01:57<01:08,  1.37it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 207/300 [01:57<01:00,  1.53it/s]# Trainer step: 200, epoch: 20:  69%|██████▉   | 208/300 [01:58<00:55,  1.67it/s]# Trainer step: 200, epoch: 20:  70%|██████▉   | 209/300 [01:58<00:50,  1.79it/s]# Trainer step: 200, epoch: 20:  70%|███████   | 210/300 [01:58<00:47,  1.88it/s]Progress: 73.00%
---- avg training fps: 7.03# Trainer step: 210, epoch: 21:  70%|███████   | 210/300 [01:59<00:47,  1.88it/s]# Trainer step: 210, epoch: 21:  70%|███████   | 211/300 [01:59<00:45,  1.95it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 212/300 [01:59<00:43,  2.00it/s]# Trainer step: 210, epoch: 21:  71%|███████   | 213/300 [02:00<00:42,  2.04it/s]# Trainer step: 210, epoch: 21:  71%|███████▏  | 214/300 [02:00<00:41,  2.06it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 215/300 [02:01<00:40,  2.08it/s]# Trainer step: 210, epoch: 21:  72%|███████▏  | 216/300 [02:01<00:39,  2.10it/s]Progress: 75.00%
---- avg training fps: 7.07# Trainer step: 210, epoch: 21:  72%|███████▏  | 217/300 [02:02<00:39,  2.11it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 218/300 [02:02<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 219/300 [02:03<00:38,  2.12it/s]# Trainer step: 210, epoch: 21:  73%|███████▎  | 220/300 [02:03<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  73%|███████▎  | 220/300 [02:04<00:37,  2.12it/s]# Trainer step: 220, epoch: 22:  74%|███████▎  | 221/300 [02:04<00:37,  2.13it/s]# Trainer step: 220, epoch: 22:  74%|███████▍  | 222/300 [02:04<00:36,  2.12it/s]Progress: 77.00%
---- avg training fps: 7.10# Trainer step: 220, epoch: 22:  74%|███████▍  | 223/300 [02:05<00:36,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▍  | 224/300 [02:05<00:35,  2.12it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 225/300 [02:05<00:35,  2.13it/s]# Trainer step: 220, epoch: 22:  75%|███████▌  | 226/300 [02:06<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 227/300 [02:06<00:34,  2.13it/s]# Trainer step: 220, epoch: 22:  76%|███████▌  | 228/300 [02:07<00:33,  2.12it/s]Progress: 79.00%
---- avg training fps: 7.13# Trainer step: 220, epoch: 22:  76%|███████▋  | 229/300 [02:07<00:33,  2.13it/s]# Trainer step: 220, epoch: 22:  77%|███████▋  | 230/300 [02:08<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 230/300 [02:08<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 231/300 [02:08<00:32,  2.13it/s]# Trainer step: 230, epoch: 23:  77%|███████▋  | 232/300 [02:09<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 233/300 [02:09<00:31,  2.13it/s]# Trainer step: 230, epoch: 23:  78%|███████▊  | 234/300 [02:10<00:31,  2.13it/s]Progress: 81.00%
---- avg training fps: 7.16# Trainer step: 230, epoch: 23:  78%|███████▊  | 235/300 [02:10<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▊  | 236/300 [02:11<00:30,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 237/300 [02:11<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  79%|███████▉  | 238/300 [02:12<00:29,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|███████▉  | 239/300 [02:12<00:28,  2.13it/s]# Trainer step: 230, epoch: 23:  80%|████████  | 240/300 [02:13<00:28,  2.13it/s]Progress: 83.00%
---- avg training fps: 7.19# Trainer step: 240, epoch: 24:  80%|████████  | 240/300 [02:13<00:28,  2.13it/s]# Trainer step: 240, epoch: 24:  80%|████████  | 241/300 [02:13<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 242/300 [02:13<00:27,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████  | 243/300 [02:14<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  81%|████████▏ | 244/300 [02:14<00:26,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 245/300 [02:15<00:25,  2.13it/s]# Trainer step: 240, epoch: 24:  82%|████████▏ | 246/300 [02:15<00:25,  2.13it/s]Progress: 85.00%
---- avg training fps: 7.22# Trainer step: 240, epoch: 24:  82%|████████▏ | 247/300 [02:16<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 248/300 [02:16<00:24,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 249/300 [02:17<00:23,  2.13it/s]# Trainer step: 240, epoch: 24:  83%|████████▎ | 250/300 [02:17<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  83%|████████▎ | 250/300 [02:18<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▎ | 251/300 [02:18<00:23,  2.13it/s]# Trainer step: 250, epoch: 25:  84%|████████▍ | 252/300 [02:22<01:16,  1.60s/it]Progress: 87.00%
---- avg training fps: 7.05# Trainer step: 250, epoch: 25:  84%|████████▍ | 253/300 [02:22<00:59,  1.26s/it]# Trainer step: 250, epoch: 25:  85%|████████▍ | 254/300 [02:23<00:47,  1.02s/it]# Trainer step: 250, epoch: 25:  85%|████████▌ | 255/300 [02:23<00:38,  1.17it/s]# Trainer step: 250, epoch: 25:  85%|████████▌ | 256/300 [02:24<00:32,  1.35it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 257/300 [02:24<00:28,  1.52it/s]# Trainer step: 250, epoch: 25:  86%|████████▌ | 258/300 [02:25<00:25,  1.66it/s]Progress: 89.00%
---- avg training fps: 7.08# Trainer step: 250, epoch: 25:  86%|████████▋ | 259/300 [02:25<00:23,  1.78it/s]# Trainer step: 250, epoch: 25:  87%|████████▋ | 260/300 [02:26<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 260/300 [02:26<00:21,  1.86it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 261/300 [02:26<00:20,  1.94it/s]# Trainer step: 260, epoch: 26:  87%|████████▋ | 262/300 [02:27<00:19,  1.99it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 263/300 [02:27<00:18,  2.03it/s]# Trainer step: 260, epoch: 26:  88%|████████▊ | 264/300 [02:28<00:17,  2.06it/s]Progress: 91.00%
---- avg training fps: 7.11# Trainer step: 260, epoch: 26:  88%|████████▊ | 265/300 [02:28<00:16,  2.08it/s]# Trainer step: 260, epoch: 26:  89%|████████▊ | 266/300 [02:29<00:16,  2.10it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 267/300 [02:29<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  89%|████████▉ | 268/300 [02:29<00:15,  2.11it/s]# Trainer step: 260, epoch: 26:  90%|████████▉ | 269/300 [02:30<00:14,  2.12it/s]# Trainer step: 260, epoch: 26:  90%|█████████ | 270/300 [02:30<00:14,  2.13it/s]Progress: 93.00%
---- avg training fps: 7.14# Trainer step: 270, epoch: 27:  90%|█████████ | 270/300 [02:31<00:14,  2.13it/s]# Trainer step: 270, epoch: 27:  90%|█████████ | 271/300 [02:31<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 272/300 [02:31<00:13,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████ | 273/300 [02:32<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  91%|█████████▏| 274/300 [02:32<00:12,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 275/300 [02:33<00:11,  2.13it/s]# Trainer step: 270, epoch: 27:  92%|█████████▏| 276/300 [02:33<00:11,  2.13it/s]Progress: 95.00%
---- avg training fps: 7.16# Trainer step: 270, epoch: 27:  92%|█████████▏| 277/300 [02:34<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 278/300 [02:34<00:10,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 279/300 [02:35<00:09,  2.13it/s]# Trainer step: 270, epoch: 27:  93%|█████████▎| 280/300 [02:35<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  93%|█████████▎| 280/300 [02:36<00:09,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▎| 281/300 [02:36<00:08,  2.13it/s]# Trainer step: 280, epoch: 28:  94%|█████████▍| 282/300 [02:36<00:08,  2.13it/s]Progress: 97.00%
---- avg training fps: 7.19# Trainer step: 280, epoch: 28:  94%|█████████▍| 283/300 [02:36<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▍| 284/300 [02:37<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 285/300 [02:37<00:07,  2.13it/s]# Trainer step: 280, epoch: 28:  95%|█████████▌| 286/300 [02:38<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 287/300 [02:38<00:06,  2.13it/s]# Trainer step: 280, epoch: 28:  96%|█████████▌| 288/300 [02:39<00:05,  2.13it/s]Progress: 99.00%
---- avg training fps: 7.21# Trainer step: 280, epoch: 28:  96%|█████████▋| 289/300 [02:39<00:05,  2.13it/s]# Trainer step: 280, epoch: 28:  97%|█████████▋| 290/300 [02:40<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 290/300 [02:40<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 291/300 [02:40<00:04,  2.13it/s]# Trainer step: 290, epoch: 29:  97%|█████████▋| 292/300 [02:41<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 293/300 [02:41<00:03,  2.13it/s]# Trainer step: 290, epoch: 29:  98%|█████████▊| 294/300 [02:42<00:02,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.23# Trainer step: 290, epoch: 29:  98%|█████████▊| 295/300 [02:42<00:02,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▊| 296/300 [02:43<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 297/300 [02:43<00:01,  2.13it/s]# Trainer step: 290, epoch: 29:  99%|█████████▉| 298/300 [02:44<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|█████████▉| 299/300 [02:44<00:00,  2.13it/s]# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [02:44<00:00,  2.13it/s]Progress: 100.00%
---- avg training fps: 7.25Progress: 100.00%Saving checkpoint at step.. 300
Saving LoRA weights for SDXL model...
Using existing model for inference
Re-using training pipeline for inference, just swapping the scheduler..
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 0.80
Rendering validation img with prompt: 
-------------------------
Adjusted prompt for LORA:

-- to:
in the style of <s0><s1><s2>,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>,
Embedding zero prompt: 
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:07,  3.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.67it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.59it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.55it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.52it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.51it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.50it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.49it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.49it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.48it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.48it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.48it/s][A
 47%|████▋     | 14/30 [00:03<00:04,  3.48it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.47it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.47it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.47it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.47it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.46it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.46it/s][A
 70%|███████   | 21/30 [00:05<00:02,  3.45it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.45it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.44it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.44it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.44it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.43it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.43it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.43it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.43it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.43it/s][A100%|██████████| 30/30 [00:08<00:00,  3.48it/s]
Rendering validation img with prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Adjusted prompt for LORA:
Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-- to:
in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Embedding zero prompt: Binary Love: A heart-shaped composition made up of glowing binary code, symbolizing the merging of human emotion and technology, incredible digital art, cyberpunk, neon colors, glitch effects, 3D octane render, HD
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.92it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.68it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.57it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.51it/s][A
 20%|██        | 6/30 [00:01<00:06,  3.48it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.46it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.44it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.43it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.41it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.41it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.41it/s][A
 43%|████▎     | 13/30 [00:03<00:04,  3.41it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.40it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.40it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.39it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.39it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.39it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.38it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.39it/s][A
 80%|████████  | 24/30 [00:06<00:01,  3.38it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.38it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.38it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.37it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.37it/s][A100%|██████████| 30/30 [00:08<00:00,  3.43it/s]
Rendering validation img with prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Adjusted prompt for LORA:
Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-- to:
in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Embedding zero prompt: Glass Roots: A luminescent glass sculpture of a fully bloomed rose emerges from a broken marble pedestal, natures resilience triumphant amidst the decay. Shadows cast by a dim overhead spotlight. Delicate veins intertwine the transparent petals, illuminating from within, symbolizing fragilitys steely core.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.90it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.63it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.53it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.47it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.43it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.41it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.39it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.38it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.37it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.37it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.36it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.36it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.36it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.36it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.35it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.35it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.36it/s][A
 67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.35it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.35it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.35it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.35it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s][A
 90%|█████████ | 27/30 [00:07<00:00,  3.34it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.35it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.34it/s][A100%|██████████| 30/30 [00:08<00:00,  3.39it/s]
Rendering validation img with prompt: the stunning skyline of New York City
-------------------------
Adjusted prompt for LORA:
the stunning skyline of New York City
-- to:
in the style of <s0><s1><s2>, the stunning skyline of New York City
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, the stunning skyline of New York City
Embedding zero prompt: the stunning skyline of New York City
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:06,  4.83it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.61it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.50it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.44it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.41it/s][A
 23%|██▎       | 7/30 [00:01<00:06,  3.39it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.37it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.36it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.35it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.34it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.34it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.34it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.34it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.33it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s][A
 57%|█████▋    | 17/30 [00:04<00:03,  3.33it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.33it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.33it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.33it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.33it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.33it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.32it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.33it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.33it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.32it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.32it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.32it/s][A100%|██████████| 30/30 [00:08<00:00,  3.37it/s]
Rendering validation img with prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Adjusted prompt for LORA:
An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-- to:
in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Embedding zero prompt: An ethereal, levitating monolith backlit by a supernova sky, casting iridescent light on the ice-spiked Martian terrain. Neo-futurism, Dali surrealism, wide-angle lens, chiaroscuro lighting.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.86it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.60it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.43it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.39it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.37it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.35it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.34it/s][A
 33%|███▎      | 10/30 [00:02<00:05,  3.34it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.33it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.33it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.32it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.32it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.32it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.32it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.31it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.31it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.31it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.31it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.31it/s][A100%|██████████| 30/30 [00:08<00:00,  3.35it/s]
Rendering validation img with prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Adjusted prompt for LORA:
The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-- to:
in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Embedding zero prompt: The Silent Of Silicon, a digital deer rendered in hyper-realistic 3D, eyes glowing in binary code, comfortably resting amidst rich motherboard-green foliage, accented under crisply fluorescent, simulated LED dawn.
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.85it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.59it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.48it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.42it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.38it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.34it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.33it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.33it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.32it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.32it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.31it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.31it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.31it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.31it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.31it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.31it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.31it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.31it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.30it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.30it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.31it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.30it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.30it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.30it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.30it/s][A100%|██████████| 30/30 [00:08<00:00,  3.34it/s]
Rendering validation img with prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Adjusted prompt for LORA:
In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-- to:
in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Embedding zero prompt: In the heart of an ancient forest, a massive projection illuminates the darkness. A lone figure, a majestic mythical creature made of shimmering gold, materializes, casting a radiant glow amidst the towering trees. intricate geometric surfaces encasing an expanse of flora and fauna,
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.58it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.47it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.41it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.37it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.35it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.31it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.30it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.30it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:08<00:00,  3.29it/s][A100%|██████████| 30/30 [00:08<00:00,  3.33it/s]
Rendering validation img with prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Adjusted prompt for LORA:
A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-- to:
in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
-------------------------
Embedding lora prompt: in the style of <s0><s1><s2>, A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Embedding zero prompt: A solitary tree standing tall amidst a sea of buildings, Urban nature photography, vibrant colors, juxtaposition of natural elements with urban landscapes, play of light and shadow, storytelling through compositions
Setting token_scale to 0.96 (lora_scale = 0.80, power = 0.4)

  0%|          | 0/30 [00:00<?, ?it/s][A
  3%|▎         | 1/30 [00:00<00:05,  4.86it/s][A
  7%|▋         | 2/30 [00:00<00:07,  3.83it/s][A
 10%|█         | 3/30 [00:00<00:07,  3.57it/s][A
 13%|█▎        | 4/30 [00:01<00:07,  3.46it/s][A
 17%|█▋        | 5/30 [00:01<00:07,  3.40it/s][A
 20%|██        | 6/30 [00:01<00:07,  3.36it/s][A
 23%|██▎       | 7/30 [00:02<00:06,  3.34it/s][A
 27%|██▋       | 8/30 [00:02<00:06,  3.33it/s][A
 30%|███       | 9/30 [00:02<00:06,  3.32it/s][A
 33%|███▎      | 10/30 [00:02<00:06,  3.31it/s][A
 37%|███▋      | 11/30 [00:03<00:05,  3.31it/s][A
 40%|████      | 12/30 [00:03<00:05,  3.30it/s][A
 43%|████▎     | 13/30 [00:03<00:05,  3.30it/s][A
 47%|████▋     | 14/30 [00:04<00:04,  3.30it/s][A
 50%|█████     | 15/30 [00:04<00:04,  3.30it/s][A
 53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s][A
 57%|█████▋    | 17/30 [00:05<00:03,  3.30it/s][A
 60%|██████    | 18/30 [00:05<00:03,  3.30it/s][A
 63%|██████▎   | 19/30 [00:05<00:03,  3.30it/s][A
 67%|██████▋   | 20/30 [00:05<00:03,  3.30it/s][A
 70%|███████   | 21/30 [00:06<00:02,  3.29it/s][A
 73%|███████▎  | 22/30 [00:06<00:02,  3.29it/s][A
 77%|███████▋  | 23/30 [00:06<00:02,  3.29it/s][A
 80%|████████  | 24/30 [00:07<00:01,  3.29it/s][A
 83%|████████▎ | 25/30 [00:07<00:01,  3.29it/s][A
 87%|████████▋ | 26/30 [00:07<00:01,  3.29it/s][A
 90%|█████████ | 27/30 [00:08<00:00,  3.29it/s][A
 93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s][A
 97%|█████████▋| 29/30 [00:08<00:00,  3.29it/s][A
100%|██████████| 30/30 [00:09<00:00,  3.29it/s][A100%|██████████| 30/30 [00:09<00:00,  3.33it/s]
list_adapters_component_wise: {'unet': ['default']}
Set adapter 'default' of 'unet' with scale = 1.00
Training job complete, saving outputs...
# Trainer step: 290, epoch: 29: 100%|██████████| 300/300 [04:03<00:00,  1.23it/s]
------------------------------------------
Training done :)
